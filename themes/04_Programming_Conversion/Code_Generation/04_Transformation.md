# ä»£ç ç”Ÿæˆè½¬æ¢å®ç°

## ğŸ“‘ ç›®å½•

- [ä»£ç ç”Ÿæˆè½¬æ¢å®ç°](#ä»£ç ç”Ÿæˆè½¬æ¢å®ç°)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. è½¬æ¢å®ç°æ¦‚è¿°](#1-è½¬æ¢å®ç°æ¦‚è¿°)
  - [2. Schemaè§£æå®ç°](#2-schemaè§£æå®ç°)
  - [3. æ¨¡æ¿å¼•æ“å®ç°](#3-æ¨¡æ¿å¼•æ“å®ç°)
  - [4. ä»£ç ç”Ÿæˆå®ç°](#4-ä»£ç ç”Ÿæˆå®ç°)
  - [5. è½¬æ¢å·¥å…·](#5-è½¬æ¢å·¥å…·)
  - [6. å‚è€ƒæ–‡çŒ®](#6-å‚è€ƒæ–‡çŒ®)
    - [6.1 æŠ€æœ¯æ–‡æ¡£](#61-æŠ€æœ¯æ–‡æ¡£)

---

## 1. è½¬æ¢å®ç°æ¦‚è¿°

ä»£ç ç”Ÿæˆè½¬æ¢å®ç°åŒ…æ‹¬ï¼š

1. **Schemaè§£æ**ï¼šè§£æè¾“å…¥Schema
2. **æ¨¡æ¿åº”ç”¨**ï¼šåº”ç”¨ä»£ç æ¨¡æ¿
3. **ä»£ç ç”Ÿæˆ**ï¼šç”Ÿæˆç›®æ ‡ä»£ç 

---

## 2. Schemaè§£æå®ç°

**Pythonå®ç°**ï¼š

```python
import json
from typing import Dict, Any

class SchemaParser:
    """Schemaè§£æå™¨"""

    def __init__(self, schema_file: str):
        with open(schema_file, 'r') as f:
            self.schema = json.load(f)

    def parse(self) -> Dict[str, Any]:
        """è§£æSchema"""
        return {
            'types': self._parse_types(),
            'models': self._parse_models()
        }

    def _parse_types(self) -> List[Dict[str, Any]]:
        """è§£æç±»å‹å®šä¹‰"""
        # å®ç°ç±»å‹è§£æé€»è¾‘
        pass

    def _parse_models(self) -> List[Dict[str, Any]]:
        """è§£ææ¨¡å‹å®šä¹‰"""
        # å®ç°æ¨¡å‹è§£æé€»è¾‘
        pass
```

---

## 3. æ¨¡æ¿å¼•æ“å®ç°

**Pythonå®ç°ï¼ˆä½¿ç”¨Jinja2ï¼‰**ï¼š

```python
from jinja2 import Template

class TemplateEngine:
    """æ¨¡æ¿å¼•æ“"""

    def __init__(self, template_file: str):
        with open(template_file, 'r') as f:
            self.template = Template(f.read())

    def render(self, context: Dict[str, Any]) -> str:
        """æ¸²æŸ“æ¨¡æ¿"""
        return self.template.render(**context)
```

---

## 4. ä»£ç ç”Ÿæˆå®ç°

**Pythonå®ç°**ï¼š

```python
class CodeGenerator:
    """ä»£ç ç”Ÿæˆå™¨"""

    def __init__(self, parser: SchemaParser, template_engine: TemplateEngine):
        self.parser = parser
        self.template_engine = template_engine

    def generate(self, output_file: str):
        """ç”Ÿæˆä»£ç """
        schema_data = self.parser.parse()
        code = self.template_engine.render(schema_data)

        with open(output_file, 'w') as f:
            f.write(code)
```

---

## 5. è½¬æ¢å·¥å…·

**å·¥å…·åˆ—è¡¨**ï¼š

1. **openapi-generator**ï¼šOpenAPIä»£ç ç”Ÿæˆ
2. **protoc**ï¼šProtocol Buffersç¼–è¯‘å™¨
3. **quicktype**ï¼šJSONåˆ°ä»£ç ç”Ÿæˆ

---

## 6. ä»£ç ç”Ÿæˆæ•°æ®å­˜å‚¨ä¸åˆ†æ

### 6.1 PostgreSQLä»£ç ç”Ÿæˆæ•°æ®å­˜å‚¨

**ä»£ç ç”Ÿæˆä»»åŠ¡å’Œç”Ÿæˆç»“æœæ•°æ®å­˜å‚¨æ–¹æ¡ˆ**ï¼š

```python
import psycopg2
import json
from typing import Dict, List, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass

@dataclass
class CodeGenerationTask:
    """ä»£ç ç”Ÿæˆä»»åŠ¡"""
    task_id: str
    source_schema: Dict
    target_language: str
    template_name: str
    generation_config: Dict
    timestamp: datetime
    status: str = 'pending'

@dataclass
class GeneratedCode:
    """ç”Ÿæˆçš„ä»£ç """
    task_id: str
    file_path: str
    code_content: str
    metadata: Dict
    timestamp: datetime
    success: bool = True

class CodeGenerationStorage:
    """ä»£ç ç”Ÿæˆæ•°æ®å­˜å‚¨ç³»ç»Ÿ"""

    def __init__(self, connection_string: str):
        self.conn = psycopg2.connect(connection_string)
        self.cur = self.conn.cursor()
        self._create_tables()

    def _create_tables(self):
        """åˆ›å»ºä»£ç ç”Ÿæˆæ•°æ®è¡¨"""
        # ä»£ç ç”Ÿæˆä»»åŠ¡è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS code_generation_tasks (
                id SERIAL PRIMARY KEY,
                task_id VARCHAR(200) UNIQUE NOT NULL,
                source_schema JSONB NOT NULL,
                target_language VARCHAR(50) NOT NULL,
                template_name VARCHAR(100) NOT NULL,
                generation_config JSONB NOT NULL,
                status VARCHAR(50) DEFAULT 'pending',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # ç”Ÿæˆä»£ç è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS generated_code (
                id BIGSERIAL PRIMARY KEY,
                task_id VARCHAR(200) NOT NULL,
                file_path VARCHAR(500) NOT NULL,
                code_content TEXT NOT NULL,
                metadata JSONB NOT NULL,
                success BOOLEAN DEFAULT TRUE,
                timestamp TIMESTAMP NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (task_id) REFERENCES code_generation_tasks(task_id)
            )
        """)

        # ä»£ç ç”Ÿæˆç»Ÿè®¡è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS code_generation_statistics (
                id SERIAL PRIMARY KEY,
                target_language VARCHAR(50) NOT NULL,
                statistic_type VARCHAR(50) NOT NULL,
                time_window TIMESTAMP NOT NULL,
                statistics JSONB NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(target_language, statistic_type, time_window)
            )
        """)

        # åˆ›å»ºç´¢å¼•
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_tasks_language_status
            ON code_generation_tasks(target_language, status)
        """)
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_code_task_time
            ON generated_code(task_id, timestamp DESC)
        """)

        self.conn.commit()

    def create_task(self, task: CodeGenerationTask):
        """åˆ›å»ºä»£ç ç”Ÿæˆä»»åŠ¡"""
        self.cur.execute("""
            INSERT INTO code_generation_tasks
            (task_id, source_schema, target_language, template_name, generation_config, status)
            VALUES (%s, %s::jsonb, %s, %s, %s::jsonb, %s)
        """, (task.task_id, json.dumps(task.source_schema),
              task.target_language, task.template_name,
              json.dumps(task.generation_config), task.status))
        self.conn.commit()

    def store_code(self, code: GeneratedCode):
        """å­˜å‚¨ç”Ÿæˆçš„ä»£ç """
        self.cur.execute("""
            INSERT INTO generated_code
            (task_id, file_path, code_content, metadata, success, timestamp)
            VALUES (%s, %s, %s, %s::jsonb, %s, %s)
        """, (code.task_id, code.file_path, code.code_content,
              json.dumps(code.metadata), code.success, code.timestamp))

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        self.cur.execute("""
            UPDATE code_generation_tasks
            SET status = %s, updated_at = CURRENT_TIMESTAMP
            WHERE task_id = %s
        """, ('completed' if code.success else 'failed', code.task_id))

        self.conn.commit()

    def calculate_statistics(self, target_language: str,
                            time_window: timedelta = timedelta(hours=1)) -> Dict:
        """è®¡ç®—ä»£ç ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        end_time = datetime.utcnow()
        start_time = end_time - time_window

        self.cur.execute("""
            SELECT
                COUNT(*) as total_tasks,
                SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as completed_tasks,
                SUM(CASE WHEN success THEN 1 ELSE 0 END) as successful_generations
            FROM code_generation_tasks t
            LEFT JOIN generated_code c ON t.task_id = c.task_id
            WHERE t.target_language = %s
              AND t.created_at >= %s
              AND t.created_at <= %s
        """, (target_language, start_time, end_time))

        stats = self.cur.fetchone()

        statistics = {
            'total_tasks': stats[0] if stats[0] else 0,
            'completed_tasks': stats[1] if stats[1] else 0,
            'successful_generations': stats[2] if stats[2] else 0,
            'success_rate': (stats[2] / stats[0] * 100) if stats[0] > 0 else 0
        }

        # å­˜å‚¨ç»Ÿè®¡ç»“æœ
        self.cur.execute("""
            INSERT INTO code_generation_statistics
            (target_language, statistic_type, time_window, statistics)
            VALUES (%s, %s, %s, %s::jsonb)
            ON CONFLICT (target_language, statistic_type, time_window) DO UPDATE
            SET statistics = EXCLUDED.statistics
        """, (target_language, 'code_generation_statistics', end_time,
              json.dumps(statistics)))
        self.conn.commit()

        return statistics

    def close(self):
        """å…³é—­è¿æ¥"""
        self.cur.close()
        self.conn.close()
```

---

## 7. å‚è€ƒæ–‡çŒ®

### 7.1 æŠ€æœ¯æ–‡æ¡£

- ä»£ç ç”Ÿæˆæœ€ä½³å®è·µ
- PostgreSQL JSONBæ–‡æ¡£

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `05_Case_Studies.md` - å®è·µæ¡ˆä¾‹

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21ï¼ˆæ‰©å±•ä»£ç ç”Ÿæˆæ•°æ®å­˜å‚¨å’Œåˆ†æåŠŸèƒ½ï¼Œæ–°å¢PostgreSQLå­˜å‚¨æ–¹æ¡ˆï¼‰
