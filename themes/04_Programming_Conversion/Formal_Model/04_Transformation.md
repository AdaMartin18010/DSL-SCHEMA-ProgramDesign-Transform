# ç¼–ç¨‹è¯­è¨€è½¬æ¢å®ç°

## ğŸ“‘ ç›®å½•

- [ç¼–ç¨‹è¯­è¨€è½¬æ¢å®ç°](#ç¼–ç¨‹è¯­è¨€è½¬æ¢å®ç°)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. è½¬æ¢å®ç°æ¦‚è¿°](#1-è½¬æ¢å®ç°æ¦‚è¿°)
  - [2. Schemaè§£æ](#2-schemaè§£æ)
    - [2.1 JSON Schemaè§£æ](#21-json-schemaè§£æ)
    - [2.2 OpenAPIè§£æ](#22-openapiè§£æ)
    - [2.3 Protocol Buffersè§£æ](#23-protocol-buffersè§£æ)
  - [3. ç±»å‹è½¬æ¢å®ç°](#3-ç±»å‹è½¬æ¢å®ç°)
    - [3.1 åŸºæœ¬ç±»å‹è½¬æ¢](#31-åŸºæœ¬ç±»å‹è½¬æ¢)
    - [3.2 å¤åˆç±»å‹è½¬æ¢](#32-å¤åˆç±»å‹è½¬æ¢)
    - [3.3 çº¦æŸè½¬æ¢](#33-çº¦æŸè½¬æ¢)
  - [4. ä»£ç ç”Ÿæˆå®ç°](#4-ä»£ç ç”Ÿæˆå®ç°)
    - [4.1 Pythonä»£ç ç”Ÿæˆ](#41-pythonä»£ç ç”Ÿæˆ)
    - [4.2 Rustä»£ç ç”Ÿæˆ](#42-rustä»£ç ç”Ÿæˆ)
    - [4.3 Javaä»£ç ç”Ÿæˆ](#43-javaä»£ç ç”Ÿæˆ)
  - [5. è½¬æ¢å·¥å…·](#5-è½¬æ¢å·¥å…·)
  - [6. è½¬æ¢éªŒè¯](#6-è½¬æ¢éªŒè¯)
  - [7. å‚è€ƒæ–‡çŒ®](#7-å‚è€ƒæ–‡çŒ®)

---

## 1. è½¬æ¢å®ç°æ¦‚è¿°

ç¼–ç¨‹è¯­è¨€è½¬æ¢å®ç°åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š

1. **Schemaè§£æ**ï¼šè§£æè¾“å…¥Schema
2. **ç±»å‹è½¬æ¢**ï¼šè½¬æ¢ç±»å‹ç³»ç»Ÿ
3. **ä»£ç ç”Ÿæˆ**ï¼šç”Ÿæˆç›®æ ‡è¯­è¨€ä»£ç 
4. **éªŒè¯æµ‹è¯•**ï¼šéªŒè¯ç”Ÿæˆä»£ç 

---

## 2. Schemaè§£æ

### 2.1 JSON Schemaè§£æ

**Pythonå®ç°**ï¼š

```python
import json
from typing import Dict, Any, List

class JSONSchemaParser:
    """JSON Schemaè§£æå™¨"""

    def __init__(self, schema_file: str):
        with open(schema_file, 'r') as f:
            self.schema = json.load(f)

    def parse_types(self) -> List[Dict[str, Any]]:
        """è§£æç±»å‹å®šä¹‰"""
        types = []

        if 'definitions' in self.schema:
            for name, definition in self.schema['definitions'].items():
                types.append({
                    'name': name,
                    'type': definition.get('type'),
                    'properties': definition.get('properties', {}),
                    'required': definition.get('required', [])
                })

        return types

    def parse_constraints(self, schema: Dict[str, Any]) -> Dict[str, Any]:
        """è§£æçº¦æŸæ¡ä»¶"""
        constraints = {}

        if 'minimum' in schema:
            constraints['min'] = schema['minimum']
        if 'maximum' in schema:
            constraints['max'] = schema['maximum']
        if 'pattern' in schema:
            constraints['pattern'] = schema['pattern']
        if 'enum' in schema:
            constraints['enum'] = schema['enum']

        return constraints
```

### 2.2 OpenAPIè§£æ

**Pythonå®ç°**ï¼š

```python
import yaml
from typing import Dict, Any

class OpenAPIParser:
    """OpenAPIè§£æå™¨"""

    def __init__(self, spec_file: str):
        with open(spec_file, 'r') as f:
            self.spec = yaml.safe_load(f)

    def parse_schemas(self) -> Dict[str, Any]:
        """è§£æSchemaå®šä¹‰"""
        schemas = {}

        if 'components' in self.spec and 'schemas' in self.spec['components']:
            schemas = self.spec['components']['schemas']

        return schemas

    def parse_models(self) -> List[Dict[str, Any]]:
        """è§£ææ•°æ®æ¨¡å‹"""
        models = []
        schemas = self.parse_schemas()

        for name, schema in schemas.items():
            models.append({
                'name': name,
                'type': schema.get('type'),
                'properties': schema.get('properties', {}),
                'required': schema.get('required', [])
            })

        return models
```

### 2.3 Protocol Buffersè§£æ

**Pythonå®ç°**ï¼š

```python
from google.protobuf import descriptor_pb2
from google.protobuf import message_factory

class ProtobufParser:
    """Protocol Buffersè§£æå™¨"""

    def __init__(self, proto_file: str):
        self.proto_file = proto_file

    def parse_messages(self) -> List[Dict[str, Any]]:
        """è§£ææ¶ˆæ¯å®šä¹‰"""
        # ä½¿ç”¨protocè§£æ.protoæ–‡ä»¶
        # è¿™é‡Œç®€åŒ–å®ç°
        messages = []
        return messages
```

---

## 3. ç±»å‹è½¬æ¢å®ç°

### 3.1 åŸºæœ¬ç±»å‹è½¬æ¢

**Pythonå®ç°**ï¼š

```python
class TypeConverter:
    """ç±»å‹è½¬æ¢å™¨"""

    TYPE_MAPPING = {
        'integer': {
            'python': 'int',
            'rust': 'i32',
            'java': 'int',
            'go': 'int'
        },
        'number': {
            'python': 'float',
            'rust': 'f64',
            'java': 'double',
            'go': 'float64'
        },
        'string': {
            'python': 'str',
            'rust': 'String',
            'java': 'String',
            'go': 'string'
        },
        'boolean': {
            'python': 'bool',
            'rust': 'bool',
            'java': 'boolean',
            'go': 'bool'
        }
    }

    def convert_type(self, schema_type: str, target_lang: str) -> str:
        """è½¬æ¢ç±»å‹"""
        if schema_type in self.TYPE_MAPPING:
            return self.TYPE_MAPPING[schema_type].get(target_lang, 'unknown')
        return 'unknown'
```

### 3.2 å¤åˆç±»å‹è½¬æ¢

**Pythonå®ç°**ï¼š

```python
class CompositeTypeConverter:
    """å¤åˆç±»å‹è½¬æ¢å™¨"""

    def convert_object(self, properties: Dict[str, Any],
                      target_lang: str) -> str:
        """è½¬æ¢å¯¹è±¡ç±»å‹"""
        if target_lang == 'python':
            return self._convert_to_python_class(properties)
        elif target_lang == 'rust':
            return self._convert_to_rust_struct(properties)
        elif target_lang == 'java':
            return self._convert_to_java_class(properties)
        elif target_lang == 'go':
            return self._convert_to_go_struct(properties)

    def _convert_to_python_class(self, properties: Dict[str, Any]) -> str:
        """è½¬æ¢ä¸ºPythonç±»"""
        code = "from dataclasses import dataclass\n\n"
        code += "@dataclass\n"
        code += "class Model:\n"

        for name, prop in properties.items():
            prop_type = prop.get('type', 'Any')
            code += f"    {name}: {prop_type}\n"

        return code
```

### 3.3 çº¦æŸè½¬æ¢

**Pythonå®ç°**ï¼š

```python
class ConstraintConverter:
    """çº¦æŸè½¬æ¢å™¨"""

    def convert_constraints(self, constraints: Dict[str, Any],
                           target_lang: str) -> str:
        """è½¬æ¢çº¦æŸæ¡ä»¶"""
        if target_lang == 'python':
            return self._convert_to_python_validation(constraints)
        elif target_lang == 'rust':
            return self._convert_to_rust_validation(constraints)

    def _convert_to_python_validation(self, constraints: Dict[str, Any]) -> str:
        """è½¬æ¢ä¸ºPythonéªŒè¯ä»£ç """
        code = "def validate(self) -> bool:\n"
        code += "    \"\"\"éªŒè¯çº¦æŸæ¡ä»¶\"\"\"\n"

        if 'min' in constraints:
            code += f"    if self.value < {constraints['min']}:\n"
            code += "        return False\n"

        if 'max' in constraints:
            code += f"    if self.value > {constraints['max']}:\n"
            code += "        return False\n"

        code += "    return True\n"
        return code
```

---

## 4. ä»£ç ç”Ÿæˆå®ç°

### 4.1 Pythonä»£ç ç”Ÿæˆ

**Pythonå®ç°**ï¼š

```python
class PythonCodeGenerator:
    """Pythonä»£ç ç”Ÿæˆå™¨"""

    def generate_class(self, model: Dict[str, Any]) -> str:
        """ç”ŸæˆPythonç±»"""
        code = "from dataclasses import dataclass\n"
        code += "from typing import Optional\n\n"
        code += f"@dataclass\n"
        code += f"class {model['name']}:\n"

        for prop_name, prop_def in model['properties'].items():
            prop_type = self._convert_type(prop_def.get('type'))
            required = prop_name in model.get('required', [])

            if not required:
                prop_type = f"Optional[{prop_type}]"

            code += f"    {prop_name}: {prop_type}\n"

        return code

    def _convert_type(self, schema_type: str) -> str:
        """è½¬æ¢ç±»å‹"""
        type_map = {
            'integer': 'int',
            'number': 'float',
            'string': 'str',
            'boolean': 'bool',
            'array': 'List',
            'object': 'Dict'
        }
        return type_map.get(schema_type, 'Any')
```

### 4.2 Rustä»£ç ç”Ÿæˆ

**Pythonå®ç°**ï¼š

```python
class RustCodeGenerator:
    """Rustä»£ç ç”Ÿæˆå™¨"""

    def generate_struct(self, model: Dict[str, Any]) -> str:
        """ç”ŸæˆRustç»“æ„ä½“"""
        code = "#[derive(Debug, Clone, Serialize, Deserialize)]\n"
        code += f"pub struct {model['name']} {{\n"

        for prop_name, prop_def in model['properties'].items():
            prop_type = self._convert_type(prop_def.get('type'))
            code += f"    pub {prop_name}: {prop_type},\n"

        code += "}\n"
        return code

    def _convert_type(self, schema_type: str) -> str:
        """è½¬æ¢ç±»å‹"""
        type_map = {
            'integer': 'i32',
            'number': 'f64',
            'string': 'String',
            'boolean': 'bool',
            'array': 'Vec',
            'object': 'HashMap'
        }
        return type_map.get(schema_type, 'String')
```

### 4.3 Javaä»£ç ç”Ÿæˆ

**Pythonå®ç°**ï¼š

```python
class JavaCodeGenerator:
    """Javaä»£ç ç”Ÿæˆå™¨"""

    def generate_class(self, model: Dict[str, Any]) -> str:
        """ç”ŸæˆJavaç±»"""
        code = "public class " + model['name'] + " {\n"

        for prop_name, prop_def in model['properties'].items():
            prop_type = self._convert_type(prop_def.get('type'))
            code += f"    private {prop_type} {prop_name};\n"

        # ç”Ÿæˆgetterå’Œsetter
        for prop_name, prop_def in model['properties'].items():
            prop_type = self._convert_type(prop_def.get('type'))
            code += f"\n    public {prop_type} get{prop_name.capitalize()}() {{\n"
            code += f"        return {prop_name};\n"
            code += "    }\n"
            code += f"\n    public void set{prop_name.capitalize()}({prop_type} {prop_name}) {{\n"
            code += f"        this.{prop_name} = {prop_name};\n"
            code += "    }\n"

        code += "}\n"
        return code

    def _convert_type(self, schema_type: str) -> str:
        """è½¬æ¢ç±»å‹"""
        type_map = {
            'integer': 'int',
            'number': 'double',
            'string': 'String',
            'boolean': 'boolean',
            'array': 'List',
            'object': 'Map'
        }
        return type_map.get(schema_type, 'Object')
```

---

## 5. è½¬æ¢å·¥å…·

**å·¥å…·åˆ—è¡¨**ï¼š

1. **openapi-generator**ï¼šOpenAPIä»£ç ç”Ÿæˆå·¥å…·
2. **protoc**ï¼šProtocol Buffersç¼–è¯‘å™¨
3. **quicktype**ï¼šJSONåˆ°ä»£ç ç”Ÿæˆå·¥å…·
4. **json-schema-to-typescript**ï¼šJSON Schemaåˆ°TypeScriptç”Ÿæˆå·¥å…·

---

## 6. è½¬æ¢éªŒè¯

**éªŒè¯æ–¹æ³•**ï¼š

1. **è¯­æ³•éªŒè¯**ï¼šéªŒè¯ç”Ÿæˆä»£ç è¯­æ³•
2. **ç±»å‹éªŒè¯**ï¼šéªŒè¯ç±»å‹æ­£ç¡®æ€§
3. **åŠŸèƒ½éªŒè¯**ï¼šéªŒè¯åŠŸèƒ½æ­£ç¡®æ€§

---

## 7. è½¬æ¢ä»»åŠ¡æ•°æ®å­˜å‚¨ä¸åˆ†æ

### 7.1 PostgreSQLè½¬æ¢ä»»åŠ¡æ•°æ®å­˜å‚¨

**è½¬æ¢ä»»åŠ¡å’Œç»“æœæ•°æ®å­˜å‚¨æ–¹æ¡ˆ**ï¼š

```python
import psycopg2
import json
from typing import Dict, List, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass

@dataclass
class ConversionTask:
    """è½¬æ¢ä»»åŠ¡"""
    task_id: str
    source_schema: Dict
    target_language: str
    conversion_config: Dict
    timestamp: datetime
    status: str = 'pending'

@dataclass
class ConversionResult:
    """è½¬æ¢ç»“æœ"""
    task_id: str
    generated_code: str
    metadata: Dict
    timestamp: datetime
    success: bool = True

class ConversionStorage:
    """è½¬æ¢ä»»åŠ¡æ•°æ®å­˜å‚¨ç³»ç»Ÿ"""

    def __init__(self, connection_string: str):
        self.conn = psycopg2.connect(connection_string)
        self.cur = self.conn.cursor()
        self._create_tables()

    def _create_tables(self):
        """åˆ›å»ºè½¬æ¢ä»»åŠ¡æ•°æ®è¡¨"""
        # è½¬æ¢ä»»åŠ¡è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS conversion_tasks (
                id SERIAL PRIMARY KEY,
                task_id VARCHAR(200) UNIQUE NOT NULL,
                source_schema JSONB NOT NULL,
                target_language VARCHAR(50) NOT NULL,
                conversion_config JSONB NOT NULL,
                status VARCHAR(50) DEFAULT 'pending',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # è½¬æ¢ç»“æœè¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS conversion_results (
                id BIGSERIAL PRIMARY KEY,
                task_id VARCHAR(200) NOT NULL,
                generated_code TEXT NOT NULL,
                metadata JSONB NOT NULL,
                success BOOLEAN DEFAULT TRUE,
                error_message TEXT,
                execution_time_ms INTEGER,
                timestamp TIMESTAMP NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (task_id) REFERENCES conversion_tasks(task_id)
            )
        """)

        # è½¬æ¢ç»Ÿè®¡è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS conversion_statistics (
                id SERIAL PRIMARY KEY,
                target_language VARCHAR(50) NOT NULL,
                statistic_type VARCHAR(50) NOT NULL,
                time_window TIMESTAMP NOT NULL,
                statistics JSONB NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(target_language, statistic_type, time_window)
            )
        """)

        # åˆ›å»ºç´¢å¼•
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_tasks_language_status
            ON conversion_tasks(target_language, status)
        """)
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_results_task_time
            ON conversion_results(task_id, timestamp DESC)
        """)

        self.conn.commit()

    def create_task(self, task: ConversionTask):
        """åˆ›å»ºè½¬æ¢ä»»åŠ¡"""
        self.cur.execute("""
            INSERT INTO conversion_tasks
            (task_id, source_schema, target_language, conversion_config, status)
            VALUES (%s, %s::jsonb, %s, %s::jsonb, %s)
        """, (task.task_id, json.dumps(task.source_schema),
              task.target_language, json.dumps(task.conversion_config),
              task.status))
        self.conn.commit()

    def store_result(self, result: ConversionResult, execution_time_ms: int = None):
        """å­˜å‚¨è½¬æ¢ç»“æœ"""
        self.cur.execute("""
            INSERT INTO conversion_results
            (task_id, generated_code, metadata, success, error_message,
             execution_time_ms, timestamp)
            VALUES (%s, %s, %s::jsonb, %s, %s, %s, %s)
        """, (result.task_id, result.generated_code,
              json.dumps(result.metadata), result.success,
              None if result.success else "Conversion failed",
              execution_time_ms, result.timestamp))

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        self.cur.execute("""
            UPDATE conversion_tasks
            SET status = %s, updated_at = CURRENT_TIMESTAMP
            WHERE task_id = %s
        """, ('completed' if result.success else 'failed', result.task_id))

        self.conn.commit()

    def calculate_statistics(self, target_language: str,
                            time_window: timedelta = timedelta(hours=1)) -> Dict:
        """è®¡ç®—è½¬æ¢ç»Ÿè®¡ä¿¡æ¯"""
        end_time = datetime.utcnow()
        start_time = end_time - time_window

        self.cur.execute("""
            SELECT
                COUNT(*) as total_tasks,
                SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as completed_tasks,
                AVG(execution_time_ms) as avg_execution_time_ms
            FROM conversion_tasks t
            LEFT JOIN conversion_results r ON t.task_id = r.task_id
            WHERE t.target_language = %s
              AND t.created_at >= %s
              AND t.created_at <= %s
        """, (target_language, start_time, end_time))

        stats = self.cur.fetchone()

        statistics = {
            'total_tasks': stats[0] if stats[0] else 0,
            'completed_tasks': stats[1] if stats[1] else 0,
            'success_rate': (stats[1] / stats[0] * 100) if stats[0] > 0 else 0,
            'avg_execution_time_ms': float(stats[2]) if stats[2] else 0
        }

        # å­˜å‚¨ç»Ÿè®¡ç»“æœ
        self.cur.execute("""
            INSERT INTO conversion_statistics
            (target_language, statistic_type, time_window, statistics)
            VALUES (%s, %s, %s, %s::jsonb)
            ON CONFLICT (target_language, statistic_type, time_window) DO UPDATE
            SET statistics = EXCLUDED.statistics
        """, (target_language, 'conversion_statistics', end_time,
              json.dumps(statistics)))
        self.conn.commit()

        return statistics

    def get_task_history(self, target_language: str = None,
                        limit: int = 100) -> List[Dict]:
        """è·å–è½¬æ¢ä»»åŠ¡å†å²"""
        query = """
            SELECT task_id, target_language, status, created_at
            FROM conversion_tasks
        """
        params = []

        if target_language:
            query += " WHERE target_language = %s"
            params.append(target_language)

        query += " ORDER BY created_at DESC LIMIT %s"
        params.append(limit)

        self.cur.execute(query, params)
        results = []
        for row in self.cur.fetchall():
            results.append({
                'task_id': row[0],
                'target_language': row[1],
                'status': row[2],
                'created_at': row[3]
            })
        return results

    def close(self):
        """å…³é—­è¿æ¥"""
        self.cur.close()
        self.conn.close()
```

---

## 8. å‚è€ƒæ–‡çŒ®

### 8.1 æŠ€æœ¯æ–‡æ¡£

- ä»£ç ç”Ÿæˆæœ€ä½³å®è·µ
- å¤šè¯­è¨€è½¬æ¢å·¥å…·æŒ‡å—
- PostgreSQL JSONBæ–‡æ¡£

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `../Language_Mapping/` - è¯­è¨€æ˜ å°„
- `../Code_Generation/` - ä»£ç ç”Ÿæˆ

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21ï¼ˆæ‰©å±•è½¬æ¢ä»»åŠ¡æ•°æ®å­˜å‚¨å’Œåˆ†æåŠŸèƒ½ï¼Œæ–°å¢PostgreSQLå­˜å‚¨æ–¹æ¡ˆï¼‰
