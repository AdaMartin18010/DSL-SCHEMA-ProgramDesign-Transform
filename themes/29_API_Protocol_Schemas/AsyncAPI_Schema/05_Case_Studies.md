# AsyncAPI Schemaå®è·µæ¡ˆä¾‹

## ğŸ“‘ ç›®å½•

- [AsyncAPI Schemaå®è·µæ¡ˆä¾‹](#asyncapi-schemaå®è·µæ¡ˆä¾‹)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¡ˆä¾‹æ¦‚è¿°](#1-æ¡ˆä¾‹æ¦‚è¿°)
  - [2. æ¡ˆä¾‹1ï¼šé‡‘èç§‘æŠ€å…¬å¸äº‹ä»¶é©±åŠ¨æ¶æ„è½¬å‹](#2-æ¡ˆä¾‹1é‡‘èç§‘æŠ€å…¬å¸äº‹ä»¶é©±åŠ¨æ¶æ„è½¬å‹)
    - [2.1 ä¼ä¸šèƒŒæ™¯](#21-ä¼ä¸šèƒŒæ™¯)
    - [2.2 ä¸šåŠ¡ç—›ç‚¹](#22-ä¸šåŠ¡ç—›ç‚¹)
    - [2.3 ä¸šåŠ¡ç›®æ ‡](#23-ä¸šåŠ¡ç›®æ ‡)
    - [2.4 æŠ€æœ¯æŒ‘æˆ˜](#24-æŠ€æœ¯æŒ‘æˆ˜)
    - [2.5 è§£å†³æ–¹æ¡ˆ](#25-è§£å†³æ–¹æ¡ˆ)
    - [2.6 å®Œæ•´ä»£ç å®ç°](#26-å®Œæ•´ä»£ç å®ç°)
    - [2.7 æ•ˆæœè¯„ä¼°ä¸ROI](#27-æ•ˆæœè¯„ä¼°ä¸roi)
  - [3. æ¡ˆä¾‹2ï¼šç‰©è”ç½‘è®¾å¤‡å®æ—¶æ•°æ®å¤„ç†](#3-æ¡ˆä¾‹2ç‰©è”ç½‘è®¾å¤‡å®æ—¶æ•°æ®å¤„ç†)
  - [4. æ¡ˆä¾‹3ï¼šç”µå•†å¹³å°è®¢å•çŠ¶æ€æµè½¬ç³»ç»Ÿ](#4-æ¡ˆä¾‹3ç”µå•†å¹³å°è®¢å•çŠ¶æ€æµè½¬ç³»ç»Ÿ)
  - [5. æ¡ˆä¾‹4ï¼šAsyncAPIåˆ°OpenAPIè½¬æ¢å·¥å…·](#5-æ¡ˆä¾‹4asyncapiåˆ°openapiè½¬æ¢å·¥å…·)
  - [6. æ¡ˆä¾‹5ï¼šAsyncAPI Schemaç‰ˆæœ¬ç®¡ç†](#6-æ¡ˆä¾‹5asyncapi-schemaç‰ˆæœ¬ç®¡ç†)

---

## 1. æ¡ˆä¾‹æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›AsyncAPI Schemaåœ¨å®é™…ä¼ä¸šåº”ç”¨ä¸­çš„å®è·µæ¡ˆä¾‹ï¼Œæ¶µç›–äº‹ä»¶é©±åŠ¨æ¶æ„ã€ç‰©è”ç½‘æ¶ˆæ¯ç³»ç»Ÿã€è®¢å•çŠ¶æ€æµè½¬ç­‰çœŸå®åœºæ™¯ã€‚

**æ¡ˆä¾‹ç±»å‹**ï¼š

1. **é‡‘èç§‘æŠ€EDAè½¬å‹**ï¼šæ ¸å¿ƒç³»ç»Ÿè§£è€¦ä¸äº‹ä»¶é©±åŠ¨
2. **ç‰©è”ç½‘å®æ—¶æ•°æ®å¤„ç†**ï¼šMQTT + Kafkaå®æ—¶æ¶ˆæ¯æµ
3. **ç”µå•†è®¢å•çŠ¶æ€æµè½¬**ï¼šè®¢å•ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ç®¡ç†
4. **AsyncAPIåˆ°OpenAPIè½¬æ¢**ï¼šAPIæ–‡æ¡£ç»Ÿä¸€
5. **Schemaç‰ˆæœ¬ç®¡ç†**ï¼šäº‹ä»¶ç‰ˆæœ¬æ¼”è¿›ç­–ç•¥

**å‚è€ƒä¼ä¸šæ¡ˆä¾‹**ï¼š

- **PayPal**ï¼šäº‹ä»¶é©±åŠ¨æ¶æ„å®è·µ
- **Netflix**ï¼šå¤§è§„æ¨¡å¼‚æ­¥æ¶ˆæ¯ç³»ç»Ÿ
- **è¥¿é—¨å­**ï¼šå·¥ä¸šç‰©è”ç½‘æ¶ˆæ¯å¹³å°

---

## 2. æ¡ˆä¾‹1ï¼šé‡‘èç§‘æŠ€å…¬å¸äº‹ä»¶é©±åŠ¨æ¶æ„è½¬å‹

### 2.1 ä¼ä¸šèƒŒæ™¯

**ä¼ä¸šæ¦‚å†µ**ï¼š
"æ’ä¿¡é‡‘è"ï¼ˆåŒ–åï¼‰æ˜¯ä¸­å›½é¢†å…ˆçš„é‡‘èç§‘æŠ€å…¬å¸ï¼Œæˆç«‹äº2012å¹´ï¼Œä¸ºè¶…è¿‡500ä¸‡ä¸ªäººç”¨æˆ·å’Œ10ä¸‡ä¼ä¸šå®¢æˆ·æä¾›æ•°å­—é‡‘èæœåŠ¡ã€‚å…¬å¸æ—¥å‡äº¤æ˜“é‡è¶…è¿‡3000ä¸‡ç¬”ï¼Œå³°å€¼TPSè¾¾50,000ã€‚

**æŠ€æœ¯ç°çŠ¶**ï¼š
- å•ä½“åº”ç”¨æ¶æ„ï¼Œæ ¸å¿ƒç³»ç»Ÿè€¦åˆä¸¥é‡
- æœåŠ¡é—´é‡‡ç”¨åŒæ­¥HTTPè°ƒç”¨ï¼Œé“¾è·¯å†—é•¿
- ç³»ç»Ÿæ‰©å±•å›°éš¾ï¼Œé«˜å³°æœŸå“åº”å»¶è¿Ÿé«˜
- æ•…éšœä¼ æ’­é£é™©å¤§ï¼Œç¼ºä¹éš”ç¦»æœºåˆ¶

### 2.2 ä¸šåŠ¡ç—›ç‚¹

1. **ç³»ç»Ÿè€¦åˆä¸¥é‡**
   - æ ¸å¿ƒäº¤æ˜“ç³»ç»Ÿä¸é£æ§ã€è´¦åŠ¡ã€é€šçŸ¥å¼ºè€¦åˆ
   - ä¸€ä¸ªæœåŠ¡æ•…éšœå½±å“æ•´ä¸ªäº¤æ˜“é“¾è·¯
   - ä¿®æ”¹ä¸€ä¸ªåŠŸèƒ½éœ€è¦è”åŠ¨å¤šä¸ªç³»ç»Ÿå‘å¸ƒ

2. **å“åº”å»¶è¿Ÿé«˜**
   - åŒæ­¥è°ƒç”¨é“¾è·¯è¿‡é•¿ï¼Œå¹³å‡å“åº”1.5ç§’
   - é«˜å³°æœŸç³»ç»Ÿè´Ÿè½½é«˜ï¼Œå“åº”æ—¶é—´æš´æ¶¨
   - ç”¨æˆ·ä½“éªŒå·®ï¼Œäº¤æ˜“è½¬åŒ–ç‡ä¸‹é™

3. **æ‰©å±•å›°éš¾**
   - æ•°æ®åº“ç“¶é¢ˆæ˜æ˜¾ï¼Œæ— æ³•æ°´å¹³æ‰©å±•
   - æ–°åŠŸèƒ½ä¸Šçº¿å‘¨æœŸé•¿è¾¾2-3å‘¨
   - æŠ€æœ¯å€ºåŠ¡ç§¯ç´¯ï¼Œç»´æŠ¤æˆæœ¬é«˜

4. **æ•°æ®ä¸€è‡´æ€§éš¾ä¿éšœ**
   - åˆ†å¸ƒå¼äº‹åŠ¡å¤„ç†å¤æ‚
   - æ•°æ®åŒæ­¥å»¶è¿Ÿï¼Œå¯¹è´¦å›°éš¾
   - ç¼ºä¹å¯é çš„äº‹ä»¶æº¯æºæœºåˆ¶

5. **æ•…éšœæ¢å¤æ…¢**
   - ç¼ºä¹æ•…éšœéš”ç¦»ï¼Œå•ç‚¹æ•…éšœå½±å“å…¨å±€
   - é—®é¢˜å®šä½å›°éš¾ï¼Œå¹³å‡æ¢å¤æ—¶é—´(MTTR)è¶…è¿‡30åˆ†é’Ÿ
   - ç¼ºä¹ä¼˜é›…é™çº§æœºåˆ¶

### 2.3 ä¸šåŠ¡ç›®æ ‡

1. **ç³»ç»Ÿè§£è€¦**
   - æ ¸å¿ƒä¸šåŠ¡ç³»ç»Ÿå®Œå…¨è§£è€¦ï¼Œç‹¬ç«‹æ¼”è¿›
   - å»ºç«‹äº‹ä»¶é©±åŠ¨é€šä¿¡æœºåˆ¶
   - å®ç°æœåŠ¡è‡ªæ²»å’Œç‹¬ç«‹éƒ¨ç½²

2. **æ€§èƒ½æå‡**
   - äº¤æ˜“å“åº”æ—¶é—´ä»1.5ç§’é™è‡³200msä»¥å†…
   - æ”¯æŒ10å€æµé‡æ‰©å±•
   - ç³»ç»Ÿå¯ç”¨æ€§è¾¾åˆ°99.99%

3. **æ•æ·äº¤ä»˜**
   - æ–°åŠŸèƒ½ä¸Šçº¿å‘¨æœŸä»2å‘¨ç¼©çŸ­è‡³2å¤©
   - å®ç°æŒç»­é›†æˆå’ŒæŒç»­éƒ¨ç½²
   - æ”¯æŒA/Bæµ‹è¯•å’Œç°åº¦å‘å¸ƒ

4. **æ•°æ®ä¸€è‡´æ€§ä¿éšœ**
   - å»ºç«‹å¯é çš„äº‹ä»¶æ€»çº¿
   - å®ç°æœ€ç»ˆä¸€è‡´æ€§ä¿è¯
   - æ”¯æŒäº‹ä»¶æº¯æºå’Œå®¡è®¡

5. **æ•…éšœå®¹å¿**
   - å•ç‚¹æ•…éšœä¸å½±å“æ•´ä½“æœåŠ¡
   - è‡ªåŠ¨æ•…éšœæ£€æµ‹å’Œæ¢å¤
   - å®ç°ä¼˜é›…é™çº§å’Œç†”æ–­

### 2.4 æŠ€æœ¯æŒ‘æˆ˜

1. **å¤æ‚äº‹ä»¶å»ºæ¨¡**
   - é‡‘èäº¤æ˜“äº‹ä»¶å¤æ‚ï¼ŒçŠ¶æ€æœºè®¾è®¡å›°éš¾
   - éœ€è¦æ”¯æŒå¤šç§äº‹ä»¶æ¨¡å¼ï¼ˆå‘å¸ƒè®¢é˜…ã€ç‚¹å¯¹ç‚¹ã€å¹¿æ’­ï¼‰
   - äº‹ä»¶ç‰ˆæœ¬æ¼”è¿›å’Œå‘åå…¼å®¹

2. **é«˜å¯é æ¶ˆæ¯ä¼ è¾“**
   - é‡‘èåœºæ™¯è¦æ±‚æ¶ˆæ¯100%ä¸ä¸¢å¤±
   - éœ€è¦æ”¯æŒæ¶ˆæ¯é¡ºåºå’Œå¹‚ç­‰æ€§
   - é«˜å¹¶å‘ä¸‹çš„ä½å»¶è¿Ÿä¿è¯

3. **æ•°æ®ä¸€è‡´æ€§ä¿éšœ**
   - åˆ†å¸ƒå¼äº‹åŠ¡çš„æœ€ç»ˆä¸€è‡´æ€§
   - æ¶ˆæ¯ç”Ÿäº§å’Œæ¶ˆè´¹çš„å¯é æ€§
   - å¼‚å¸¸åœºæ™¯çš„æ•°æ®è¡¥å¿æœºåˆ¶

4. **ç³»ç»Ÿå¯è§‚æµ‹æ€§**
   - å¼‚æ­¥é“¾è·¯è¿½è¸ªå›°éš¾
   - éœ€è¦å®æ—¶ç›‘æ§å’Œå‘Šè­¦
   - äº‹ä»¶æµçš„å¯è§†åŒ–å±•ç¤º

5. **å®‰å…¨åˆè§„**
   - é‡‘èæ•°æ®åŠ å¯†ä¼ è¾“
   - äº‹ä»¶è®¿é—®æƒé™æ§åˆ¶
   - å®Œæ•´çš„å®¡è®¡æ—¥å¿—

### 2.5 è§£å†³æ–¹æ¡ˆ

**æŠ€æœ¯æ¶æ„**ï¼š
- æ¶ˆæ¯ä¸­é—´ä»¶ï¼šApache Kafkaé›†ç¾¤ï¼ˆ5èŠ‚ç‚¹ï¼‰
- äº‹ä»¶å¹³å°ï¼šAsyncAPI + Schema Registry
- æµå¤„ç†ï¼šApache Flinkå®æ—¶å¤„ç†
- ç›‘æ§ï¼šPrometheus + Grafana + Jaeger

### 2.6 å®Œæ•´ä»£ç å®ç°

```python
#!/usr/bin/env python3
"""
AsyncAPI Schemaå®Œæ•´å®ç°
æ’ä¿¡é‡‘èäº‹ä»¶é©±åŠ¨æ¶æ„ç³»ç»Ÿ
"""

import json
import yaml
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import asyncio
from kafka import KafkaProducer, KafkaConsumer
from jsonschema import validate, ValidationError, Draft7Validator
import hashlib
import threading
from collections import defaultdict


class EventType(str, Enum):
    """äº‹ä»¶ç±»å‹"""
    TRANSACTION_CREATED = "TransactionCreated"
    TRANSACTION_APPROVED = "TransactionApproved"
    TRANSACTION_REJECTED = "TransactionRejected"
    TRANSACTION_COMPLETED = "TransactionCompleted"
    RISK_CHECK_PASSED = "RiskCheckPassed"
    RISK_CHECK_FAILED = "RiskCheckFailed"
    ACCOUNT_DEBITED = "AccountDebited"
    ACCOUNT_CREDITED = "AccountCredited"
    NOTIFICATION_SENT = "NotificationSent"


class ChannelType(str, Enum):
    """é€šé“ç±»å‹"""
    KAFKA = "kafka"
    MQTT = "mqtt"
    WEBSOCKET = "websocket"
    HTTP = "http"


@dataclass
class AsyncAPIMessage:
    """AsyncAPIæ¶ˆæ¯å®šä¹‰"""
    message_id: str
    message_name: str
    content_type: str
    schema: Dict[str, Any]
    examples: List[Dict] = field(default_factory=list)
    description: str = ""


@dataclass
class AsyncAPIChannel:
    """AsyncAPIé€šé“å®šä¹‰"""
    channel_name: str
    channel_type: ChannelType
    description: str
    publish_message: Optional[AsyncAPIMessage] = None
    subscribe_message: Optional[AsyncAPIMessage] = None
    bindings: Dict[str, Any] = field(default_factory=dict)


@dataclass
class AsyncAPISchema:
    """AsyncAPI Schemaå®šä¹‰"""
    asyncapi_version: str
    info: Dict[str, Any]
    servers: Dict[str, Any]
    channels: Dict[str, AsyncAPIChannel]
    components: Dict[str, Any]


class AsyncAPIGenerator:
    """AsyncAPIæ–‡æ¡£ç”Ÿæˆå™¨"""
    
    def __init__(self, title: str, version: str):
        self.title = title
        self.version = version
        self.channels: Dict[str, AsyncAPIChannel] = {}
        self.schemas: Dict[str, Dict] = {}
        
    def add_channel(self, channel: AsyncAPIChannel):
        """æ·»åŠ é€šé“"""
        self.channels[channel.channel_name] = channel
        
    def add_schema(self, name: str, schema: Dict):
        """æ·»åŠ Schema"""
        self.schemas[name] = schema
    
    def generate_spec(self) -> Dict:
        """ç”ŸæˆAsyncAPIè§„èŒƒæ–‡æ¡£"""
        spec = {
            "asyncapi": "2.6.0",
            "info": {
                "title": self.title,
                "version": self.version,
                "description": f"{self.title} AsyncAPI Specification"
            },
            "servers": {
                "production": {
                    "url": "kafka://kafka.hengxin.com:9092",
                    "protocol": "kafka",
                    "description": "ç”Ÿäº§ç¯å¢ƒKafkaé›†ç¾¤"
                },
                "staging": {
                    "url": "kafka://kafka-staging.hengxin.com:9092",
                    "protocol": "kafka",
                    "description": "æµ‹è¯•ç¯å¢ƒKafkaé›†ç¾¤"
                }
            },
            "channels": {},
            "components": {
                "schemas": self.schemas,
                "messages": {}
            }
        }
        
        for channel_name, channel in self.channels.items():
            channel_spec = {
                "description": channel.description
            }
            
            if channel.publish_message:
                channel_spec["publish"] = {
                    "message": {
                        "$ref": f"#/components/messages/{channel.publish_message.message_name}"
                    }
                }
                spec["components"]["messages"][channel.publish_message.message_name] = {
                    "name": channel.publish_message.message_name,
                    "contentType": channel.publish_message.content_type,
                    "payload": {
                        "$ref": f"#/components/schemas/{channel.publish_message.message_name}Payload"
                    },
                    "examples": channel.publish_message.examples
                }
            
            if channel.subscribe_message:
                channel_spec["subscribe"] = {
                    "message": {
                        "$ref": f"#/components/messages/{channel.subscribe_message.message_name}"
                    }
                }
            
            if channel.bindings:
                channel_spec["bindings"] = channel.bindings
            
            spec["channels"][channel_name] = channel_spec
        
        return spec
    
    def to_yaml(self) -> str:
        """å¯¼å‡ºä¸ºYAMLæ ¼å¼"""
        return yaml.dump(self.generate_spec(), sort_keys=False, allow_unicode=True)
    
    def to_json(self) -> str:
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        return json.dumps(self.generate_spec(), indent=2, ensure_ascii=False)


class AsyncAPIValidator:
    """AsyncAPIæ¶ˆæ¯éªŒè¯å™¨"""
    
    def __init__(self, asyncapi_spec: Dict):
        self.spec = asyncapi_spec
        self.validators: Dict[str, Draft7Validator] = {}
        self._compile_validators()
    
    def _compile_validators(self):
        """ç¼–è¯‘éªŒè¯å™¨"""
        schemas = self.spec.get("components", {}).get("schemas", {})
        for schema_name, schema in schemas.items():
            try:
                self.validators[schema_name] = Draft7Validator(schema)
            except Exception as e:
                print(f"Error compiling schema {schema_name}: {e}")
    
    def validate_message(self, channel_name: str, message: Dict, operation: str = "publish") -> Dict:
        """éªŒè¯æ¶ˆæ¯"""
        channel = self.spec.get("channels", {}).get(channel_name)
        if not channel:
            return {"valid": False, "error": f"Channel {channel_name} not found"}
        
        op_config = channel.get(operation, {})
        message_ref = op_config.get("message", {}).get("$ref", "")
        
        if not message_ref:
            return {"valid": False, "error": "Message reference not found"}
        
        # æå–æ¶ˆæ¯åç§°
        message_name = message_ref.split("/")[-1]
        payload_schema_name = f"{message_name}Payload"
        
        validator = self.validators.get(payload_schema_name)
        if not validator:
            return {"valid": False, "error": f"Validator for {payload_schema_name} not found"}
        
        errors = []
        try:
            validator.validate(message)
            return {"valid": True, "errors": []}
        except ValidationError as e:
            errors.append({"path": list(e.path), "message": e.message})
            for error in validator.iter_errors(message):
                if error != e:
                    errors.append({"path": list(error.path), "message": error.message})
            return {"valid": False, "errors": errors}


class AsyncAPIEventPublisher:
    """AsyncAPIäº‹ä»¶å‘å¸ƒå™¨"""
    
    def __init__(self, asyncapi_spec_path: str, kafka_servers: List[str]):
        with open(asyncapi_spec_path, 'r') as f:
            self.spec = yaml.safe_load(f)
        
        self.validator = AsyncAPIValidator(self.spec)
        self.producer = KafkaProducer(
            bootstrap_servers=kafka_servers,
            value_serializer=lambda v: json.dumps(v, ensure_ascii=False).encode('utf-8'),
            key_serializer=lambda k: k.encode('utf-8') if k else None,
            acks='all',  # ç¡®ä¿æ¶ˆæ¯ä¸ä¸¢å¤±
            retries=3,
            max_in_flight_requests_per_connection=1  # ä¿è¯æ¶ˆæ¯é¡ºåº
        )
        
    def publish_event(self, channel: str, event_type: str, payload: Dict, 
                     key: Optional[str] = None, headers: Optional[Dict] = None) -> Dict:
        """å‘å¸ƒäº‹ä»¶"""
        # éªŒè¯æ¶ˆæ¯
        validation_result = self.validator.validate_message(channel, payload)
        if not validation_result["valid"]:
            return {
                "success": False,
                "error": "Validation failed",
                "details": validation_result["errors"]
            }
        
        # è·å–é€šé“é…ç½®
        channel_config = self.spec.get("channels", {}).get(channel, {})
        bindings = channel_config.get("bindings", {}).get("kafka", {})
        topic = bindings.get("topic", channel.replace("/", "."))
        
        # æ„å»ºæ¶ˆæ¯
        message = {
            "event_type": event_type,
            "version": "1.0",
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "payload": payload,
            "metadata": {
                "correlation_id": headers.get("correlation_id") if headers else None,
                "source": headers.get("source") if headers else "unknown"
            }
        }
        
        try:
            # å‘é€æ¶ˆæ¯
            future = self.producer.send(
                topic,
                value=message,
                key=key.encode('utf-8') if key else None,
                headers=[(k, v.encode('utf-8')) for k, v in (headers or {}).items()]
            )
            record_metadata = future.get(timeout=10)
            
            return {
                "success": True,
                "topic": record_metadata.topic,
                "partition": record_metadata.partition,
                "offset": record_metadata.offset
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def publish_transaction_created(self, transaction_id: str, user_id: str, 
                                   amount: float, currency: str) -> Dict:
        """å‘å¸ƒäº¤æ˜“åˆ›å»ºäº‹ä»¶"""
        payload = {
            "transactionId": transaction_id,
            "userId": user_id,
            "amount": amount,
            "currency": currency,
            "status": "PENDING",
            "createdAt": datetime.utcnow().isoformat() + "Z"
        }
        
        return self.publish_event(
            channel="transaction/events",
            event_type=EventType.TRANSACTION_CREATED,
            payload=payload,
            key=transaction_id,
            headers={
                "correlation_id": transaction_id,
                "source": "transaction-service"
            }
        )
    
    def close(self):
        """å…³é—­å‘å¸ƒå™¨"""
        self.producer.flush()
        self.producer.close()


class AsyncAPIEventConsumer:
    """AsyncAPIäº‹ä»¶æ¶ˆè´¹è€…"""
    
    def __init__(self, kafka_servers: List[str], group_id: str):
        self.consumer = KafkaConsumer(
            bootstrap_servers=kafka_servers,
            group_id=group_id,
            auto_offset_reset='earliest',
            enable_auto_commit=False,  # æ‰‹åŠ¨æäº¤offset
            value_deserializer=lambda v: json.loads(v.decode('utf-8'))
        )
        self.handlers: Dict[str, List[Callable]] = defaultdict(list)
        self.running = False
    
    def subscribe(self, topic: str, event_type: Optional[str] = None):
        """è®¢é˜…è£…é¥°å™¨"""
        def decorator(func: Callable):
            key = f"{topic}:{event_type}" if event_type else topic
            self.handlers[key].append(func)
            return func
        return decorator
    
    def start_consuming(self, topics: List[str]):
        """å¼€å§‹æ¶ˆè´¹"""
        self.consumer.subscribe(topics)
        self.running = True
        
        while self.running:
            try:
                messages = self.consumer.poll(timeout_ms=1000)
                for topic_partition, msgs in messages.items():
                    for msg in msgs:
                        self._process_message(msg)
                
                # æ‰‹åŠ¨æäº¤offset
                self.consumer.commit()
            except Exception as e:
                print(f"Error consuming message: {e}")
    
    def _process_message(self, msg):
        """å¤„ç†æ¶ˆæ¯"""
        try:
            data = msg.value
            event_type = data.get("event_type")
            topic = msg.topic
            
            # æŸ¥æ‰¾åŒ¹é…çš„å¤„ç†å™¨
            keys = [
                f"{topic}:{event_type}",
                topic
            ]
            
            for key in keys:
                handlers = self.handlers.get(key, [])
                for handler in handlers:
                    try:
                        handler(data)
                    except Exception as e:
                        print(f"Handler error: {e}")
        except Exception as e:
            print(f"Message processing error: {e}")
    
    def stop(self):
        """åœæ­¢æ¶ˆè´¹"""
        self.running = False
        self.consumer.close()


def create_financial_asyncapi_spec():
    """åˆ›å»ºé‡‘èä¸šåŠ¡AsyncAPIè§„èŒƒ"""
    generator = AsyncAPIGenerator("æ’ä¿¡é‡‘èäº‹ä»¶å¹³å°", "1.0.0")
    
    # å®šä¹‰äº¤æ˜“äº‹ä»¶Schema
    transaction_created_schema = {
        "type": "object",
        "required": ["transactionId", "userId", "amount", "currency", "status"],
        "properties": {
            "transactionId": {
                "type": "string",
                "description": "äº¤æ˜“ID",
                "pattern": "^TXN[0-9]{16}$"
            },
            "userId": {
                "type": "string",
                "description": "ç”¨æˆ·ID"
            },
            "amount": {
                "type": "number",
                "description": "äº¤æ˜“é‡‘é¢",
                "minimum": 0.01
            },
            "currency": {
                "type": "string",
                "description": "å¸ç§",
                "enum": ["CNY", "USD", "EUR"]
            },
            "status": {
                "type": "string",
                "enum": ["PENDING", "PROCESSING", "COMPLETED", "FAILED"]
            },
            "createdAt": {
                "type": "string",
                "format": "date-time"
            }
        }
    }
    generator.add_schema("TransactionCreatedPayload", transaction_created_schema)
    
    # åˆ›å»ºäº¤æ˜“äº‹ä»¶é€šé“
    transaction_channel = AsyncAPIChannel(
        channel_name="transaction/events",
        channel_type=ChannelType.KAFKA,
        description="äº¤æ˜“äº‹ä»¶é€šé“",
        publish_message=AsyncAPIMessage(
            message_id="MSG-001",
            message_name="TransactionCreated",
            content_type="application/json",
            schema=transaction_created_schema,
            examples=[{
                "transactionId": "TXN2025011500001234",
                "userId": "USR12345678",
                "amount": 1000.00,
                "currency": "CNY",
                "status": "PENDING",
                "createdAt": "2025-01-15T10:30:00Z"
            }]
        ),
        bindings={
            "kafka": {
                "topic": "transaction.events",
                "partitions": 12,
                "replicationFactor": 3
            }
        }
    )
    generator.add_channel(transaction_channel)
    
    # å®šä¹‰é£æ§äº‹ä»¶Schema
    risk_check_schema = {
        "type": "object",
        "required": ["transactionId", "riskLevel", "decision"],
        "properties": {
            "transactionId": {"type": "string"},
            "riskLevel": {
                "type": "string",
                "enum": ["LOW", "MEDIUM", "HIGH", "CRITICAL"]
            },
            "decision": {
                "type": "string",
                "enum": ["PASS", "REJECT", "REVIEW"]
            },
            "riskFactors": {
                "type": "array",
                "items": {"type": "string"}
            }
        }
    }
    generator.add_schema("RiskCheckCompletedPayload", risk_check_schema)
    
    # åˆ›å»ºé£æ§äº‹ä»¶é€šé“
    risk_channel = AsyncAPIChannel(
        channel_name="risk/events",
        channel_type=ChannelType.KAFKA,
        description="é£æ§äº‹ä»¶é€šé“",
        publish_message=AsyncAPIMessage(
            message_id="MSG-002",
            message_name="RiskCheckCompleted",
            content_type="application/json",
            schema=risk_check_schema
        ),
        bindings={
            "kafka": {
                "topic": "risk.events",
                "partitions": 6
            }
        }
    )
    generator.add_channel(risk_channel)
    
    return generator


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # åˆ›å»ºAsyncAPIè§„èŒƒ
    generator = create_financial_asyncapi_spec()
    
    print("=" * 60)
    print("ã€æ’ä¿¡é‡‘èAsyncAPIè§„èŒƒã€‘")
    print("=" * 60)
    
    # è¾“å‡ºYAMLæ ¼å¼
    yaml_spec = generator.to_yaml()
    print("\nğŸ“„ AsyncAPI YAMLè§„èŒƒ:")
    print("-" * 40)
    print(yaml_spec[:2000] + "...")
    
    # è¾“å‡ºJSONæ ¼å¼
    json_spec = generator.to_json()
    print("\nğŸ“„ AsyncAPI JSONè§„èŒƒé•¿åº¦:", len(json_spec), "å­—ç¬¦")
    
    # æ¼”ç¤ºäº‹ä»¶å‘å¸ƒ
    print("\nğŸ“¨ äº‹ä»¶å‘å¸ƒæ¼”ç¤º:")
    print("-" * 40)
    
    # ä¿å­˜è§„èŒƒåˆ°æ–‡ä»¶
    with open("hengxin-asyncapi.yaml", "w") as f:
        f.write(yaml_spec)
    print("âœ… AsyncAPIè§„èŒƒå·²ä¿å­˜åˆ° hengxin-asyncapi.yaml")
    
    print("\n" + "=" * 60)
```

### 2.7 æ•ˆæœè¯„ä¼°ä¸ROI

**å…³é”®ç»©æ•ˆæŒ‡æ ‡æ”¹è¿›**ï¼š

| æŒ‡æ ‡ | æ”¹è¿›å‰ | æ”¹è¿›å | æå‡å¹…åº¦ |
|------|--------|--------|----------|
| ç³»ç»Ÿè€¦åˆåº¦ | é«˜è€¦åˆ | æ¾è€¦åˆ | æ˜¾è‘—æå‡ |
| äº¤æ˜“å“åº”æ—¶é—´ | 1500ms | 180ms | 88%æå‡ |
| ç³»ç»Ÿå¯ç”¨æ€§ | 99.5% | 99.99% | +0.49% |
| å³°å€¼TPS | 50,000 | 500,000 | 10å€ |
| å‘å¸ƒå‘¨æœŸ | 2å‘¨ | 2å¤© | 7å€æé€Ÿ |
| æ•…éšœæ¢å¤æ—¶é—´ | 30åˆ†é’Ÿ | 3åˆ†é’Ÿ | 90%æå‡ |

**ROIè®¡ç®—**ï¼š

```
é¡¹ç›®æŠ•èµ„ï¼š680ä¸‡å…ƒ
  - åŸºç¡€è®¾æ–½ï¼š280ä¸‡å…ƒ
  - è½¯ä»¶å¼€å‘ï¼š250ä¸‡å…ƒ
  - å®æ–½å’¨è¯¢ï¼š150ä¸‡å…ƒ

å¹´åº¦æ”¶ç›Šï¼š3,200ä¸‡å…ƒ
  - æ€§èƒ½æå‡å¸¦æ¥çš„ä¸šåŠ¡å¢é•¿ï¼š1,500ä¸‡å…ƒ
  - è¿ç»´æˆæœ¬é™ä½ï¼š800ä¸‡å…ƒ
  - å¼€å‘æ•ˆç‡æå‡ï¼š900ä¸‡å…ƒ

ç¬¬ä¸€å¹´ROI = (3,200 - 680) / 680 = 371%
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `04_Transformation.md` - è½¬æ¢ä½“ç³»

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-02-15
