# é‡‘èç§‘æŠ€Schemaå®è·µæ¡ˆä¾‹

## ğŸ“‘ ç›®å½•

- [é‡‘èç§‘æŠ€Schemaå®è·µæ¡ˆä¾‹](#é‡‘èç§‘æŠ€schemaå®è·µæ¡ˆä¾‹)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¡ˆä¾‹æ¦‚è¿°](#1-æ¡ˆä¾‹æ¦‚è¿°)
  - [2. æ¡ˆä¾‹1ï¼šæ™ºèƒ½é£æ§ä¸åæ¬ºè¯ˆç³»ç»Ÿ](#2-æ¡ˆä¾‹1æ™ºèƒ½é£æ§ä¸åæ¬ºè¯ˆç³»ç»Ÿ)
    - [2.1 ä¼ä¸šèƒŒæ™¯](#21-ä¼ä¸šèƒŒæ™¯)
    - [2.2 ä¸šåŠ¡ç—›ç‚¹](#22-ä¸šåŠ¡ç—›ç‚¹)
    - [2.3 ä¸šåŠ¡ç›®æ ‡](#23-ä¸šåŠ¡ç›®æ ‡)
    - [2.4 æŠ€æœ¯æŒ‘æˆ˜](#24-æŠ€æœ¯æŒ‘æˆ˜)
    - [2.5 å®Œæ•´ä»£ç å®ç°](#25-å®Œæ•´ä»£ç å®ç°)
    - [2.6 æ•ˆæœè¯„ä¼°ä¸ROI](#26-æ•ˆæœè¯„ä¼°ä¸roi)
  - [3. æ¡ˆä¾‹2ï¼šé‡åŒ–äº¤æ˜“ç³»ç»Ÿ](#3-æ¡ˆä¾‹2é‡åŒ–äº¤æ˜“ç³»ç»Ÿ)
    - [3.1 ä¼ä¸šèƒŒæ™¯](#31-ä¼ä¸šèƒŒæ™¯)
    - [3.2 æŠ€æœ¯æŒ‘æˆ˜](#32-æŠ€æœ¯æŒ‘æˆ˜)
    - [3.3 å®Œæ•´ä»£ç å®ç°](#33-å®Œæ•´ä»£ç å®ç°)
    - [3.4 æ•ˆæœè¯„ä¼°ä¸ROI](#34-æ•ˆæœè¯„ä¼°ä¸roi)
  - [4. æ¡ˆä¾‹3ï¼šåŒºå—é“¾ä¾›åº”é“¾é‡‘èå¹³å°](#4-æ¡ˆä¾‹3åŒºå—é“¾ä¾›åº”é“¾é‡‘èå¹³å°)
  - [5. æ¡ˆä¾‹æ€»ç»“](#5-æ¡ˆä¾‹æ€»ç»“)

---

## 1. æ¡ˆä¾‹æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›**é‡‘èç§‘æŠ€Schemaçš„å®é™…åº”ç”¨æ¡ˆä¾‹**ï¼Œæ¶µç›–æ™ºèƒ½é£æ§ã€é‡åŒ–äº¤æ˜“ã€åŒºå—é“¾é‡‘èã€æ™ºèƒ½æŠ•é¡¾ç­‰é¢†åŸŸã€‚é‡‘èç§‘æŠ€é€šè¿‡æŠ€æœ¯åˆ›æ–°æå‡é‡‘èæœåŠ¡æ•ˆç‡ã€é™ä½é£é™©ã€åˆ›é€ æ–°å•†ä¸šæ¨¡å¼ã€‚

**æ¡ˆä¾‹ç±»å‹**ï¼š

- æ™ºèƒ½é£æ§ä¸åæ¬ºè¯ˆç³»ç»Ÿ
- é‡åŒ–äº¤æ˜“ç³»ç»Ÿ
- åŒºå—é“¾ä¾›åº”é“¾é‡‘èå¹³å°

---

## 2. æ¡ˆä¾‹1ï¼šæ™ºèƒ½é£æ§ä¸åæ¬ºè¯ˆç³»ç»Ÿ

### 2.1 ä¼ä¸šèƒŒæ™¯

**ä¼ä¸šèƒŒæ™¯**ï¼š
æŸå¤´éƒ¨æ¶ˆè´¹é‡‘èå…¬å¸ï¼ˆä»¥ä¸‹ç®€ç§°"FinCredit"ï¼‰æˆç«‹äº2015å¹´ï¼Œä¸“æ³¨äºä¸ºå¹´è½»ç¾¤ä½“æä¾›æ¶ˆè´¹ä¿¡è´·æœåŠ¡ã€‚å…¬å¸ç´¯è®¡æ³¨å†Œç”¨æˆ·è¶…è¿‡8000ä¸‡ï¼Œæœˆå‡æ”¾è´·é‡‘é¢è¶…è¿‡100äº¿å…ƒï¼Œä¸šåŠ¡è¦†ç›–å…¨å›½300+åŸå¸‚ã€‚

éšç€ä¸šåŠ¡è§„æ¨¡å¿«é€Ÿæ‰©å¼ ï¼Œå…¬å¸é¢ä¸´æ—¥ç›Šä¸¥å³»çš„æ¬ºè¯ˆé£é™©å’Œä¿¡ç”¨é£é™©æŒ‘æˆ˜ã€‚ä¼ ç»Ÿé£æ§è§„åˆ™å¼•æ“éš¾ä»¥åº”å¯¹æ–°å‹æ¬ºè¯ˆæ‰‹æ®µï¼Œåè´¦ç‡æŒç»­ä¸Šå‡ï¼Œè¿«åˆ‡éœ€è¦æ„å»ºæ™ºèƒ½åŒ–çš„é£æ§ä½“ç³»ã€‚

### 2.2 ä¸šåŠ¡ç—›ç‚¹

1. **æ¬ºè¯ˆæŸå¤±ä¸¥é‡**ï¼š2022å¹´å› æ¬ºè¯ˆå¯¼è‡´çš„ç›´æ¥æŸå¤±è¶…è¿‡3.5äº¿å…ƒï¼Œæ¬ºè¯ˆäº¤æ˜“å æ¯”è¾¾0.8%ã€‚

2. **æ–°å‹æ¬ºè¯ˆæ‰‹æ®µå±‚å‡ºä¸ç©·**ï¼šå›¢ä¼™æ¬ºè¯ˆã€è®¾å¤‡å†œåœºã€èº«ä»½å†’ç”¨ç­‰æ–°å‹æ¬ºè¯ˆæ‰‹æ®µå¿«é€Ÿæ¼”å˜ï¼Œè§„åˆ™åº“éš¾ä»¥åŠæ—¶æ›´æ–°ã€‚

3. **å®¡æ‰¹æ•ˆç‡ä½ä¸‹**ï¼šäººå·¥å®¡æ ¸å æ¯”30%ï¼Œå¹³å‡å®¡æ‰¹æ—¶é—´4å°æ—¶ï¼Œå®¢æˆ·ä½“éªŒå·®ï¼Œè½¬åŒ–ç‡ä½ã€‚

4. **è¯¯æ€ç‡é«˜**ï¼šä¿å®ˆçš„é£æ§ç­–ç•¥å¯¼è‡´8%çš„æ­£å¸¸ç”³è¯·è¢«è¯¯åˆ¤æ‹’ç»ï¼Œå¹´æŸå¤±æ½œåœ¨æ”¶å…¥çº¦5äº¿å…ƒã€‚

5. **ç›‘ç®¡åˆè§„å‹åŠ›**ï¼šç›‘ç®¡è¦æ±‚åŠ å¼ºé£æ§é€æ˜åº¦ï¼Œä¼ ç»Ÿé»‘ç›’æ¨¡å‹éš¾ä»¥æ»¡è¶³å¯è§£é‡Šæ€§è¦æ±‚ã€‚

### 2.3 ä¸šåŠ¡ç›®æ ‡

1. **é™ä½æ¬ºè¯ˆæŸå¤±**ï¼šå°†æ¬ºè¯ˆæŸå¤±ç‡ä»0.8%é™è‡³0.2%ä»¥ä¸‹ï¼Œå¹´å‡å°‘æŸå¤±2.5äº¿å…ƒã€‚

2. **æå‡å®¡æ‰¹æ•ˆç‡**ï¼šå®ç°90%ç”³è¯·è‡ªåŠ¨å®¡æ‰¹ï¼Œå¹³å‡å®¡æ‰¹æ—¶é—´ç¼©çŸ­è‡³5åˆ†é’Ÿã€‚

3. **é™ä½è¯¯æ€ç‡**ï¼šå°†æ­£å¸¸ç”¨æˆ·è¯¯æ‹’ç‡ä»8%é™è‡³2%ä»¥ä¸‹ã€‚

4. **å¢å¼ºå¯è§£é‡Šæ€§**ï¼šå®ç°æ¨¡å‹å†³ç­–å¯è¿½æº¯ã€å¯è§£é‡Šï¼Œæ»¡è¶³ç›‘ç®¡è¦æ±‚ã€‚

5. **å®æ—¶é£æ§èƒ½åŠ›**ï¼šæ„å»ºæ¯«ç§’çº§å“åº”çš„å®æ—¶é£æ§å¼•æ“ã€‚

### 2.4 æŠ€æœ¯æŒ‘æˆ˜

1. **é«˜å¹¶å‘ä½å»¶è¿Ÿ**ï¼šæ—¥å³°å€¼QPSè¶…è¿‡50ä¸‡ï¼Œé£æ§å†³ç­–å»¶è¿Ÿéœ€æ§åˆ¶åœ¨50msä»¥å†…ã€‚

2. **ç‰¹å¾å·¥ç¨‹å¤æ‚**ï¼šéœ€è¦æ•´åˆå¤šæºå¼‚æ„æ•°æ®ï¼Œæ„å»ºä¸‡çº§ç‰¹å¾ä½“ç³»ã€‚

3. **æ ·æœ¬ä¸å¹³è¡¡**ï¼šæ¬ºè¯ˆæ ·æœ¬å æ¯”æä½ï¼ˆ<1%ï¼‰ï¼Œæ¨¡å‹è®­ç»ƒå›°éš¾ã€‚

4. **å¯¹æŠ—æ€§æ”»å‡»**ï¼šé»‘äº§æŒç»­æ”»å‡»æ¨¡å‹ï¼Œéœ€è¦å…·å¤‡å¯¹æŠ—é²æ£’æ€§ã€‚

5. **æ•°æ®éšç§ä¿æŠ¤**ï¼šåœ¨è”é‚¦å­¦ä¹ åœºæ™¯ä¸‹ä¿æŠ¤ç”¨æˆ·éšç§ã€‚

### 2.5 å®Œæ•´ä»£ç å®ç°

```python
#!/usr/bin/env python3
"""
æ™ºèƒ½é£æ§ä¸åæ¬ºè¯ˆç³»ç»Ÿ
FinCredit å®æ—¶é£æ§å¼•æ“

åŠŸèƒ½æ¨¡å—ï¼š
1. å®æ—¶ç‰¹å¾è®¡ç®—å¼•æ“
2. æœºå™¨å­¦ä¹ é£æ§æ¨¡å‹
3. è§„åˆ™å¼•æ“ä¸ç­–ç•¥ç¼–æ’
4. å›¾ç¥ç»ç½‘ç»œæ¬ºè¯ˆæ£€æµ‹
5. å¯è§£é‡Šæ€§åˆ†æ

æŠ€æœ¯æ ˆï¼šPython + Redis + Kafka + TensorFlow + Neo4j

ä½œè€…ï¼šé£æ§ç®—æ³•å›¢é˜Ÿ
ç‰ˆæœ¬ï¼š3.0
"""

import json
import hashlib
import redis
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
from enum import Enum
import tensorflow as tf
from sklearn.ensemble import GradientBoostingClassifier, IsolationForest
from sklearn.preprocessing import StandardScaler
import networkx as nx
import logging
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RiskLevel(Enum):
    """é£é™©ç­‰çº§"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class DecisionAction(Enum):
    """å†³ç­–åŠ¨ä½œ"""
    APPROVE = "approve"
    REVIEW = "manual_review"
    REJECT = "reject"
    ENHANCED_VERIFY = "enhanced_verification"


@dataclass
class Application:
    """è´·æ¬¾ç”³è¯·"""
    app_id: str
    user_id: str
    apply_time: datetime
    
    # ç”³è¯·ä¿¡æ¯
    amount: float
    term: int
    purpose: str
    
    # è®¾å¤‡ä¿¡æ¯
    device_id: str
    ip_address: str
    gps_location: Optional[Tuple[float, float]] = None
    
    # ç”¨æˆ·ä¿¡æ¯
    id_number: str
    phone: str
    contact_list: List[str] = field(default_factory=list)


@dataclass
class RiskFeature:
    """é£é™©ç‰¹å¾"""
    feature_id: str
    name: str
    value: Any
    category: str  # user, device, behavior, relation
    weight: float = 1.0


@dataclass
class RiskDecision:
    """é£æ§å†³ç­–"""
    app_id: str
    decision: DecisionAction
    risk_level: RiskLevel
    risk_score: float
    
    # å†³ç­–è¯¦æƒ…
    rule_hits: List[str] = field(default_factory=list)
    model_scores: Dict[str, float] = field(default_factory=dict)
    feature_importance: Dict[str, float] = field(default_factory=dict)
    
    # è§£é‡Š
    explanation: str = ""
    processing_time_ms: float = 0.0


class FeatureEngine:
    """ç‰¹å¾å¼•æ“"""
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
        self.feature_cache_ttl = 3600  # 1å°æ—¶
        
    def extract_features(self, app: Application) -> List[RiskFeature]:
        """æå–ç‰¹å¾"""
        features = []
        
        # ç”¨æˆ·ç‰¹å¾
        user_features = self._extract_user_features(app)
        features.extend(user_features)
        
        # è®¾å¤‡ç‰¹å¾
        device_features = self._extract_device_features(app)
        features.extend(device_features)
        
        # è¡Œä¸ºç‰¹å¾
        behavior_features = self._extract_behavior_features(app)
        features.extend(behavior_features)
        
        # å…³è”ç‰¹å¾
        relation_features = self._extract_relation_features(app)
        features.extend(relation_features)
        
        return features
    
    def _extract_user_features(self, app: Application) -> List[RiskFeature]:
        """æå–ç”¨æˆ·ç‰¹å¾"""
        features = []
        
        # ç”¨æˆ·å†å²ç”³è¯·æ¬¡æ•°
        cache_key = f"user:apps:{app.user_id}"
        app_count = int(self.redis.get(cache_key) or 0)
        features.append(RiskFeature(
            feature_id="user_app_count",
            name="å†å²ç”³è¯·æ¬¡æ•°",
            value=app_count,
            category="user"
        ))
        
        # èº«ä»½è¯å¹´é¾„ç‰¹å¾
        birth_year = int(app.id_number[6:10])
        age = datetime.now().year - birth_year
        features.append(RiskFeature(
            feature_id="user_age",
            name="ç”¨æˆ·å¹´é¾„",
            value=age,
            category="user"
        ))
        
        # æ‰‹æœºå·ä½¿ç”¨æ—¶é•¿ï¼ˆæ¨¡æ‹Ÿï¼‰
        features.append(RiskFeature(
            feature_id="phone_tenure",
            name="æ‰‹æœºå·ä½¿ç”¨æ—¶é•¿",
            value=np.random.randint(1, 120),  # æœˆ
            category="user"
        ))
        
        return features
    
    def _extract_device_features(self, app: Application) -> List[RiskFeature]:
        """æå–è®¾å¤‡ç‰¹å¾"""
        features = []
        
        # è®¾å¤‡å…³è”ç”¨æˆ·æ•°
        cache_key = f"device:users:{app.device_id}"
        user_count = len(self.redis.smembers(cache_key))
        features.append(RiskFeature(
            feature_id="device_user_count",
            name="è®¾å¤‡å…³è”ç”¨æˆ·æ•°",
            value=user_count,
            category="device"
        ))
        
        # IPå…³è”ç”¨æˆ·æ•°
        cache_key = f"ip:users:{app.ip_address}"
        ip_user_count = len(self.redis.smembers(cache_key))
        features.append(RiskFeature(
            feature_id="ip_user_count",
            name="IPå…³è”ç”¨æˆ·æ•°",
            value=ip_user_count,
            category="device"
        ))
        
        # æ˜¯å¦ä»£ç†IPï¼ˆæ¨¡æ‹Ÿï¼‰
        features.append(RiskFeature(
            feature_id="is_proxy_ip",
            name="æ˜¯å¦ä»£ç†IP",
            value=np.random.random() < 0.05,
            category="device"
        ))
        
        return features
    
    def _extract_behavior_features(self, app: Application) -> List[RiskFeature]:
        """æå–è¡Œä¸ºç‰¹å¾"""
        features = []
        
        # ç”³è¯·æ—¶æ®µ
        hour = app.apply_time.hour
        features.append(RiskFeature(
            feature_id="apply_hour",
            name="ç”³è¯·æ—¶æ®µ",
            value=hour,
            category="behavior"
        ))
        
        # ç”³è¯·é‡‘é¢ä¸æ”¶å…¥æ¯”ï¼ˆæ¨¡æ‹Ÿï¼‰
        features.append(RiskFeature(
            feature_id="amount_income_ratio",
            name="é‡‘é¢æ”¶å…¥æ¯”",
            value=app.amount / max(np.random.normal(8000, 3000), 1000),
            category="behavior"
        ))
        
        return features
    
    def _extract_relation_features(self, app: Application) -> List[RiskFeature]:
        """æå–å…³è”ç‰¹å¾"""
        features = []
        
        # è”ç³»äººå‘½ä¸­é»‘åå•æ¯”ä¾‹
        blacklist_count = sum(1 for phone in app.contact_list 
                            if self.redis.sismember("blacklist:phone", phone))
        blacklist_ratio = blacklist_count / max(len(app.contact_list), 1)
        features.append(RiskFeature(
            feature_id="contact_blacklist_ratio",
            name="è”ç³»äººé»‘åå•æ¯”ä¾‹",
            value=blacklist_ratio,
            category="relation"
        ))
        
        return features
    
    def update_cache(self, app: Application):
        """æ›´æ–°ç¼“å­˜"""
        # æ›´æ–°ç”¨æˆ·ç”³è¯·è®¡æ•°
        cache_key = f"user:apps:{app.user_id}"
        self.redis.incr(cache_key)
        self.redis.expire(cache_key, self.feature_cache_ttl)
        
        # æ›´æ–°è®¾å¤‡å…³è”ç”¨æˆ·
        cache_key = f"device:users:{app.device_id}"
        self.redis.sadd(cache_key, app.user_id)
        
        # æ›´æ–°IPå…³è”ç”¨æˆ·
        cache_key = f"ip:users:{app.ip_address}"
        self.redis.sadd(cache_key, app.user_id)


class RuleEngine:
    """è§„åˆ™å¼•æ“"""
    
    def __init__(self):
        self.rules = []
        self._load_rules()
    
    def _load_rules(self):
        """åŠ è½½è§„åˆ™"""
        # ç¡¬è§„åˆ™ï¼ˆç›´æ¥æ‹’ç»ï¼‰
        self.rules.append({
            'id': 'R001',
            'name': 'é»‘åå•ç”¨æˆ·',
            'condition': lambda f: self._get_feature(f, 'user_in_blacklist') == True,
            'action': DecisionAction.REJECT,
            'risk_level': RiskLevel.CRITICAL,
            'score': 100
        })
        
        # è½¯è§„åˆ™ï¼ˆåŠ åˆ†ï¼‰
        self.rules.append({
            'id': 'R002',
            'name': 'è®¾å¤‡å¤šç”¨æˆ·',
            'condition': lambda f: self._get_feature(f, 'device_user_count') > 5,
            'action': DecisionAction.ENHANCED_VERIFY,
            'risk_level': RiskLevel.HIGH,
            'score': 60
        })
        
        self.rules.append({
            'id': 'R003',
            'name': 'è”ç³»äººé«˜é£é™©',
            'condition': lambda f: self._get_feature(f, 'contact_blacklist_ratio') > 0.3,
            'action': DecisionAction.REVIEW,
            'risk_level': RiskLevel.MEDIUM,
            'score': 40
        })
    
    def _get_feature(self, features: List[RiskFeature], name: str) -> Any:
        """è·å–ç‰¹å¾å€¼"""
        for f in features:
            if f.feature_id == name:
                return f.value
        return None
    
    def evaluate(self, features: List[RiskFeature]) -> Tuple[List[str], float, RiskLevel]:
        """è¯„ä¼°è§„åˆ™"""
        hit_rules = []
        total_score = 0
        max_risk = RiskLevel.LOW
        
        for rule in self.rules:
            try:
                if rule['condition'](features):
                    hit_rules.append(rule['id'])
                    total_score += rule['score']
                    
                    # æ›´æ–°æœ€é«˜é£é™©ç­‰çº§
                    risk_order = [RiskLevel.LOW, RiskLevel.MEDIUM, RiskLevel.HIGH, RiskLevel.CRITICAL]
                    if risk_order.index(rule['risk_level']) > risk_order.index(max_risk):
                        max_risk = rule['risk_level']
            except Exception as e:
                logger.error(f"Rule evaluation error: {e}")
        
        return hit_rules, min(total_score, 100), max_risk


class MLRiskModel:
    """æœºå™¨å­¦ä¹ é£æ§æ¨¡å‹"""
    
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = []
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        # ç®€åŒ–ç‰ˆï¼šä½¿ç”¨GBDTæ¨¡å‹
        self.model = GradientBoostingClassifier(
            n_estimators=100,
            max_depth=5,
            learning_rate=0.1
        )
        
        # å®é™…åº”ä»æ–‡ä»¶åŠ è½½å·²è®­ç»ƒæ¨¡å‹
        logger.info("ML model loaded")
    
    def predict(self, features: List[RiskFeature]) -> Tuple[float, Dict[str, float]]:
        """é¢„æµ‹é£é™©åˆ†æ•°"""
        # ç‰¹å¾å‘é‡åŒ–
        feature_dict = {f.feature_id: f.value for f in features}
        
        # æ¨¡æ‹Ÿæ¨¡å‹é¢„æµ‹ï¼ˆå®é™…åº”ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼‰
        # åŸºäºç‰¹å¾è®¡ç®—é£é™©åˆ†æ•°
        risk_score = 0
        
        if feature_dict.get('device_user_count', 0) > 3:
            risk_score += 20
        
        if feature_dict.get('contact_blacklist_ratio', 0) > 0.2:
            risk_score += 25
        
        if feature_dict.get('is_proxy_ip', False):
            risk_score += 30
        
        if feature_dict.get('user_app_count', 0) > 5:
            risk_score += 10
        
        # å½’ä¸€åŒ–åˆ°0-100
        risk_score = min(risk_score + np.random.randint(-5, 5), 100)
        risk_score = max(risk_score, 0)
        
        # ç‰¹å¾é‡è¦æ€§ï¼ˆç®€åŒ–ï¼‰
        importance = {
            'device_user_count': 0.25,
            'contact_blacklist_ratio': 0.30,
            'is_proxy_ip': 0.35,
            'user_app_count': 0.10
        }
        
        return risk_score / 100, importance


class GraphFraudDetector:
    """å›¾ç¥ç»ç½‘ç»œæ¬ºè¯ˆæ£€æµ‹"""
    
    def __init__(self):
        self.graph = nx.Graph()
    
    def build_graph(self, applications: List[Application]):
        """æ„å»ºå…³è”å›¾è°±"""
        for app in applications:
            # æ·»åŠ èŠ‚ç‚¹
            self.graph.add_node(app.user_id, type='user')
            self.graph.add_node(app.device_id, type='device')
            self.graph.add_node(app.ip_address, type='ip')
            
            # æ·»åŠ è¾¹
            self.graph.add_edge(app.user_id, app.device_id, relation='uses')
            self.graph.add_edge(app.user_id, app.ip_address, relation='access_from')
            
            # è”ç³»äººå…³è”
            for contact in app.contact_list:
                self.graph.add_node(contact, type='phone')
                self.graph.add_edge(app.user_id, contact, relation='contacts')
    
    def detect_fraud_rings(self) -> List[List[str]]:
        """æ£€æµ‹æ¬ºè¯ˆå›¢ä¼™"""
        # å¯»æ‰¾ç´§å¯†è¿æ¥çš„ç¤¾åŒº
        communities = nx.community.greedy_modularity_communities(self.graph)
        
        fraud_rings = []
        for comm in communities:
            # æ£€æŸ¥ç¤¾åŒºç‰¹å¾
            users = [n for n in comm if self.graph.nodes[n].get('type') == 'user']
            devices = [n for n in comm if self.graph.nodes[n].get('type') == 'device']
            
            # å¦‚æœå¤šä¸ªç”¨æˆ·å…±äº«å°‘é‡è®¾å¤‡ï¼Œå¯èƒ½æ˜¯è®¾å¤‡å†œåœº
            if len(users) > 3 and len(devices) < len(users) / 3:
                fraud_rings.append(list(users))
        
        return fraud_rings
    
    def calculate_centrality(self, user_id: str) -> Dict[str, float]:
        """è®¡ç®—ä¸­å¿ƒæ€§æŒ‡æ ‡"""
        if user_id not in self.graph:
            return {}
        
        return {
            'degree': nx.degree_centrality(self.graph).get(user_id, 0),
            'betweenness': nx.betweenness_centrality(self.graph).get(user_id, 0),
            'closeness': nx.closeness_centrality(self.graph).get(user_id, 0)
        }


class RiskDecisionEngine:
    """é£æ§å†³ç­–å¼•æ“"""
    
    def __init__(self, redis_host: str = 'localhost'):
        self.redis = redis.Redis(host=redis_host, decode_responses=True)
        self.feature_engine = FeatureEngine(self.redis)
        self.rule_engine = RuleEngine()
        self.ml_model = MLRiskModel()
        self.graph_detector = GraphFraudDetector()
        
        # å†³ç­–ç­–ç•¥
        self.strategy = {
            'rule_weight': 0.4,
            'ml_weight': 0.6,
            'auto_approve_threshold': 30,
            'manual_review_threshold': 70,
            'reject_threshold': 90
        }
    
    def decide(self, app: Application) -> RiskDecision:
        """é£æ§å†³ç­–"""
        start_time = time.time()
        
        # 1. ç‰¹å¾æå–
        features = self.feature_engine.extract_features(app)
        
        # 2. è§„åˆ™è¯„ä¼°
        rule_hits, rule_score, rule_risk = self.rule_engine.evaluate(features)
        
        # 3. æ¨¡å‹è¯„ä¼°
        ml_score, feature_importance = self.ml_model.predict(features)
        ml_score *= 100
        
        # 4. èåˆåˆ†æ•°
        final_score = (
            rule_score * self.strategy['rule_weight'] +
            ml_score * self.strategy['ml_weight']
        )
        
        # 5. å†³ç­–
        if final_score < self.strategy['auto_approve_threshold']:
            decision = DecisionAction.APPROVE
            risk_level = RiskLevel.LOW
        elif final_score < self.strategy['manual_review_threshold']:
            decision = DecisionAction.REVIEW
            risk_level = RiskLevel.MEDIUM
        elif final_score < self.strategy['reject_threshold']:
            decision = DecisionAction.ENHANCED_VERIFY
            risk_level = RiskLevel.HIGH
        else:
            decision = DecisionAction.REJECT
            risk_level = RiskLevel.CRITICAL
        
        # 6. æ›´æ–°ç¼“å­˜
        self.feature_engine.update_cache(app)
        
        processing_time = (time.time() - start_time) * 1000
        
        # 7. ç”Ÿæˆè§£é‡Š
        explanation = self._generate_explanation(
            app, features, rule_hits, feature_importance
        )
        
        return RiskDecision(
            app_id=app.app_id,
            decision=decision,
            risk_level=risk_level,
            risk_score=final_score,
            rule_hits=rule_hits,
            model_scores={'ml_score': ml_score, 'rule_score': rule_score},
            feature_importance=feature_importance,
            explanation=explanation,
            processing_time_ms=processing_time
        )
    
    def _generate_explanation(self, app: Application, 
                             features: List[RiskFeature],
                             rule_hits: List[str],
                             importance: Dict[str, float]) -> str:
        """ç”Ÿæˆå†³ç­–è§£é‡Š"""
        explanations = []
        
        if rule_hits:
            explanations.append(f"å‘½ä¸­è§„åˆ™: {', '.join(rule_hits)}")
        
        # ä¸»è¦é£é™©å› ç´ 
        top_features = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:3]
        explanations.append("ä¸»è¦é£é™©å› ç´ : " + 
                          ", ".join([f"{k}({v:.0%})" for k, v in top_features]))
        
        return "; ".join(explanations)


# ==================== æ¼”ç¤º ====================

def demo_risk_engine():
    """æ¼”ç¤ºé£æ§å¼•æ“"""
    print("=" * 70)
    print("FinCredit æ™ºèƒ½é£æ§å¼•æ“æ¼”ç¤º")
    print("=" * 70)
    
    # åˆ›å»ºé£æ§å¼•æ“
    engine = RiskDecisionEngine()
    
    # æ¨¡æ‹Ÿç”³è¯·
    test_cases = [
        {
            'name': 'æ­£å¸¸ç”¨æˆ·',
            'device_users': 1,
            'blacklist_ratio': 0,
            'is_proxy': False
        },
        {
            'name': 'å¯ç–‘ç”¨æˆ·',
            'device_users': 8,
            'blacklist_ratio': 0.2,
            'is_proxy': True
        },
        {
            'name': 'é«˜é£é™©ç”¨æˆ·',
            'device_users': 15,
            'blacklist_ratio': 0.5,
            'is_proxy': True
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f"\n--- æµ‹è¯•ç”¨ä¾‹ {i}: {case['name']} ---")
        
        app = Application(
            app_id=f"APP_{i:04d}",
            user_id=f"USER_{i:04d}",
            apply_time=datetime.now(),
            amount=10000,
            term=12,
            purpose="æ¶ˆè´¹",
            device_id=f"DEV_{case['device_users']:03d}",
            ip_address=f"192.168.1.{i}",
            id_number="310101199001011234",
            phone="13800138000",
            contact_list=["13900139000", "13700137000"]
        )
        
        # æ¨¡æ‹Ÿç¼“å­˜æ•°æ®
        engine.redis.set(f"user:apps:{app.user_id}", np.random.randint(0, 10))
        for j in range(case['device_users']):
            engine.redis.sadd(f"device:users:{app.device_id}", f"USER_{j:04d}")
        
        # é£æ§å†³ç­–
        decision = engine.decide(app)
        
        print(f"ç”³è¯·ID: {decision.app_id}")
        print(f"å†³ç­–ç»“æœ: {decision.decision.value}")
        print(f"é£é™©ç­‰çº§: {decision.risk_level.value}")
        print(f"é£é™©åˆ†æ•°: {decision.risk_score:.1f}")
        print(f"å‘½ä¸­è§„åˆ™: {decision.rule_hits}")
        print(f"å¤„ç†æ—¶é—´: {decision.processing_time_ms:.2f}ms")
        print(f"å†³ç­–è§£é‡Š: {decision.explanation}")
    
    print("\n" + "=" * 70)
    print("æ¼”ç¤ºå®Œæˆ")
    print("=" * 70)


if __name__ == "__main__":
    demo_risk_engine()
```

### 2.6 æ•ˆæœè¯„ä¼°ä¸ROI

| æŒ‡æ ‡ | å®æ–½å‰ | å®æ–½å | æå‡å¹…åº¦ |
|------|--------|--------|----------|
| æ¬ºè¯ˆæŸå¤±ç‡ | 0.8% | 0.15% | **81%é™ä½** |
| å®¡æ‰¹æ—¶æ•ˆ | 4å°æ—¶ | 3åˆ†é’Ÿ | **98%ç¼©çŸ­** |
| è‡ªåŠ¨å®¡æ‰¹ç‡ | 70% | 92% | **31%æå‡** |
| è¯¯æ‹’ç‡ | 8% | 1.5% | **81%é™ä½** |
| å®¡æ‰¹äººåŠ› | 200äºº | 30äºº | **85%å‡å°‘** |

**æŠ•èµ„å›æŠ¥ç‡ï¼ˆROIï¼‰**ï¼š

| é¡¹ç›® | å¹´åº¦æˆæœ¬/æ”¶ç›Šï¼ˆä¸‡å…ƒï¼‰ |
|------|-------------------|
| ç³»ç»Ÿå»ºè®¾ | -800 |
| è¿è¥ç»´æŠ¤ | -200 |
| æ¬ºè¯ˆæŸå¤±å‡å°‘ | +2500 |
| äººåŠ›æˆæœ¬èŠ‚çœ | +1200 |
| æ”¶å…¥å¢åŠ ï¼ˆé™ä½è¯¯æ‹’ï¼‰ | +3500 |
| **å¹´åº¦å‡€æ”¶ç›Š** | **+6200** |
| **ROI** | **520%** |

---

## 3. æ¡ˆä¾‹2ï¼šé‡åŒ–äº¤æ˜“ç³»ç»Ÿ

### 3.1 ä¼ä¸šèƒŒæ™¯

æŸç§å‹Ÿé‡åŒ–åŸºé‡‘ï¼ˆQuantAssetï¼‰ç®¡ç†è§„æ¨¡è¶…è¿‡50äº¿å…ƒï¼Œé‡‡ç”¨å¤šç­–ç•¥é‡åŒ–æŠ•èµ„ã€‚éœ€è¦é«˜æ€§èƒ½çš„äº¤æ˜“ç³»ç»Ÿå’Œç­–ç•¥å›æµ‹å¹³å°ã€‚

### 3.2 æŠ€æœ¯æŒ‘æˆ˜

1. **ä½å»¶è¿Ÿäº¤æ˜“**ï¼šè®¢å•å»¶è¿Ÿéœ€æ§åˆ¶åœ¨10å¾®ç§’ä»¥å†…
2. **é«˜é¢‘æ•°æ®å¤„ç†**ï¼šæ¯ç§’å¤„ç†ç™¾ä¸‡çº§è¡Œæƒ…æ•°æ®
3. **ç­–ç•¥å›æµ‹**ï¼šæ”¯æŒ10å¹´å†å²æ•°æ®çš„å¿«é€Ÿå›æµ‹
4. **é£é™©æ§åˆ¶**ï¼šå®æ—¶æŒä»“é£é™©å’Œæ•å£ç›‘æ§

### 3.3 å®Œæ•´ä»£ç å®ç°

```python
#!/usr/bin/env python3
"""
é‡åŒ–äº¤æ˜“ç³»ç»Ÿ
QuantAsset é«˜é¢‘äº¤æ˜“å¼•æ“
"""

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import asyncio


class OrderSide(Enum):
    BUY = "buy"
    SELL = "sell"


class OrderType(Enum):
    MARKET = "market"
    LIMIT = "limit"


@dataclass
class Order:
    """è®¢å•"""
    order_id: str
    symbol: str
    side: OrderSide
    order_type: OrderType
    quantity: int
    price: Optional[float] = None
    timestamp: datetime = None


@dataclass
class Position:
    """æŒä»“"""
    symbol: str
    quantity: int
    avg_cost: float
    market_value: float
    unrealized_pnl: float


class Strategy:
    """ç­–ç•¥åŸºç±»"""
    
    def __init__(self, name: str):
        self.name = name
        self.positions: Dict[str, Position] = {}
        self.cash = 1000000  # åˆå§‹èµ„é‡‘
        
    def on_bar(self, data: pd.DataFrame) -> List[Order]:
        """å¤„ç†Kçº¿æ•°æ®"""
        return []
    
    def on_tick(self, tick: Dict) -> List[Order]:
        """å¤„ç†Tickæ•°æ®"""
        return []


class MovingAverageStrategy(Strategy):
    """å‡çº¿ç­–ç•¥"""
    
    def __init__(self, short_window: int = 20, long_window: int = 50):
        super().__init__("MA_Cross")
        self.short_window = short_window
        self.long_window = long_window
        self.data_buffer: Dict[str, pd.DataFrame] = {}
    
    def on_bar(self, data: pd.DataFrame) -> List[Order]:
        """åŒå‡çº¿äº¤å‰ç­–ç•¥"""
        orders = []
        
        for symbol in data['symbol'].unique():
            symbol_data = data[data['symbol'] == symbol].copy()
            
            if len(symbol_data) < self.long_window:
                continue
            
            # è®¡ç®—å‡çº¿
            symbol_data['ma_short'] = symbol_data['close'].rolling(self.short_window).mean()
            symbol_data['ma_long'] = symbol_data['close'].rolling(self.long_window).mean()
            
            # ç”Ÿæˆä¿¡å·
            latest = symbol_data.iloc[-1]
            prev = symbol_data.iloc[-2] if len(symbol_data) > 1 else latest
            
            # é‡‘å‰ä¹°å…¥
            if prev['ma_short'] <= prev['ma_long'] and latest['ma_short'] > latest['ma_long']:
                if symbol not in self.positions:
                    orders.append(Order(
                        order_id=f"ORD_{datetime.now().timestamp()}",
                        symbol=symbol,
                        side=OrderSide.BUY,
                        order_type=OrderType.MARKET,
                        quantity=100,
                        timestamp=datetime.now()
                    ))
            
            # æ­»å‰å–å‡º
            elif prev['ma_short'] >= prev['ma_long'] and latest['ma_short'] < latest['ma_long']:
                if symbol in self.positions and self.positions[symbol].quantity > 0:
                    orders.append(Order(
                        order_id=f"ORD_{datetime.now().timestamp()}",
                        symbol=symbol,
                        side=OrderSide.SELL,
                        order_type=OrderType.MARKET,
                        quantity=self.positions[symbol].quantity,
                        timestamp=datetime.now()
                    ))
        
        return orders


class BacktestEngine:
    """å›æµ‹å¼•æ“"""
    
    def __init__(self, initial_capital: float = 1000000):
        self.initial_capital = initial_capital
        self.cash = initial_capital
        self.positions: Dict[str, Position] = {}
        self.trades: List[Dict] = []
        self.daily_pnl: List[Dict] = []
    
    def run(self, strategy: Strategy, data: pd.DataFrame) -> Dict:
        """è¿è¡Œå›æµ‹"""
        # æŒ‰æ—¥æœŸåˆ†ç»„
        dates = data['date'].unique()
        
        for date in dates:
            day_data = data[data['date'] == date]
            
            # æ‰§è¡Œç­–ç•¥
            orders = strategy.on_bar(day_data)
            
            # æ¨¡æ‹Ÿæˆäº¤
            for order in orders:
                self._execute_order(order, day_data)
            
            # è®¡ç®—æ—¥æ”¶ç›Š
            self._calculate_daily_pnl(date, day_data)
        
        return self._generate_report()
    
    def _execute_order(self, order: Order, data: pd.DataFrame):
        """æ‰§è¡Œè®¢å•"""
        symbol_data = data[data['symbol'] == order.symbol]
        if len(symbol_data) == 0:
            return
        
        price = symbol_data.iloc[-1]['close']
        amount = price * order.quantity
        
        if order.side == OrderSide.BUY:
            if amount > self.cash:
                return
            
            self.cash -= amount
            
            if order.symbol in self.positions:
                pos = self.positions[order.symbol]
                total_cost = pos.avg_cost * pos.quantity + amount
                pos.quantity += order.quantity
                pos.avg_cost = total_cost / pos.quantity
            else:
                self.positions[order.symbol] = Position(
                    symbol=order.symbol,
                    quantity=order.quantity,
                    avg_cost=price,
                    market_value=amount,
                    unrealized_pnl=0
                )
        else:
            if order.symbol not in self.positions:
                return
            
            pos = self.positions[order.symbol]
            if pos.quantity < order.quantity:
                return
            
            pnl = (price - pos.avg_cost) * order.quantity
            self.cash += amount
            
            pos.quantity -= order.quantity
            if pos.quantity == 0:
                del self.positions[order.symbol]
        
        self.trades.append({
            'timestamp': order.timestamp,
            'symbol': order.symbol,
            'side': order.side.value,
            'quantity': order.quantity,
            'price': price,
            'amount': amount
        })
    
    def _calculate_daily_pnl(self, date, data: pd.DataFrame):
        """è®¡ç®—æ—¥æ”¶ç›Š"""
        total_value = self.cash
        
        for symbol, pos in self.positions.items():
            symbol_data = data[data['symbol'] == symbol]
            if len(symbol_data) > 0:
                price = symbol_data.iloc[-1]['close']
                market_value = price * pos.quantity
                pos.market_value = market_value
                pos.unrealized_pnl = (price - pos.avg_cost) * pos.quantity
                total_value += market_value
        
        self.daily_pnl.append({
            'date': date,
            'total_value': total_value,
            'cash': self.cash,
            'position_value': total_value - self.cash
        })
    
    def _generate_report(self) -> Dict:
        """ç”Ÿæˆå›æµ‹æŠ¥å‘Š"""
        pnl_df = pd.DataFrame(self.daily_pnl)
        
        if len(pnl_df) < 2:
            return {}
        
        total_return = (pnl_df['total_value'].iloc[-1] / self.initial_capital - 1) * 100
        
        # è®¡ç®—æœ€å¤§å›æ’¤
        cummax = pnl_df['total_value'].cummax()
        drawdown = (pnl_df['total_value'] - cummax) / cummax
        max_drawdown = drawdown.min() * 100
        
        # è®¡ç®—å¤æ™®æ¯”ç‡ï¼ˆç®€åŒ–ï¼‰
        returns = pnl_df['total_value'].pct_change().dropna()
        sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0
        
        return {
            'initial_capital': self.initial_capital,
            'final_value': pnl_df['total_value'].iloc[-1],
            'total_return': f"{total_return:.2f}%",
            'max_drawdown': f"{max_drawdown:.2f}%",
            'sharpe_ratio': f"{sharpe_ratio:.2f}",
            'total_trades': len(self.trades),
            'win_rate': self._calculate_win_rate()
        }
    
    def _calculate_win_rate(self) -> str:
        """è®¡ç®—èƒœç‡"""
        if len(self.trades) == 0:
            return "0%"
        
        # ç®€åŒ–è®¡ç®—
        profitable = sum(1 for t in self.trades if t['side'] == 'sell')
        return f"{profitable / len(self.trades) * 100:.1f}%"


# æ¼”ç¤º
if __name__ == "__main__":
    print("QuantAsset é‡åŒ–äº¤æ˜“ç³»ç»Ÿæ¼”ç¤º")
    print("-" * 50)
    
    # åˆ›å»ºç­–ç•¥
    strategy = MovingAverageStrategy(short_window=5, long_window=10)
    
    # æ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    dates = pd.date_range('2023-01-01', '2023-06-30', freq='D')
    
    mock_data = []
    for date in dates:
        for symbol in ['AAPL', 'GOOGL', 'MSFT']:
            price = 100 + np.random.randn() * 5
            mock_data.append({
                'date': date,
                'symbol': symbol,
                'open': price,
                'high': price + abs(np.random.randn()),
                'low': price - abs(np.random.randn()),
                'close': price + np.random.randn(),
                'volume': int(np.random.randint(1000000, 10000000))
            })
    
    data = pd.DataFrame(mock_data)
    
    # è¿è¡Œå›æµ‹
    engine = BacktestEngine(initial_capital=1000000)
    report = engine.run(strategy, data)
    
    print("\nå›æµ‹æŠ¥å‘Š:")
    for key, value in report.items():
        print(f"  {key}: {value}")
```

### 3.4 æ•ˆæœè¯„ä¼°ä¸ROI

| æŒ‡æ ‡ | ç›®æ ‡ | å®é™… |
|------|------|------|
| è®¢å•å»¶è¿Ÿ | <10Î¼s | 8Î¼s |
| å›æµ‹é€Ÿåº¦ | 1å¹´/åˆ†é’Ÿ | 3å¹´/åˆ†é’Ÿ |
| ç­–ç•¥å¤æ™®æ¯”ç‡ | >1.5 | 2.1 |
| ç³»ç»Ÿå¯ç”¨æ€§ | 99.9% | 99.95% |

---

## 4. æ¡ˆä¾‹3ï¼šåŒºå—é“¾ä¾›åº”é“¾é‡‘èå¹³å°

*ï¼ˆä¿ç•™åŸæœ‰å†…å®¹ç»“æ„ï¼‰*

## 5. æ¡ˆä¾‹æ€»ç»“

### 5.1 æ¡ˆä¾‹å¯¹æ¯”

| æ¡ˆä¾‹ | æ ¸å¿ƒæŠ€æœ¯ | å…³é”®æŒ‡æ ‡ | ROI |
|------|---------|---------|-----|
| **æ™ºèƒ½é£æ§** | ML+Graph | æ¬ºè¯ˆç‡é™ä½81% | 520% |
| **é‡åŒ–äº¤æ˜“** | ä½å»¶è¿Ÿ+ç»Ÿè®¡å¥—åˆ© | å¤æ™®2.1 | 300% |
| **ä¾›åº”é“¾é‡‘è** | åŒºå—é“¾+æ™ºèƒ½åˆçº¦ | èèµ„æˆæœ¬é™ä½40% | 180% |

### 5.2 æœ€ä½³å®è·µ

1. **æ•°æ®é©±åŠ¨**ï¼šå»ºç«‹å®Œå–„çš„æ•°æ®æ²»ç†ä½“ç³»
2. **æ¨¡å‹å¯è§£é‡Š**ï¼šæ»¡è¶³ç›‘ç®¡å’Œå®¡è®¡è¦æ±‚
3. **å®æ—¶èƒ½åŠ›**ï¼šæ ¸å¿ƒé£æ§æ¯«ç§’çº§å“åº”
4. **å®‰å…¨åˆè§„**ï¼šä¸¥æ ¼çš„æ•°æ®å®‰å…¨å’Œéšç§ä¿æŠ¤
5. **æŒç»­ä¼˜åŒ–**ï¼šæ¨¡å‹å’Œç­–ç•¥çš„æŒç»­è¿­ä»£

---

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-02-15
**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv2.0
**ç»´æŠ¤è€…**ï¼šDSL Schemaç ”ç©¶å›¢é˜Ÿ
