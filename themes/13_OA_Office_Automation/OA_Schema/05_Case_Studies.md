# åŠå…¬è‡ªåŠ¨åŒ–Schemaå®è·µæ¡ˆä¾‹

## ğŸ“‘ ç›®å½•

- [åŠå…¬è‡ªåŠ¨åŒ–Schemaå®è·µæ¡ˆä¾‹](#åŠå…¬è‡ªåŠ¨åŒ–schemaå®è·µæ¡ˆä¾‹)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¡ˆä¾‹æ¦‚è¿°](#1-æ¡ˆä¾‹æ¦‚è¿°)
  - [2. æ¡ˆä¾‹1ï¼šæ–‡æ¡£ç®¡ç†ç³»ç»Ÿå’Œç‰ˆæœ¬æ§åˆ¶](#2-æ¡ˆä¾‹1æ–‡æ¡£ç®¡ç†ç³»ç»Ÿå’Œç‰ˆæœ¬æ§åˆ¶)
    - [2.1 åœºæ™¯æè¿°](#21-åœºæ™¯æè¿°)
    - [2.2 Schemaå®šä¹‰](#22-schemaå®šä¹‰)
    - [2.3 å®ç°ä»£ç ](#23-å®ç°ä»£ç )
  - [3. æ¡ˆä¾‹2ï¼šè¯·å‡å®¡æ‰¹æµç¨‹ç®¡ç†](#3-æ¡ˆä¾‹2è¯·å‡å®¡æ‰¹æµç¨‹ç®¡ç†)
    - [3.1 åœºæ™¯æè¿°](#31-åœºæ™¯æè¿°)
    - [3.2 Schemaå®šä¹‰](#32-schemaå®šä¹‰)
    - [3.3 å®ç°ä»£ç ](#33-å®ç°ä»£ç )
  - [4. æ¡ˆä¾‹3ï¼šä»»åŠ¡ç®¡ç†ç³»ç»Ÿ](#4-æ¡ˆä¾‹3ä»»åŠ¡ç®¡ç†ç³»ç»Ÿ)
    - [4.1 åœºæ™¯æè¿°](#41-åœºæ™¯æè¿°)
    - [4.2 Schemaå®šä¹‰](#42-schemaå®šä¹‰)
    - [4.3 å®ç°ä»£ç ](#43-å®ç°ä»£ç )
  - [5. æ¡ˆä¾‹4ï¼šæ–‡æ¡£æ ¼å¼æ‰¹é‡è½¬æ¢](#5-æ¡ˆä¾‹4æ–‡æ¡£æ ¼å¼æ‰¹é‡è½¬æ¢)
    - [5.1 åœºæ™¯æè¿°](#51-åœºæ™¯æè¿°)
    - [5.2 å®ç°ä»£ç ](#52-å®ç°ä»£ç )
  - [6. æ¡ˆä¾‹5ï¼šOAæ•°æ®åˆ†æå’ŒæŠ¥è¡¨](#6-æ¡ˆä¾‹5oaæ•°æ®åˆ†æå’ŒæŠ¥è¡¨)
    - [6.1 åœºæ™¯æè¿°](#61-åœºæ™¯æè¿°)
    - [6.2 å®ç°ä»£ç ](#62-å®ç°ä»£ç )
    - [6.3 æ•°æ®åˆ†æç¤ºä¾‹](#63-æ•°æ®åˆ†æç¤ºä¾‹)
  - [7. æ¡ˆä¾‹6ï¼šæ–‡æ¡£åä½œç¼–è¾‘ï¼ˆå¤šäººåŒæ—¶ç¼–è¾‘ï¼‰](#7-æ¡ˆä¾‹6æ–‡æ¡£åä½œç¼–è¾‘å¤šäººåŒæ—¶ç¼–è¾‘)
    - [7.1 åœºæ™¯æè¿°](#71-åœºæ™¯æè¿°)
    - [7.2 Schemaå®šä¹‰](#72-schemaå®šä¹‰)
    - [7.3 å®ç°ä»£ç ](#73-å®ç°ä»£ç )
  - [8. æ¡ˆä¾‹7ï¼šå¤æ‚å®¡æ‰¹æµç¨‹ï¼ˆå¤šçº§å®¡æ‰¹ï¼‰](#8-æ¡ˆä¾‹7å¤æ‚å®¡æ‰¹æµç¨‹å¤šçº§å®¡æ‰¹)
    - [8.1 åœºæ™¯æè¿°](#81-åœºæ™¯æè¿°)
    - [8.2 Schemaå®šä¹‰](#82-schemaå®šä¹‰)
    - [8.3 å®ç°ä»£ç ](#83-å®ç°ä»£ç )
  - [9. æ¡ˆä¾‹8ï¼šæ–‡æ¡£ç‰ˆæœ¬å¯¹æ¯”](#9-æ¡ˆä¾‹8æ–‡æ¡£ç‰ˆæœ¬å¯¹æ¯”)
    - [9.1 åœºæ™¯æè¿°](#91-åœºæ™¯æè¿°)
    - [9.2 å®ç°ä»£ç ](#92-å®ç°ä»£ç )
  - [10. æ¡ˆä¾‹9ï¼šæµç¨‹æ•ˆç‡åˆ†æ](#10-æ¡ˆä¾‹9æµç¨‹æ•ˆç‡åˆ†æ)
    - [10.1 åœºæ™¯æè¿°](#101-åœºæ™¯æè¿°)
    - [10.2 å®ç°ä»£ç ](#102-å®ç°ä»£ç )
  - [11. æ¡ˆä¾‹10ï¼šçŸ¥è¯†åº“ç®¡ç†](#11-æ¡ˆä¾‹10çŸ¥è¯†åº“ç®¡ç†)
    - [11.1 åœºæ™¯æè¿°](#111-åœºæ™¯æè¿°)
    - [11.2 Schemaå®šä¹‰](#112-schemaå®šä¹‰)
    - [11.3 å®ç°ä»£ç ](#113-å®ç°ä»£ç )
  - [12. æ¡ˆä¾‹11ï¼šæ–‡æ¡£æ™ºèƒ½åˆ†æç³»ç»Ÿ](#12-æ¡ˆä¾‹11æ–‡æ¡£æ™ºèƒ½åˆ†æç³»ç»Ÿ)
    - [12.1 åœºæ™¯æè¿°](#121-åœºæ™¯æè¿°)
    - [12.2 Schemaå®šä¹‰](#122-schemaå®šä¹‰)
    - [12.3 å®ç°ä»£ç ](#123-å®ç°ä»£ç )
  - [13. æ¡ˆä¾‹12ï¼šæµç¨‹è‡ªåŠ¨åŒ–ç³»ç»Ÿ](#13-æ¡ˆä¾‹12æµç¨‹è‡ªåŠ¨åŒ–ç³»ç»Ÿ)
    - [13.1 åœºæ™¯æè¿°](#131-åœºæ™¯æè¿°)
    - [13.2 Schemaå®šä¹‰](#132-schemaå®šä¹‰)
    - [13.3 å®ç°ä»£ç ](#133-å®ç°ä»£ç )
  - [14. æ¡ˆä¾‹13ï¼šåä½œæ•ˆç‡åˆ†æç³»ç»Ÿ](#14-æ¡ˆä¾‹13åä½œæ•ˆç‡åˆ†æç³»ç»Ÿ)
    - [14.1 åœºæ™¯æè¿°](#141-åœºæ™¯æè¿°)
    - [14.2 Schemaå®šä¹‰](#142-schemaå®šä¹‰)
    - [14.3 å®ç°ä»£ç ](#143-å®ç°ä»£ç )

---

## 1. æ¡ˆä¾‹æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›åŠå…¬è‡ªåŠ¨åŒ–Schemaåœ¨å®é™…åº”ç”¨ä¸­çš„å®è·µæ¡ˆä¾‹ã€‚

---

## 2. æ¡ˆä¾‹1ï¼šæ–‡æ¡£ç®¡ç†ç³»ç»Ÿå’Œç‰ˆæœ¬æ§åˆ¶

### 2.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
ä¼ä¸šéœ€è¦ç®¡ç†å¤§é‡æ–‡æ¡£ï¼Œæ”¯æŒç‰ˆæœ¬æ§åˆ¶ã€æƒé™ç®¡ç†å’Œæ–‡æ¡£æ£€ç´¢åŠŸèƒ½ã€‚
æ–‡æ¡£éœ€è¦æ”¯æŒODFå’ŒOOXMLæ ¼å¼ï¼Œå¹¶èƒ½åœ¨è¿™ä¸¤ç§æ ¼å¼ä¹‹é—´è½¬æ¢ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦å®ç°æ–‡æ¡£ç‰ˆæœ¬æ§åˆ¶
- éœ€è¦ç®¡ç†æ–‡æ¡£æƒé™
- éœ€è¦æ”¯æŒæ–‡æ¡£æ ¼å¼è½¬æ¢
- éœ€è¦å®ç°æ–‡æ¡£å…¨æ–‡æ£€ç´¢

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨DocumentVersionManagerå®ç°æ–‡æ¡£ç‰ˆæœ¬æ§åˆ¶ï¼Œä½¿ç”¨ODFToOOXMLConverter
å®ç°æ–‡æ¡£æ ¼å¼è½¬æ¢ã€‚

### 2.2 Schemaå®šä¹‰

è¯¦è§ç¬¬2.2èŠ‚åŸå§‹å®šä¹‰ã€‚

### 2.3 å®ç°ä»£ç 

**å®Œæ•´çš„æ–‡æ¡£ç®¡ç†ç³»ç»Ÿå®ç°**ï¼š

```python
from oa_storage import OAStorage
from document_version_manager import DocumentVersionManager
from odf_to_ooxml_converter import ODFToOOXMLConverter
from datetime import datetime

# åˆå§‹åŒ–å­˜å‚¨å’Œç»„ä»¶
storage = OAStorage("postgresql://user:pass@localhost/oa")
version_manager = DocumentVersionManager(storage)
converter = ODFToOOXMLConverter()

# åˆ›å»ºæ–‡æ¡£
document_data = {
    "document_id": "DOC20250121001",
    "document_title": "é¡¹ç›®è®¡åˆ’ä¹¦",
    "document_type": "Word",
    "author": "å¼ ä¸‰",
    "file_path": "/documents/project/plan.odt",
    "file_size": 102400,
    "mime_type": "application/vnd.oasis.opendocument.text",
    "current_version": 1
}

# å­˜å‚¨æ–‡æ¡£
doc_id = storage.store_document(document_data)
print(f"Created document: {doc_id}")

# åˆ›å»ºç‰ˆæœ¬1
version1 = version_manager.create_version(
    "DOC20250121001",
    "å¼ ä¸‰",
    "/documents/project/plan_v1.odt",
    "åˆå§‹ç‰ˆæœ¬"
)
print(f"Created version 1: {version1}")

# åˆ›å»ºç‰ˆæœ¬2
version2 = version_manager.create_version(
    "DOC20250121001",
    "æå››",
    "/documents/project/plan_v2.odt",
    "æ·»åŠ é¡¹ç›®é¢„ç®—"
)
print(f"Created version 2: {version2}")

# æŸ¥è¯¢ç‰ˆæœ¬å†å²
history = version_manager.get_version_history("DOC20250121001")
print(f"\nVersion history:")
for version in history:
    print(f"  Version {version['version_number']}: {version['version_author']} - {version['version_comment']}")

# è½¬æ¢ODFåˆ°OOXML
ooxml_path = converter.convert_document("/documents/project/plan.odt")
if ooxml_path:
    print(f"\nConverted to OOXML: {ooxml_path}")

    # åˆ›å»ºOOXMLç‰ˆæœ¬
    version3 = version_manager.create_version(
        "DOC20250121001",
        "å¼ ä¸‰",
        ooxml_path,
        "è½¬æ¢ä¸ºDOCXæ ¼å¼"
    )
    print(f"Created version 3 (OOXML): {version3}")

# æ¢å¤ç‰ˆæœ¬1
restored = version_manager.restore_version("DOC20250121001", 1)
if restored:
    print("\nRestored version 1")
```

---

## 3. æ¡ˆä¾‹2ï¼šè¯·å‡å®¡æ‰¹æµç¨‹ç®¡ç†

### 3.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
ä¼ä¸šéœ€è¦å®ç°è¯·å‡å®¡æ‰¹æµç¨‹ï¼Œæ”¯æŒå¤šçº§å®¡æ‰¹ã€æµç¨‹è·Ÿè¸ªå’Œå®¡æ‰¹å†å²æŸ¥è¯¢ã€‚
æµç¨‹éœ€è¦æ”¯æŒBPMNæ ‡å‡†å®šä¹‰ï¼Œå¹¶èƒ½çµæ´»é…ç½®å®¡æ‰¹èŠ‚ç‚¹ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦å®ç°å·¥ä½œæµå¼•æ“
- éœ€è¦æ”¯æŒå¤šçº§å®¡æ‰¹
- éœ€è¦æµç¨‹çŠ¶æ€è·Ÿè¸ª
- éœ€è¦å®¡æ‰¹å†å²è®°å½•

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨WorkflowEngineå®ç°BPMNå·¥ä½œæµå¼•æ“ï¼Œæ”¯æŒæµç¨‹å®šä¹‰ã€å¯åŠ¨å’Œå®¡æ‰¹ã€‚

### 3.2 Schemaå®šä¹‰

è¯¦è§ç¬¬3.2èŠ‚åŸå§‹å®šä¹‰ã€‚

### 3.3 å®ç°ä»£ç 

**å®Œæ•´çš„è¯·å‡å®¡æ‰¹æµç¨‹å®ç°**ï¼š

```python
from workflow_engine import WorkflowEngine
from oa_storage import OAStorage
from datetime import datetime

# åˆå§‹åŒ–å·¥ä½œæµå¼•æ“å’Œå­˜å‚¨
storage = OAStorage("postgresql://user:pass@localhost/oa")
workflow_engine = WorkflowEngine(storage)

# å®šä¹‰è¯·å‡å®¡æ‰¹æµç¨‹
leave_process_definition = {
    "process_id": "LEAVE_PROCESS",
    "process_name": "è¯·å‡å®¡æ‰¹æµç¨‹",
    "process_type": "Leave",
    "process_definition": {
        "process_version": 1,
        "process_nodes": [
            {
                "node_id": "NODE001",
                "node_name": "æäº¤ç”³è¯·",
                "node_type": "Start",
                "node_order": 1
            },
            {
                "node_id": "NODE002",
                "node_name": "éƒ¨é—¨ç»ç†å®¡æ‰¹",
                "node_type": "Approval",
                "approver": "éƒ¨é—¨ç»ç†",
                "node_order": 2
            },
            {
                "node_id": "NODE003",
                "node_name": "HRå®¡æ‰¹",
                "node_type": "Approval",
                "approver": "HR",
                "node_order": 3
            },
            {
                "node_id": "NODE004",
                "node_name": "å®Œæˆ",
                "node_type": "End",
                "node_order": 4
            }
        ]
    }
}

# æ³¨å†Œæµç¨‹å®šä¹‰
workflow_engine.define_process("LEAVE_PROCESS", leave_process_definition)

# å¯åŠ¨æµç¨‹å®ä¾‹
process_data = {
    "leave_type": "å¹´å‡",
    "start_date": "2025-02-01",
    "end_date": "2025-02-05",
    "days": 5,
    "reason": "ä¸ªäººäº‹åŠ¡"
}

instance_id = workflow_engine.start_process(
    "LEAVE_PROCESS",
    "å¼ ä¸‰",
    process_data
)
print(f"Started process instance: {instance_id}")

# æŸ¥è¯¢æµç¨‹çŠ¶æ€
status = workflow_engine.get_process_status(instance_id)
print(f"\nProcess status: {status['current_status']}")
print(f"Current node: {status['current_node']}")

# éƒ¨é—¨ç»ç†å®¡æ‰¹
workflow_engine.approve_node(
    instance_id,
    "éƒ¨é—¨ç»ç†",
    "Approved",
    "åŒæ„è¯·å‡ç”³è¯·"
)

# æŸ¥è¯¢æ›´æ–°åçš„çŠ¶æ€
status = workflow_engine.get_process_status(instance_id)
print(f"\nAfter department manager approval:")
print(f"  Status: {status['current_status']}")
print(f"  Current node: {status['current_node']}")

# HRå®¡æ‰¹
workflow_engine.approve_node(
    instance_id,
    "HR",
    "Approved",
    "å®¡æ‰¹é€šè¿‡"
)

# æŸ¥è¯¢æœ€ç»ˆçŠ¶æ€
status = workflow_engine.get_process_status(instance_id)
print(f"\nFinal status: {status['current_status']}")

# æŸ¥è¯¢å®¡æ‰¹å†å²
history = storage.get_process_approval_history(instance_id)
print(f"\nApproval history:")
for record in history:
    print(f"  {record['node_id']}: {record['approver']} - {record['approval_result']} - {record['approval_time']}")
```

---

## 4. æ¡ˆä¾‹3ï¼šä»»åŠ¡ç®¡ç†ç³»ç»Ÿ

### 4.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
ä¼ä¸šéœ€è¦ç®¡ç†é¡¹ç›®ä»»åŠ¡ï¼Œæ”¯æŒä»»åŠ¡åˆ†é…ã€çŠ¶æ€è·Ÿè¸ªã€ä¼˜å…ˆçº§ç®¡ç†å’Œå·¥ä½œé‡ç»Ÿè®¡ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦ä»»åŠ¡åˆ†é…å’Œè·Ÿè¸ª
- éœ€è¦ä¼˜å…ˆçº§ç®¡ç†
- éœ€è¦å·¥ä½œé‡ç»Ÿè®¡
- éœ€è¦ä»»åŠ¡æé†’

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨OAStorageå­˜å‚¨ä»»åŠ¡æ•°æ®ï¼Œå®ç°ä»»åŠ¡ç®¡ç†å’Œç»Ÿè®¡åŠŸèƒ½ã€‚

### 4.2 Schemaå®šä¹‰

è¯¦è§ç¬¬4.2èŠ‚åŸå§‹å®šä¹‰ã€‚

### 4.3 å®ç°ä»£ç 

**å®Œæ•´çš„ä»»åŠ¡ç®¡ç†ç³»ç»Ÿå®ç°**ï¼š

```python
from oa_storage import OAStorage
from datetime import datetime, timedelta

# åˆå§‹åŒ–å­˜å‚¨
storage = OAStorage("postgresql://user:pass@localhost/oa")

# åˆ›å»ºä»»åŠ¡
task_data = {
    "task_id": "TASK20250121001",
    "task_title": "å®Œæˆé¡¹ç›®æ–‡æ¡£",
    "task_description": "ç¼–å†™é¡¹ç›®éœ€æ±‚æ–‡æ¡£å’ŒæŠ€æœ¯æ–¹æ¡ˆ",
    "assignee": "æå››",
    "assigner": "å¼ ä¸‰",
    "task_status": "Todo",
    "priority": "High",
    "due_date": datetime.now() + timedelta(days=5)
}

task_id = storage.store_task(task_data)
print(f"Created task: {task_id}")

# æ›´æ–°ä»»åŠ¡çŠ¶æ€
storage.update_task_status("TASK20250121001", "InProgress")
print("Updated task status to InProgress")

# æŸ¥è¯¢ä»»åŠ¡ç»Ÿè®¡
task_stats = storage.get_task_statistics(assignee="æå››", days=30)
print(f"\nTask statistics for æå››:")
for status, stats in task_stats.items():
    print(f"  {status}: {stats['count']} tasks, {stats['overdue_count']} overdue")

# æŸ¥è¯¢ç”¨æˆ·å·¥ä½œé‡
workload = storage.get_user_workload("æå››", days=7)
print(f"\nWorkload for æå›› (7 days):")
print(f"  Tasks: {workload['tasks']}")
print(f"  Approvals: {workload['approvals']}")
```

---

## 5. æ¡ˆä¾‹4ï¼šæ–‡æ¡£æ ¼å¼æ‰¹é‡è½¬æ¢

### 5.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
ä¼ä¸šéœ€è¦å°†å¤§é‡ODFæ–‡æ¡£æ‰¹é‡è½¬æ¢ä¸ºOOXMLæ ¼å¼ï¼Œä»¥ä¾¿ä¸Microsoft Officeç³»ç»Ÿé›†æˆã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦æ‰¹é‡è½¬æ¢æ–‡æ¡£
- éœ€è¦ä¿æŒæ–‡æ¡£æ ¼å¼
- éœ€è¦è½¬æ¢è¿›åº¦è·Ÿè¸ª
- éœ€è¦é”™è¯¯å¤„ç†

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨ODFToOOXMLConverterå®ç°æ‰¹é‡æ–‡æ¡£è½¬æ¢ã€‚

### 5.2 å®ç°ä»£ç 

**æ‰¹é‡æ–‡æ¡£è½¬æ¢å®ç°**ï¼š

```python
from odf_to_ooxml_converter import ODFToOOXMLConverter
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO)
converter = ODFToOOXMLConverter()

# æ‰¹é‡è½¬æ¢ODFæ–‡æ¡£
odf_directory = Path("/documents/odf")
output_directory = Path("/documents/ooxml")
output_directory.mkdir(exist_ok=True)

odf_files = list(odf_directory.glob("*.odt")) + \
            list(odf_directory.glob("*.ods")) + \
            list(odf_directory.glob("*.odp"))

print(f"Found {len(odf_files)} ODF files to convert")

success_count = 0
failed_count = 0

for odf_file in odf_files:
    try:
        output_path = output_directory / odf_file.with_suffix(
            converter._get_ooxml_extension(odf_file.suffix)
        ).name

        result = converter.convert_document(str(odf_file), str(output_path))
        if result:
            success_count += 1
            print(f"âœ“ Converted: {odf_file.name} -> {output_path.name}")
        else:
            failed_count += 1
            print(f"âœ— Failed: {odf_file.name}")
    except Exception as e:
        failed_count += 1
        print(f"âœ— Error converting {odf_file.name}: {e}")

print(f"\nConversion complete:")
print(f"  Success: {success_count}")
print(f"  Failed: {failed_count}")
```

---

## 6. æ¡ˆä¾‹5ï¼šOAæ•°æ®åˆ†æå’ŒæŠ¥è¡¨

### 6.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
ä½¿ç”¨PostgreSQLå­˜å‚¨åŠå…¬è‡ªåŠ¨åŒ–æ•°æ®ï¼Œæ”¯æŒæ–‡æ¡£ç»Ÿè®¡ã€æµç¨‹åˆ†æå’Œç”¨æˆ·å·¥ä½œé‡ç»Ÿè®¡ã€‚

### 6.2 å®ç°ä»£ç 

è¯¦è§ `04_Transformation.md` ç¬¬7ç« ã€‚

### 6.3 æ•°æ®åˆ†æç¤ºä¾‹

**OAæ•°æ®åˆ†ææŸ¥è¯¢**ï¼š

```python
from oa_storage import OAStorage
from datetime import datetime, timedelta

storage = OAStorage("postgresql://user:pass@localhost/oa")

# æŸ¥è¯¢æ–‡æ¡£ç»Ÿè®¡
doc_stats = storage.get_document_statistics(datetime.now() - timedelta(days=30))
print("Document Statistics (30 days):")
for stat in doc_stats:
    print(f"  {stat['document_type']}: {stat['count']} documents, "
          f"Total size: {stat['total_size']/1024/1024:.2f}MB")

# æŸ¥è¯¢æµç¨‹å®¡æ‰¹ç»Ÿè®¡
process_stats = storage.get_process_statistics(days=30)
print("\nProcess Statistics (30 days):")
for stat in process_stats:
    print(f"  {stat['process_type']} - {stat['current_status']}: "
          f"{stat['count']} processes, Avg: {stat['avg_hours']:.2f} hours")

# æŸ¥è¯¢ç”¨æˆ·å·¥ä½œé‡
workload = storage.get_user_workload("å¼ ä¸‰", days=7)
print(f"\nWorkload for å¼ ä¸‰ (7 days):")
print(f"  Tasks: {workload['tasks']}")
print(f"  Approvals: {workload['approvals']}")
```

---

## 7. æ¡ˆä¾‹6ï¼šæ–‡æ¡£åä½œç¼–è¾‘ï¼ˆå¤šäººåŒæ—¶ç¼–è¾‘ï¼‰

### 7.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
ä¼ä¸šéœ€è¦æ”¯æŒå¤šäººåŒæ—¶ç¼–è¾‘åŒä¸€æ–‡æ¡£ï¼Œå®ç°å®æ—¶åä½œç¼–è¾‘åŠŸèƒ½ã€‚
å¤šä¸ªç”¨æˆ·å¯ä»¥åœ¨åŒä¸€æ–‡æ¡£çš„ä¸åŒéƒ¨åˆ†è¿›è¡Œç¼–è¾‘ï¼Œç³»ç»Ÿéœ€è¦è·Ÿè¸ªæ¯ä¸ªç”¨æˆ·çš„ç¼–è¾‘æ“ä½œï¼Œå¹¶è®°å½•åä½œå†å²ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦å®ç°æ–‡æ¡£é”å®šæœºåˆ¶ï¼ˆæ®µè½/ç« èŠ‚çº§åˆ«ï¼‰
- éœ€è¦è·Ÿè¸ªæ¯ä¸ªç”¨æˆ·çš„ç¼–è¾‘æ“ä½œ
- éœ€è¦å¤„ç†ç¼–è¾‘å†²çª
- éœ€è¦è®°å½•åä½œå†å²

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨æ–‡æ¡£åä½œè®°å½•è¡¨è·Ÿè¸ªæ¯ä¸ªç”¨æˆ·çš„ç¼–è¾‘æ“ä½œï¼Œå®ç°æ®µè½çº§åˆ«çš„é”å®šæœºåˆ¶ï¼Œæ”¯æŒå¤šäººåŒæ—¶ç¼–è¾‘ã€‚

### 7.2 Schemaå®šä¹‰

**æ–‡æ¡£åä½œç¼–è¾‘Schema**ï¼š

```json
{
  "document_id": "DOC001",
  "collaboration_mode": "concurrent",
  "active_users": [
    {
      "user_id": "user001",
      "user_name": "å¼ ä¸‰",
      "editing_sections": ["section1", "section2"],
      "last_activity": "2025-01-21T10:30:00Z"
    },
    {
      "user_id": "user002",
      "user_name": "æå››",
      "editing_sections": ["section3"],
      "last_activity": "2025-01-21T10:25:00Z"
    }
  ],
  "lock_rules": {
    "lock_level": "paragraph",
    "auto_unlock_minutes": 30
  }
}
```

### 7.3 å®ç°ä»£ç 

**å®Œæ•´çš„æ–‡æ¡£åä½œç¼–è¾‘å®ç°**ï¼š

```python
import asyncio
import logging
from typing import Dict, List, Optional
from datetime import datetime, timedelta
from oa_storage import OAStorage
from document_version_manager import DocumentVersionManager

logger = logging.getLogger(__name__)

class DocumentCollaborationManager:
    """æ–‡æ¡£åä½œç®¡ç†å™¨"""

    def __init__(self, storage: OAStorage):
        self.storage = storage
        self.active_sessions: Dict[str, Dict] = {}
        self.locked_sections: Dict[str, Dict] = {}

    def start_editing_session(self, document_id: str, user_id: str,
                              section_id: str = None) -> bool:
        """å¼€å§‹ç¼–è¾‘ä¼šè¯"""
        # æ£€æŸ¥æƒé™
        if not self.storage.check_document_permission(document_id, user_id, "write"):
            logger.warning(f"User {user_id} does not have write permission for {document_id}")
            return False

        # æ£€æŸ¥æ®µè½æ˜¯å¦è¢«é”å®š
        if section_id:
            if self._is_section_locked(document_id, section_id, user_id):
                logger.warning(f"Section {section_id} is locked by another user")
                return False
            self._lock_section(document_id, section_id, user_id)

        # è®°å½•åä½œæ“ä½œ
        self.storage.store_collaboration_record(
            document_id,
            user_id,
            "start_editing",
            f"Started editing session",
            {"section_id": section_id}
        )

        # æ›´æ–°æ´»åŠ¨ä¼šè¯
        session_key = f"{document_id}_{user_id}"
        self.active_sessions[session_key] = {
            "document_id": document_id,
            "user_id": user_id,
            "section_id": section_id,
            "start_time": datetime.now(),
            "last_activity": datetime.now()
        }

        logger.info(f"User {user_id} started editing session for {document_id}")
        return True

    def save_edit(self, document_id: str, user_id: str, section_id: str,
                  content: str, change_description: str = None):
        """ä¿å­˜ç¼–è¾‘"""
        # è®°å½•ç¼–è¾‘æ“ä½œ
        self.storage.store_collaboration_record(
            document_id,
            user_id,
            "edit",
            change_description or "Edited content",
            {
                "section_id": section_id,
                "content_length": len(content),
                "timestamp": datetime.now().isoformat()
            }
        )

        # æ›´æ–°æ´»åŠ¨ä¼šè¯
        session_key = f"{document_id}_{user_id}"
        if session_key in self.active_sessions:
            self.active_sessions[session_key]["last_activity"] = datetime.now()

        logger.info(f"User {user_id} saved edit for {document_id}, section {section_id}")

    def end_editing_session(self, document_id: str, user_id: str):
        """ç»“æŸç¼–è¾‘ä¼šè¯"""
        session_key = f"{document_id}_{user_id}"
        if session_key in self.active_sessions:
            session = self.active_sessions[session_key]
            section_id = session.get("section_id")

            # è§£é”æ®µè½
            if section_id:
                self._unlock_section(document_id, section_id, user_id)

            # è®°å½•åä½œæ“ä½œ
            self.storage.store_collaboration_record(
                document_id,
                user_id,
                "end_editing",
                "Ended editing session",
                {
                    "duration_minutes": (datetime.now() - session["start_time"]).total_seconds() / 60
                }
            )

            del self.active_sessions[session_key]
            logger.info(f"User {user_id} ended editing session for {document_id}")

    def get_active_collaborators(self, document_id: str) -> List[Dict]:
        """è·å–æ´»åŠ¨åä½œè€…"""
        collaborators = []
        for session_key, session in self.active_sessions.items():
            if session["document_id"] == document_id:
                collaborators.append({
                    "user_id": session["user_id"],
                    "section_id": session.get("section_id"),
                    "last_activity": session["last_activity"]
                })
        return collaborators

    def get_collaboration_history(self, document_id: str, limit: int = 100) -> List[Dict]:
        """è·å–åä½œå†å²"""
        return self.storage.get_collaboration_history(document_id, limit)

    def _is_section_locked(self, document_id: str, section_id: str, user_id: str) -> bool:
        """æ£€æŸ¥æ®µè½æ˜¯å¦è¢«é”å®š"""
        lock_key = f"{document_id}_{section_id}"
        if lock_key in self.locked_sections:
            lock_info = self.locked_sections[lock_key]
            # æ£€æŸ¥æ˜¯å¦æ˜¯è‡ªå·±é”å®šçš„
            if lock_info["user_id"] == user_id:
                return False
            # æ£€æŸ¥é”å®šæ˜¯å¦è¿‡æœŸï¼ˆ30åˆ†é’Ÿï¼‰
            if datetime.now() - lock_info["lock_time"] > timedelta(minutes=30):
                del self.locked_sections[lock_key]
                return False
            return True
        return False

    def _lock_section(self, document_id: str, section_id: str, user_id: str):
        """é”å®šæ®µè½"""
        lock_key = f"{document_id}_{section_id}"
        self.locked_sections[lock_key] = {
            "document_id": document_id,
            "section_id": section_id,
            "user_id": user_id,
            "lock_time": datetime.now()
        }

    def _unlock_section(self, document_id: str, section_id: str, user_id: str):
        """è§£é”æ®µè½"""
        lock_key = f"{document_id}_{section_id}"
        if lock_key in self.locked_sections:
            if self.locked_sections[lock_key]["user_id"] == user_id:
                del self.locked_sections[lock_key]

async def collaborative_editing_example():
    """æ–‡æ¡£åä½œç¼–è¾‘ç¤ºä¾‹"""
    storage = OAStorage("postgresql://user:pass@localhost/oa")
    collab_manager = DocumentCollaborationManager(storage)

    document_id = "DOC001"

    # æˆäºˆæƒé™
    storage.grant_document_permission(document_id, "user001", "write", "admin")
    storage.grant_document_permission(document_id, "user002", "write", "admin")

    # ç”¨æˆ·1å¼€å§‹ç¼–è¾‘
    print("User 1 starting editing session...")
    collab_manager.start_editing_session(document_id, "user001", "section1")

    # ç”¨æˆ·2å¼€å§‹ç¼–è¾‘ï¼ˆä¸åŒæ®µè½ï¼‰
    print("User 2 starting editing session...")
    collab_manager.start_editing_session(document_id, "user002", "section2")

    # ä¿å­˜ç¼–è¾‘
    collab_manager.save_edit(document_id, "user001", "section1", "Updated content", "Added introduction")
    collab_manager.save_edit(document_id, "user002", "section2", "Updated content", "Added conclusion")

    # è·å–æ´»åŠ¨åä½œè€…
    collaborators = collab_manager.get_active_collaborators(document_id)
    print(f"\nActive collaborators: {len(collaborators)}")
    for collab in collaborators:
        print(f"  User: {collab['user_id']}, Section: {collab['section_id']}")

    # è·å–åä½œå†å²
    history = collab_manager.get_collaboration_history(document_id)
    print(f"\nCollaboration history: {len(history)} records")
    for record in history[:5]:
        print(f"  {record['user_id']}: {record['action_type']} at {record['action_time']}")

    # ç»“æŸç¼–è¾‘ä¼šè¯
    collab_manager.end_editing_session(document_id, "user001")
    collab_manager.end_editing_session(document_id, "user002")

    storage.close()

if __name__ == "__main__":
    asyncio.run(collaborative_editing_example())
```

---

## 8. æ¡ˆä¾‹7ï¼šå¤æ‚å®¡æ‰¹æµç¨‹ï¼ˆå¤šçº§å®¡æ‰¹ï¼‰

### 8.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
ä¼ä¸šéœ€è¦å®ç°å¤æ‚çš„å¤šçº§å®¡æ‰¹æµç¨‹ï¼Œä¾‹å¦‚é‡‡è´­å®¡æ‰¹éœ€è¦ç»è¿‡éƒ¨é—¨ç»ç†ã€è´¢åŠ¡ç»ç†ã€æ€»ç»ç†ä¸‰çº§å®¡æ‰¹ã€‚æ¯ä¸ªå®¡æ‰¹èŠ‚ç‚¹å¯èƒ½æœ‰ä¸åŒçš„å®¡æ‰¹è§„åˆ™å’Œæ¡ä»¶ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦æ”¯æŒå¤šçº§å®¡æ‰¹æµç¨‹
- éœ€è¦æ”¯æŒæ¡ä»¶åˆ†æ”¯ï¼ˆæ ¹æ®é‡‘é¢å†³å®šå®¡æ‰¹è·¯å¾„ï¼‰
- éœ€è¦æ”¯æŒå¹¶è¡Œå®¡æ‰¹ï¼ˆå¤šä¸ªå®¡æ‰¹äººåŒæ—¶å®¡æ‰¹ï¼‰
- éœ€è¦æ”¯æŒå®¡æ‰¹é€€å›å’Œé‡æ–°æäº¤

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨BPMNæµç¨‹å®šä¹‰æè¿°å¤æ‚å®¡æ‰¹æµç¨‹ï¼Œé€šè¿‡å·¥ä½œæµå¼•æ“æ‰§è¡Œæµç¨‹ï¼Œæ”¯æŒæ¡ä»¶åˆ†æ”¯å’Œå¹¶è¡Œå®¡æ‰¹ã€‚

### 8.2 Schemaå®šä¹‰

**å¤æ‚å®¡æ‰¹æµç¨‹Schema**ï¼š

```json
{
  "process_id": "purchase_approval",
  "process_name": "é‡‡è´­å®¡æ‰¹æµç¨‹",
  "process_type": "MultiLevelApproval",
  "process_definition": {
    "process_nodes": [
      {
        "node_id": "start",
        "node_name": "å¼€å§‹",
        "node_type": "Start",
        "node_order": 1
      },
      {
        "node_id": "dept_manager",
        "node_name": "éƒ¨é—¨ç»ç†å®¡æ‰¹",
        "node_type": "Approval",
        "node_order": 2,
        "assignee": "dept_manager",
        "condition": null
      },
      {
        "node_id": "gateway_amount",
        "node_name": "é‡‘é¢åˆ¤æ–­",
        "node_type": "Gateway",
        "node_order": 3,
        "condition": "amount > 10000"
      },
      {
        "node_id": "finance_manager",
        "node_name": "è´¢åŠ¡ç»ç†å®¡æ‰¹",
        "node_type": "Approval",
        "node_order": 4,
        "assignee": "finance_manager",
        "condition": "amount > 10000"
      },
      {
        "node_id": "general_manager",
        "node_name": "æ€»ç»ç†å®¡æ‰¹",
        "node_type": "Approval",
        "node_order": 5,
        "assignee": "general_manager",
        "condition": "amount > 50000"
      },
      {
        "node_id": "end",
        "node_name": "ç»“æŸ",
        "node_type": "End",
        "node_order": 6
      }
    ]
  }
}
```

### 8.3 å®ç°ä»£ç 

**å®Œæ•´çš„å¤æ‚å®¡æ‰¹æµç¨‹å®ç°**ï¼š

```python
import asyncio
import logging
from typing import Dict, List, Optional
from datetime import datetime
from workflow_engine import WorkflowEngine, ProcessStatus
from oa_storage import OAStorage

logger = logging.getLogger(__name__)

class MultiLevelApprovalProcess:
    """å¤šçº§å®¡æ‰¹æµç¨‹"""

    def __init__(self, workflow_engine: WorkflowEngine, storage: OAStorage):
        self.workflow_engine = workflow_engine
        self.storage = storage

    def define_purchase_approval_process(self):
        """å®šä¹‰é‡‡è´­å®¡æ‰¹æµç¨‹"""
        process_definition = {
            "process_id": "purchase_approval",
            "process_name": "é‡‡è´­å®¡æ‰¹æµç¨‹",
            "process_type": "MultiLevelApproval",
            "process_definition": {
                "process_nodes": [
                    {
                        "node_id": "start",
                        "node_name": "å¼€å§‹",
                        "node_type": "Start",
                        "node_order": 1
                    },
                    {
                        "node_id": "dept_manager",
                        "node_name": "éƒ¨é—¨ç»ç†å®¡æ‰¹",
                        "node_type": "Approval",
                        "node_order": 2,
                        "assignee": "dept_manager"
                    },
                    {
                        "node_id": "gateway_amount",
                        "node_name": "é‡‘é¢åˆ¤æ–­ç½‘å…³",
                        "node_type": "Gateway",
                        "node_order": 3
                    },
                    {
                        "node_id": "finance_manager",
                        "node_name": "è´¢åŠ¡ç»ç†å®¡æ‰¹",
                        "node_type": "Approval",
                        "node_order": 4,
                        "assignee": "finance_manager",
                        "condition": "amount > 10000"
                    },
                    {
                        "node_id": "general_manager",
                        "node_name": "æ€»ç»ç†å®¡æ‰¹",
                        "node_type": "Approval",
                        "node_order": 5,
                        "assignee": "general_manager",
                        "condition": "amount > 50000"
                    },
                    {
                        "node_id": "end",
                        "node_name": "ç»“æŸ",
                        "node_type": "End",
                        "node_order": 6
                    }
                ]
            }
        }

        self.workflow_engine.define_process("purchase_approval", process_definition)
        logger.info("Defined purchase approval process")

    def start_purchase_approval(self, submitter: str, amount: float,
                               purchase_items: List[Dict]) -> str:
        """å¯åŠ¨é‡‡è´­å®¡æ‰¹"""
        process_data = {
            "amount": amount,
            "purchase_items": purchase_items,
            "submitter": submitter
        }

        instance_id = self.workflow_engine.start_process(
            "purchase_approval",
            submitter,
            process_data
        )

        logger.info(f"Started purchase approval process: {instance_id}")
        return instance_id

    def approve_with_condition(self, instance_id: str, approver: str,
                              approval_result: str, comment: str = ""):
        """æ¡ä»¶å®¡æ‰¹"""
        process = self.workflow_engine.get_process_status(instance_id)
        if not process:
            raise ValueError(f"Process instance not found: {instance_id}")

        process_data = process.get("process_data", {})
        amount = process_data.get("amount", 0)

        # å®¡æ‰¹å½“å‰èŠ‚ç‚¹
        self.workflow_engine.approve_node(instance_id, approver, approval_result, comment)

        if approval_result == "Approved":
            # æ ¹æ®é‡‘é¢å†³å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹
            current_node = process.get("current_node")
            definition = self.workflow_engine.process_definitions[process["process_id"]]

            # è·å–ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆè€ƒè™‘æ¡ä»¶ï¼‰
            next_node = self._get_next_node_with_condition(
                definition, current_node, amount
            )

            if next_node:
                # æ›´æ–°å½“å‰èŠ‚ç‚¹
                process["current_node"] = next_node["node_id"]
                # åˆ†é…ä»»åŠ¡
                if next_node.get("assignee"):
                    self.workflow_engine.assign_task(
                        instance_id,
                        next_node["node_id"],
                        next_node["assignee"]
                    )

    def _get_next_node_with_condition(self, definition: Dict, current_node_id: str,
                                     amount: float) -> Optional[Dict]:
        """æ ¹æ®æ¡ä»¶è·å–ä¸‹ä¸€ä¸ªèŠ‚ç‚¹"""
        nodes = definition.get("process_definition", {}).get("process_nodes", [])
        current_node = None

        for node in nodes:
            if node.get("node_id") == current_node_id:
                current_node = node
                break

        if not current_node:
            return None

        current_order = current_node.get("node_order", 0)

        # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
        for node in nodes:
            node_order = node.get("node_order", 0)
            if node_order > current_order:
                # æ£€æŸ¥æ¡ä»¶
                condition = node.get("condition")
                if condition:
                    if condition == "amount > 10000" and amount <= 10000:
                        continue
                    if condition == "amount > 50000" and amount <= 50000:
                        continue
                return node

        return None

async def multi_level_approval_example():
    """å¤šçº§å®¡æ‰¹æµç¨‹ç¤ºä¾‹"""
    storage = OAStorage("postgresql://user:pass@localhost/oa")
    workflow_engine = WorkflowEngine(storage)
    approval_process = MultiLevelApprovalProcess(workflow_engine, storage)

    # å®šä¹‰æµç¨‹
    approval_process.define_purchase_approval_process()

    # å¯åŠ¨å®¡æ‰¹æµç¨‹ï¼ˆé‡‘é¢15000ï¼Œéœ€è¦è´¢åŠ¡ç»ç†å®¡æ‰¹ï¼‰
    instance_id = approval_process.start_purchase_approval(
        "user001",
        15000.0,
        [{"item": "åŠå…¬ç”¨å“", "quantity": 100}]
    )

    print(f"Started approval process: {instance_id}")

    # éƒ¨é—¨ç»ç†å®¡æ‰¹
    print("\nDepartment manager approving...")
    approval_process.approve_with_condition(
        instance_id,
        "dept_manager",
        "Approved",
        "åŒæ„é‡‡è´­"
    )

    # è´¢åŠ¡ç»ç†å®¡æ‰¹ï¼ˆå› ä¸ºé‡‘é¢>10000ï¼‰
    print("\nFinance manager approving...")
    approval_process.approve_with_condition(
        instance_id,
        "finance_manager",
        "Approved",
        "åŒæ„é‡‡è´­"
    )

    # æ£€æŸ¥æµç¨‹çŠ¶æ€
    status = workflow_engine.get_process_status(instance_id)
    print(f"\nProcess status: {status['current_status']}")
    print(f"Current node: {status['current_node']}")

    storage.close()

if __name__ == "__main__":
    asyncio.run(multi_level_approval_example())
```

---

## 9. æ¡ˆä¾‹8ï¼šæ–‡æ¡£ç‰ˆæœ¬å¯¹æ¯”

### 9.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
ä¼ä¸šéœ€è¦å¯¹æ¯”æ–‡æ¡£çš„ä¸åŒç‰ˆæœ¬ï¼ŒæŸ¥çœ‹ç‰ˆæœ¬ä¹‹é—´çš„å·®å¼‚ï¼Œäº†è§£æ–‡æ¡£çš„å˜æ›´å†å²ã€‚è¿™å¯¹äºæ–‡æ¡£å®¡æŸ¥å’Œç‰ˆæœ¬ç®¡ç†éå¸¸é‡è¦ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦æå–æ–‡æ¡£å†…å®¹
- éœ€è¦å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬çš„å·®å¼‚
- éœ€è¦é«˜äº®æ˜¾ç¤ºå˜æ›´å†…å®¹
- éœ€è¦ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨æ–‡æ¡£å†…å®¹è¡¨å­˜å‚¨æ–‡æ¡£çš„æ–‡æœ¬å†…å®¹ï¼Œå®ç°ç‰ˆæœ¬å¯¹æ¯”ç®—æ³•ï¼Œç”Ÿæˆå·®å¼‚æŠ¥å‘Šã€‚

### 9.2 å®ç°ä»£ç 

**å®Œæ•´çš„æ–‡æ¡£ç‰ˆæœ¬å¯¹æ¯”å®ç°**ï¼š

```python
import difflib
from typing import List, Dict, Tuple
from oa_storage import OAStorage
from document_version_manager import DocumentVersionManager

class DocumentVersionComparator:
    """æ–‡æ¡£ç‰ˆæœ¬å¯¹æ¯”å™¨"""

    def __init__(self, storage: OAStorage):
        self.storage = storage

    def compare_versions(self, document_id: str, version1: int, version2: int) -> Dict:
        """å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬"""
        # è·å–ç‰ˆæœ¬å†…å®¹
        content1 = self._get_version_content(document_id, version1)
        content2 = self._get_version_content(document_id, version2)

        if not content1 or not content2:
            return {"error": "Version content not found"}

        # å¯¹æ¯”å†…å®¹
        diff = self._compute_diff(content1, content2)

        return {
            "document_id": document_id,
            "version1": version1,
            "version2": version2,
            "diff": diff,
            "statistics": self._compute_statistics(diff)
        }

    def _get_version_content(self, document_id: str, version: int) -> Optional[str]:
        """è·å–ç‰ˆæœ¬å†…å®¹"""
        self.storage.cur.execute("""
            SELECT content_text FROM document_contents
            WHERE document_id = %s AND version_number = %s
        """, (document_id, version))
        result = self.storage.cur.fetchone()
        return result[0] if result else None

    def _compute_diff(self, content1: str, content2: str) -> List[Dict]:
        """è®¡ç®—å·®å¼‚"""
        lines1 = content1.splitlines(keepends=True)
        lines2 = content2.splitlines(keepends=True)

        diff = difflib.unified_diff(
            lines1, lines2,
            lineterm='',
            n=3
        )

        diff_list = []
        for line in diff:
            if line.startswith('---') or line.startswith('+++'):
                continue
            elif line.startswith('@@'):
                diff_list.append({"type": "header", "content": line})
            elif line.startswith('-'):
                diff_list.append({"type": "deleted", "content": line[1:]})
            elif line.startswith('+'):
                diff_list.append({"type": "added", "content": line[1:]})
            else:
                diff_list.append({"type": "unchanged", "content": line})

        return diff_list

    def _compute_statistics(self, diff: List[Dict]) -> Dict:
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "added_lines": 0,
            "deleted_lines": 0,
            "unchanged_lines": 0,
            "total_changes": 0
        }

        for item in diff:
            if item["type"] == "added":
                stats["added_lines"] += 1
                stats["total_changes"] += 1
            elif item["type"] == "deleted":
                stats["deleted_lines"] += 1
                stats["total_changes"] += 1
            elif item["type"] == "unchanged":
                stats["unchanged_lines"] += 1

        return stats

    def generate_diff_report(self, document_id: str, version1: int, version2: int) -> str:
        """ç”Ÿæˆå·®å¼‚æŠ¥å‘Š"""
        comparison = self.compare_versions(document_id, version1, version2)

        report = f"Document Version Comparison Report\n"
        report += f"{'='*50}\n\n"
        report += f"Document ID: {comparison['document_id']}\n"
        report += f"Version {comparison['version1']} vs Version {comparison['version2']}\n\n"

        stats = comparison['statistics']
        report += f"Statistics:\n"
        report += f"  Added lines: {stats['added_lines']}\n"
        report += f"  Deleted lines: {stats['deleted_lines']}\n"
        report += f"  Unchanged lines: {stats['unchanged_lines']}\n"
        report += f"  Total changes: {stats['total_changes']}\n\n"

        report += f"Differences:\n"
        report += f"{'-'*50}\n"

        for item in comparison['diff']:
            if item['type'] == 'added':
                report += f"+ {item['content']}"
            elif item['type'] == 'deleted':
                report += f"- {item['content']}"
            elif item['type'] == 'header':
                report += f"{item['content']}\n"

        return report

def version_comparison_example():
    """æ–‡æ¡£ç‰ˆæœ¬å¯¹æ¯”ç¤ºä¾‹"""
    storage = OAStorage("postgresql://user:pass@localhost/oa")
    comparator = DocumentVersionComparator(storage)

    document_id = "DOC001"

    # å¯¹æ¯”ç‰ˆæœ¬1å’Œç‰ˆæœ¬2
    comparison = comparator.compare_versions(document_id, 1, 2)
    print("Version Comparison:")
    print(f"  Added lines: {comparison['statistics']['added_lines']}")
    print(f"  Deleted lines: {comparison['statistics']['deleted_lines']}")

    # ç”Ÿæˆå·®å¼‚æŠ¥å‘Š
    report = comparator.generate_diff_report(document_id, 1, 2)
    print("\nDiff Report:")
    print(report)

    storage.close()

if __name__ == "__main__":
    version_comparison_example()
```

---

## 10. æ¡ˆä¾‹9ï¼šæµç¨‹æ•ˆç‡åˆ†æ

### 10.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
ä¼ä¸šéœ€è¦åˆ†æå®¡æ‰¹æµç¨‹çš„æ•ˆç‡ï¼Œæ‰¾å‡ºæµç¨‹ç“¶é¢ˆï¼Œä¼˜åŒ–æµç¨‹è®¾è®¡ã€‚é€šè¿‡åˆ†ææµç¨‹çš„æ‰§è¡Œæ—¶é—´ã€å„èŠ‚ç‚¹çš„å¤„ç†æ—¶é—´ã€å®¡æ‰¹é€šè¿‡ç‡ç­‰æŒ‡æ ‡ï¼Œå¸®åŠ©ä¼ä¸šæ”¹è¿›æµç¨‹æ•ˆç‡ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦æ”¶é›†æµç¨‹æ‰§è¡Œæ•°æ®
- éœ€è¦è®¡ç®—æµç¨‹æ€§èƒ½æŒ‡æ ‡
- éœ€è¦è¯†åˆ«æµç¨‹ç“¶é¢ˆ
- éœ€è¦ç”Ÿæˆåˆ†ææŠ¥å‘Š

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨æµç¨‹ç›‘æ§å™¨æ”¶é›†æµç¨‹æ‰§è¡Œæ•°æ®ï¼Œè®¡ç®—æ€§èƒ½æŒ‡æ ‡ï¼Œç”Ÿæˆæµç¨‹æ•ˆç‡åˆ†ææŠ¥å‘Šã€‚

### 10.2 å®ç°ä»£ç 

**å®Œæ•´çš„æµç¨‹æ•ˆç‡åˆ†æå®ç°**ï¼š

```python
from typing import Dict, List
from datetime import datetime, timedelta
from process_monitor import ProcessMonitor
from workflow_engine import WorkflowEngine
from oa_storage import OAStorage

class ProcessEfficiencyAnalyzer:
    """æµç¨‹æ•ˆç‡åˆ†æå™¨"""

    def __init__(self, process_monitor: ProcessMonitor):
        self.process_monitor = process_monitor

    def analyze_process_efficiency(self, process_id: str,
                                  start_date: datetime = None,
                                  end_date: datetime = None) -> Dict:
        """åˆ†ææµç¨‹æ•ˆç‡"""
        # è·å–æ€§èƒ½æŒ‡æ ‡
        metrics = self.process_monitor.get_process_performance_metrics(
            process_id, start_date, end_date
        )

        # è·å–æµç¨‹ç»Ÿè®¡
        stats = self.process_monitor.workflow_engine.get_process_statistics(
            process_id, start_date, end_date
        )

        # åˆ†æç“¶é¢ˆèŠ‚ç‚¹
        bottlenecks = self._identify_bottlenecks(process_id, start_date, end_date)

        return {
            "process_id": process_id,
            "metrics": metrics,
            "statistics": stats,
            "bottlenecks": bottlenecks,
            "recommendations": self._generate_recommendations(metrics, bottlenecks)
        }

    def _identify_bottlenecks(self, process_id: str,
                             start_date: datetime = None,
                             end_date: datetime = None) -> List[Dict]:
        """è¯†åˆ«æµç¨‹ç“¶é¢ˆ"""
        # è¿™é‡Œéœ€è¦æŸ¥è¯¢å„èŠ‚ç‚¹çš„å¹³å‡å¤„ç†æ—¶é—´
        # ç®€åŒ–å®ç°ï¼Œå®é™…éœ€è¦ä»æ•°æ®åº“æŸ¥è¯¢èŠ‚ç‚¹å¤„ç†æ—¶é—´
        bottlenecks = []

        # ç¤ºä¾‹ï¼šå‡è®¾æŸäº›èŠ‚ç‚¹å¤„ç†æ—¶é—´è¾ƒé•¿
        # å®é™…å®ç°éœ€è¦ä»task_assignmentsè¡¨æŸ¥è¯¢æ•°æ®

        return bottlenecks

    def _generate_recommendations(self, metrics: Dict, bottlenecks: List[Dict]) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        if metrics.get("average_duration_hours", 0) > 24:
            recommendations.append("æµç¨‹å¹³å‡å¤„ç†æ—¶é—´è¶…è¿‡24å°æ—¶ï¼Œå»ºè®®ä¼˜åŒ–æµç¨‹è®¾è®¡")

        if metrics.get("rejection_rate", 0) > 0.3:
            recommendations.append("æµç¨‹æ‹’ç»ç‡è¶…è¿‡30%ï¼Œå»ºè®®æ£€æŸ¥å®¡æ‰¹æ¡ä»¶è®¾ç½®")

        if metrics.get("completion_rate", 0) < 0.7:
            recommendations.append("æµç¨‹å®Œæˆç‡ä½äº70%ï¼Œå»ºè®®æ£€æŸ¥æµç¨‹è®¾è®¡")

        return recommendations

    def generate_efficiency_report(self, process_id: str,
                                   start_date: datetime = None,
                                   end_date: datetime = None) -> str:
        """ç”Ÿæˆæ•ˆç‡åˆ†ææŠ¥å‘Š"""
        analysis = self.analyze_process_efficiency(process_id, start_date, end_date)

        report = f"Process Efficiency Analysis Report\n"
        report += f"{'='*60}\n\n"
        report += f"Process ID: {analysis['process_id']}\n"
        if start_date:
            report += f"Start Date: {start_date.strftime('%Y-%m-%d')}\n"
        if end_date:
            report += f"End Date: {end_date.strftime('%Y-%m-%d')}\n"
        report += f"\n"

        metrics = analysis['metrics']
        report += f"Performance Metrics:\n"
        report += f"  Total Processes: {metrics['total_processes']}\n"
        report += f"  Completion Rate: {metrics['completion_rate']*100:.1f}%\n"
        report += f"  Rejection Rate: {metrics['rejection_rate']*100:.1f}%\n"
        report += f"  Average Duration: {metrics['average_duration_hours']:.2f} hours\n"
        report += f"  Throughput: {metrics['throughput_per_day']:.2f} processes/day\n"
        report += f"\n"

        stats = analysis['statistics']
        report += f"Statistics:\n"
        report += f"  Completed: {stats['completed_processes']}\n"
        report += f"  In Progress: {stats['in_progress_processes']}\n"
        report += f"  Rejected: {stats['rejected_processes']}\n"
        report += f"\n"

        recommendations = analysis['recommendations']
        if recommendations:
            report += f"Recommendations:\n"
            for i, rec in enumerate(recommendations, 1):
                report += f"  {i}. {rec}\n"

        return report

def process_efficiency_analysis_example():
    """æµç¨‹æ•ˆç‡åˆ†æç¤ºä¾‹"""
    storage = OAStorage("postgresql://user:pass@localhost/oa")
    workflow_engine = WorkflowEngine(storage)
    process_monitor = ProcessMonitor(workflow_engine, storage)
    analyzer = ProcessEfficiencyAnalyzer(process_monitor)

    process_id = "purchase_approval"
    start_date = datetime.now() - timedelta(days=30)
    end_date = datetime.now()

    # åˆ†ææµç¨‹æ•ˆç‡
    analysis = analyzer.analyze_process_efficiency(
        process_id, start_date, end_date
    )

    print("Process Efficiency Analysis:")
    print(f"  Completion Rate: {analysis['metrics']['completion_rate']*100:.1f}%")
    print(f"  Average Duration: {analysis['metrics']['average_duration_hours']:.2f} hours")

    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_efficiency_report(
        process_id, start_date, end_date
    )
    print("\nEfficiency Report:")
    print(report)

    storage.close()

if __name__ == "__main__":
    process_efficiency_analysis_example()
```

---

## 11. æ¡ˆä¾‹10ï¼šçŸ¥è¯†åº“ç®¡ç†

### 11.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
ä¼ä¸šéœ€è¦å»ºç«‹çŸ¥è¯†åº“ç³»ç»Ÿï¼Œç®¡ç†ä¼ä¸šæ–‡æ¡£ã€ç»éªŒæ€»ç»“ã€æœ€ä½³å®è·µç­‰çŸ¥è¯†èµ„äº§ã€‚çŸ¥è¯†åº“éœ€è¦æ”¯æŒåˆ†ç±»ç®¡ç†ã€æ ‡ç­¾ç®¡ç†ã€å…¨æ–‡æ£€ç´¢ã€æƒé™æ§åˆ¶ç­‰åŠŸèƒ½ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦å®ç°çŸ¥è¯†åˆ†ç±»ä½“ç³»
- éœ€è¦æ”¯æŒæ ‡ç­¾ç®¡ç†
- éœ€è¦å®ç°å…¨æ–‡æ£€ç´¢
- éœ€è¦æ”¯æŒçŸ¥è¯†æ¨è

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨æ–‡æ¡£å†…å®¹è¡¨çš„å…¨æ–‡ç´¢å¼•å®ç°çŸ¥è¯†æ£€ç´¢ï¼Œä½¿ç”¨åˆ†ç±»å’Œæ ‡ç­¾ç®¡ç†çŸ¥è¯†ç»„ç»‡ï¼Œå®ç°çŸ¥è¯†æ¨èç®—æ³•ã€‚

### 11.2 Schemaå®šä¹‰

**çŸ¥è¯†åº“ç®¡ç†Schema**ï¼š

```json
{
  "knowledge_base_id": "KB001",
  "knowledge_base_name": "ä¼ä¸šçŸ¥è¯†åº“",
  "categories": [
    {
      "category_id": "CAT001",
      "category_name": "æŠ€æœ¯æ–‡æ¡£",
      "parent_category": null,
      "description": "æŠ€æœ¯ç›¸å…³æ–‡æ¡£"
    },
    {
      "category_id": "CAT002",
      "category_name": "ä¸šåŠ¡æµç¨‹",
      "parent_category": null,
      "description": "ä¸šåŠ¡æµç¨‹æ–‡æ¡£"
    }
  ],
  "tags": [
    {"tag_id": "TAG001", "tag_name": "Python"},
    {"tag_id": "TAG002", "tag_name": "æ•°æ®åº“"},
    {"tag_id": "TAG003", "tag_name": "å®¡æ‰¹æµç¨‹"}
  ]
}
```

### 11.3 å®ç°ä»£ç 

**å®Œæ•´çš„çŸ¥è¯†åº“ç®¡ç†å®ç°**ï¼š

```python
from typing import Dict, List, Optional
from oa_storage import OAStorage

class KnowledgeBaseManager:
    """çŸ¥è¯†åº“ç®¡ç†å™¨"""

    def __init__(self, storage: OAStorage):
        self.storage = storage

    def create_category(self, category_id: str, category_name: str,
                       parent_category: str = None, description: str = None):
        """åˆ›å»ºçŸ¥è¯†åˆ†ç±»"""
        self.storage.cur.execute("""
            INSERT INTO knowledge_categories (
                category_id, category_name, parent_category, description
            ) VALUES (%s, %s, %s, %s)
            ON CONFLICT (category_id) DO UPDATE SET
                category_name = EXCLUDED.category_name,
                parent_category = EXCLUDED.parent_category,
                description = EXCLUDED.description
        """, (category_id, category_name, parent_category, description))
        self.storage.conn.commit()

    def add_document_to_knowledge_base(self, document_id: str, category_id: str,
                                      tags: List[str] = None):
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        # å…³è”æ–‡æ¡£å’Œåˆ†ç±»
        self.storage.cur.execute("""
            INSERT INTO knowledge_documents (
                document_id, category_id
            ) VALUES (%s, %s)
            ON CONFLICT (document_id) DO UPDATE SET
                category_id = EXCLUDED.category_id
        """, (document_id, category_id))

        # æ·»åŠ æ ‡ç­¾
        if tags:
            for tag in tags:
                self.storage.cur.execute("""
                    INSERT INTO document_tags (
                        document_id, tag_name
                    ) VALUES (%s, %s)
                    ON CONFLICT (document_id, tag_name) DO NOTHING
                """, (document_id, tag))

        self.storage.conn.commit()

    def search_knowledge(self, query: str, category_id: str = None,
                        tags: List[str] = None, limit: int = 20) -> List[Dict]:
        """æœç´¢çŸ¥è¯†"""
        # å…¨æ–‡æœç´¢
        results = self.storage.search_documents_fulltext(query, limit)

        # è¿‡æ»¤åˆ†ç±»
        if category_id:
            results = [r for r in results if self._document_in_category(r['document_id'], category_id)]

        # è¿‡æ»¤æ ‡ç­¾
        if tags:
            filtered_results = []
            for result in results:
                doc_tags = self._get_document_tags(result['document_id'])
                if any(tag in doc_tags for tag in tags):
                    filtered_results.append(result)
            results = filtered_results

        return results

    def recommend_knowledge(self, document_id: str, limit: int = 5) -> List[Dict]:
        """æ¨èç›¸å…³çŸ¥è¯†"""
        # è·å–æ–‡æ¡£çš„æ ‡ç­¾å’Œåˆ†ç±»
        doc_tags = self._get_document_tags(document_id)
        doc_category = self._get_document_category(document_id)

        # æŸ¥æ‰¾ç›¸åŒæ ‡ç­¾æˆ–åˆ†ç±»çš„æ–‡æ¡£
        recommendations = []

        if doc_tags:
            for tag in doc_tags:
                similar_docs = self.search_knowledge("", tags=[tag], limit=limit)
                for doc in similar_docs:
                    if doc['document_id'] != document_id:
                        recommendations.append(doc)

        if doc_category:
            category_docs = self._get_documents_in_category(doc_category, limit)
            for doc in category_docs:
                if doc['document_id'] != document_id:
                    recommendations.append(doc)

        # å»é‡å¹¶æŒ‰ç›¸å…³æ€§æ’åº
        unique_recommendations = {}
        for rec in recommendations:
            doc_id = rec['document_id']
            if doc_id not in unique_recommendations:
                unique_recommendations[doc_id] = rec

        return list(unique_recommendations.values())[:limit]

    def _document_in_category(self, document_id: str, category_id: str) -> bool:
        """æ£€æŸ¥æ–‡æ¡£æ˜¯å¦åœ¨æŒ‡å®šåˆ†ç±»"""
        self.storage.cur.execute("""
            SELECT COUNT(*) FROM knowledge_documents
            WHERE document_id = %s AND category_id = %s
        """, (document_id, category_id))
        return self.storage.cur.fetchone()[0] > 0

    def _get_document_tags(self, document_id: str) -> List[str]:
        """è·å–æ–‡æ¡£æ ‡ç­¾"""
        self.storage.cur.execute("""
            SELECT tag_name FROM document_tags
            WHERE document_id = %s
        """, (document_id,))
        return [row[0] for row in self.storage.cur.fetchall()]

    def _get_document_category(self, document_id: str) -> Optional[str]:
        """è·å–æ–‡æ¡£åˆ†ç±»"""
        self.storage.cur.execute("""
            SELECT category_id FROM knowledge_documents
            WHERE document_id = %s
        """, (document_id,))
        result = self.storage.cur.fetchone()
        return result[0] if result else None

    def _get_documents_in_category(self, category_id: str, limit: int) -> List[Dict]:
        """è·å–åˆ†ç±»ä¸‹çš„æ–‡æ¡£"""
        self.storage.cur.execute("""
            SELECT d.document_id, d.document_title, d.document_type
            FROM documents d
            JOIN knowledge_documents kd ON d.document_id = kd.document_id
            WHERE kd.category_id = %s
            ORDER BY d.created_at DESC
            LIMIT %s
        """, (category_id, limit))

        return [
            {
                "document_id": row[0],
                "document_title": row[1],
                "document_type": row[2]
            }
            for row in self.storage.cur.fetchall()
        ]

def knowledge_base_example():
    """çŸ¥è¯†åº“ç®¡ç†ç¤ºä¾‹"""
    storage = OAStorage("postgresql://user:pass@localhost/oa")
    kb_manager = KnowledgeBaseManager(storage)

    # åˆ›å»ºåˆ†ç±»
    kb_manager.create_category("CAT001", "æŠ€æœ¯æ–‡æ¡£", None, "æŠ€æœ¯ç›¸å…³æ–‡æ¡£")
    kb_manager.create_category("CAT002", "ä¸šåŠ¡æµç¨‹", None, "ä¸šåŠ¡æµç¨‹æ–‡æ¡£")

    # æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“
    kb_manager.add_document_to_knowledge_base(
        "DOC001",
        "CAT001",
        ["Python", "æ•°æ®åº“"]
    )

    # æœç´¢çŸ¥è¯†
    results = kb_manager.search_knowledge("Python", category_id="CAT001")
    print(f"Found {len(results)} documents")
    for result in results:
        print(f"  {result['document_title']}")

    # æ¨èç›¸å…³çŸ¥è¯†
    recommendations = kb_manager.recommend_knowledge("DOC001")
    print(f"\nRecommended documents: {len(recommendations)}")
    for rec in recommendations:
        print(f"  {rec['document_title']}")

    storage.close()

if __name__ == "__main__":
    knowledge_base_example()
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `04_Transformation.md` - è½¬æ¢ä½“ç³»

---

## 12. æ¡ˆä¾‹11ï¼šæ–‡æ¡£æ™ºèƒ½åˆ†æç³»ç»Ÿ

### 12.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
æ–‡æ¡£æ™ºèƒ½åˆ†æç³»ç»Ÿä½¿ç”¨AIæŠ€æœ¯åˆ†ææ–‡æ¡£å†…å®¹ï¼Œ
æå–å…³é”®ä¿¡æ¯ã€ç”Ÿæˆæ‘˜è¦ã€è¯†åˆ«ä¸»é¢˜ï¼Œæé«˜æ–‡æ¡£å¤„ç†æ•ˆç‡ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦æ–‡æ¡£å†…å®¹è§£æ
- éœ€è¦AIæ–‡æœ¬åˆ†æ
- éœ€è¦ä¿¡æ¯æå–
- éœ€è¦æ‘˜è¦ç”Ÿæˆ

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨OA_Schemaå®šä¹‰æ–‡æ¡£åˆ†æç»“æ„ï¼Œ
ä½¿ç”¨AIæ¨¡å‹è¿›è¡Œæ–‡æ¡£åˆ†æï¼Œ
ä½¿ç”¨OAStorageå­˜å‚¨åˆ†æç»“æœã€‚

### 12.2 Schemaå®šä¹‰

**æ–‡æ¡£æ™ºèƒ½åˆ†æSchema**ï¼š

```dsl
schema DocumentIntelligentAnalysis {
  analysis_session_id: String @value("DOC-ANALYSIS-20250121-001") @required
  document_id: String @value("DOC-001") @required
  analysis_time: DateTime @value("2025-01-21T10:00:00") @required

  document_info: {
    title: String @value("é¡¹ç›®è®¡åˆ’ä¹¦")
    document_type: Enum { Word } @value(Word)
    word_count: Integer @value(5000)
    page_count: Integer @value(10)
  } @required

  ai_analysis: {
    summary: String @value("æœ¬æ–‡æ¡£æè¿°äº†2025å¹´Q1é¡¹ç›®è®¡åˆ’...")
    key_topics: [String] @value(["é¡¹ç›®ç®¡ç†", "èµ„æºåˆ†é…", "æ—¶é—´è§„åˆ’"])
    key_entities: [
      {
        entity_type: String @value("Person")
        entity_name: String @value("å¼ ä¸‰")
        mention_count: Integer @value(5)
      }
    ]
    sentiment: Enum { Neutral } @value(Neutral)
    language: String @value("zh-CN")
  } @required

  extracted_information: {
    dates: [Date] @value(["2025-01-21", "2025-03-31"])
    deadlines: [Date] @value(["2025-03-31"])
    budget_info: {
      total_budget: Decimal @value(1000000.0)
      currency: String @value("RMB")
    }
    action_items: [
      {
        item: String @value("å®Œæˆéœ€æ±‚åˆ†æ")
        assignee: String @value("å¼ ä¸‰")
        due_date: Date @value("2025-02-15")
      }
    ]
  } @required
} @standard("ODF/OOXML")
```

### 12.3 å®ç°ä»£ç 

```python
from oa_storage import OAStorage
from datetime import datetime

def document_intelligent_analysis():
    """æ–‡æ¡£æ™ºèƒ½åˆ†æç³»ç»Ÿç¤ºä¾‹"""
    storage = OAStorage("postgresql://user:password@localhost/oa_db")

    # æ–‡æ¡£ä¿¡æ¯
    document_info = {
        "document_id": "DOC-001",
        "title": "é¡¹ç›®è®¡åˆ’ä¹¦",
        "document_type": "Word",
        "word_count": 5000,
        "page_count": 10
    }

    # AIæ–‡æ¡£åˆ†æï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
    def analyze_document(document_id, content):
        """AIæ–‡æ¡£åˆ†æ"""
        # ç”Ÿæˆæ‘˜è¦ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
        summary = "æœ¬æ–‡æ¡£æè¿°äº†2025å¹´Q1é¡¹ç›®è®¡åˆ’ï¼ŒåŒ…æ‹¬é¡¹ç›®ç›®æ ‡ã€èµ„æºåˆ†é…ã€æ—¶é—´è§„åˆ’ç­‰å†…å®¹ã€‚"

        # æå–å…³é”®ä¸»é¢˜
        key_topics = ["é¡¹ç›®ç®¡ç†", "èµ„æºåˆ†é…", "æ—¶é—´è§„åˆ’"]

        # æå–å…³é”®å®ä½“
        key_entities = [
            {
                "entity_type": "Person",
                "entity_name": "å¼ ä¸‰",
                "mention_count": 5
            }
        ]

        # æƒ…æ„Ÿåˆ†æ
        sentiment = "Neutral"

        # æå–ä¿¡æ¯
        extracted_info = {
            "dates": ["2025-01-21", "2025-03-31"],
            "deadlines": ["2025-03-31"],
            "budget_info": {
                "total_budget": 1000000.0,
                "currency": "RMB"
            },
            "action_items": [
                {
                    "item": "å®Œæˆéœ€æ±‚åˆ†æ",
                    "assignee": "å¼ ä¸‰",
                    "due_date": "2025-02-15"
                }
            ]
        }

        return {
            "summary": summary,
            "key_topics": key_topics,
            "key_entities": key_entities,
            "sentiment": sentiment,
            "language": "zh-CN",
            "extracted_information": extracted_info
        }

    # æ‰§è¡Œæ–‡æ¡£åˆ†æ
    content = "..."  # æ–‡æ¡£å†…å®¹
    ai_analysis = analyze_document(document_info["document_id"], content)

    # å­˜å‚¨åˆ†æç»“æœ
    analysis_data = {
        "analysis_session_id": "DOC-ANALYSIS-20250121-001",
        "document_id": document_info["document_id"],
        "analysis_time": datetime.now(),
        "document_title": document_info["title"],
        "document_type": document_info["document_type"],
        "word_count": document_info["word_count"],
        "summary": ai_analysis["summary"],
        "key_topics": ai_analysis["key_topics"],
        "key_entities": ai_analysis["key_entities"],
        "sentiment": ai_analysis["sentiment"],
        "extracted_dates": ai_analysis["extracted_information"]["dates"],
        "extracted_deadlines": ai_analysis["extracted_information"]["deadlines"],
        "budget_total": ai_analysis["extracted_information"]["budget_info"]["total_budget"],
        "action_items": ai_analysis["extracted_information"]["action_items"]
    }

    # å­˜å‚¨åˆ°æ•°æ®åº“
    analysis_id = storage.store_document_analysis(analysis_data)
    print(f"Document analysis stored: {analysis_id}")

    print(f"\nDocument Intelligent Analysis Results:")
    print(f"  Document: {document_info['title']}")
    print(f"  Summary: {ai_analysis['summary'][:100]}...")
    print(f"  Key topics: {', '.join(ai_analysis['key_topics'])}")
    print(f"  Key entities: {len(ai_analysis['key_entities'])}")
    print(f"  Action items: {len(ai_analysis['extracted_information']['action_items'])}")

    return analysis_data

if __name__ == "__main__":
    document_intelligent_analysis()
```

---

## 13. æ¡ˆä¾‹12ï¼šæµç¨‹è‡ªåŠ¨åŒ–ç³»ç»Ÿ

### 13.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
æµç¨‹è‡ªåŠ¨åŒ–ç³»ç»Ÿè‡ªåŠ¨æ‰§è¡Œé‡å¤æ€§ä¸šåŠ¡æµç¨‹ï¼Œ
ä¾‹å¦‚è‡ªåŠ¨å®¡æ‰¹ã€è‡ªåŠ¨é€šçŸ¥ã€è‡ªåŠ¨æ•°æ®åŒæ­¥ç­‰ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦æµç¨‹è§„åˆ™å®šä¹‰
- éœ€è¦æ¡ä»¶åˆ¤æ–­
- éœ€è¦è‡ªåŠ¨æ‰§è¡Œ
- éœ€è¦æ‰§è¡Œç›‘æ§

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨OA_Schemaå®šä¹‰æµç¨‹è‡ªåŠ¨åŒ–è§„åˆ™ï¼Œ
ä½¿ç”¨BPMNå¼•æ“æ‰§è¡Œè‡ªåŠ¨åŒ–æµç¨‹ï¼Œ
ä½¿ç”¨OAStorageå­˜å‚¨è‡ªåŠ¨åŒ–æ•°æ®ã€‚

### 13.2 Schemaå®šä¹‰

**æµç¨‹è‡ªåŠ¨åŒ–Schema**ï¼š

```dsl
schema ProcessAutomation {
  automation_id: String @value("AUTO-PROC-20250121-001") @required
  automation_name: String @value("è‡ªåŠ¨å®¡æ‰¹æµç¨‹") @required
  process_id: String @value("PROC-001") @required

  automation_rules: [
    {
      rule_id: String @value("RULE-001")
      rule_name: String @value("é‡‘é¢è‡ªåŠ¨å®¡æ‰¹")
      condition: {
        field: String @value("amount")
        operator: Enum { LessThan } @value(LessThan)
        value: Decimal @value(10000.0)
      }
      action: {
        action_type: Enum { AutoApprove } @value(AutoApprove)
        approver: String @value("SYSTEM")
        notification: Boolean @value(true)
      }
    }
  ] @required

  automation_status: {
    status: Enum { Active } @value(Active)
    execution_count: Integer @value(50)
    success_rate: Decimal @value(0.98) @range(0.0, 1.0)
    last_executed: DateTime @value("2025-01-21T10:00:00")
  } @required
} @standard("BPMN")
```

### 13.3 å®ç°ä»£ç 

```python
from oa_storage import OAStorage
from datetime import datetime

def process_automation_system():
    """æµç¨‹è‡ªåŠ¨åŒ–ç³»ç»Ÿç¤ºä¾‹"""
    storage = OAStorage("postgresql://user:password@localhost/oa_db")

    # è‡ªåŠ¨åŒ–è§„åˆ™
    automation_rules = [
        {
            "rule_id": "RULE-001",
            "rule_name": "é‡‘é¢è‡ªåŠ¨å®¡æ‰¹",
            "condition": {
                "field": "amount",
                "operator": "LessThan",
                "value": 10000.0
            },
            "action": {
                "action_type": "AutoApprove",
                "approver": "SYSTEM",
                "notification": True
            }
        }
    ]

    # æ£€æŸ¥è‡ªåŠ¨åŒ–æ¡ä»¶
    def check_automation_condition(rule, process_data):
        """æ£€æŸ¥è‡ªåŠ¨åŒ–æ¡ä»¶"""
        field_value = process_data.get(rule["condition"]["field"])
        operator = rule["condition"]["operator"]
        threshold = rule["condition"]["value"]

        if operator == "LessThan":
            return field_value < threshold
        elif operator == "GreaterThan":
            return field_value > threshold
        elif operator == "Equals":
            return field_value == threshold
        return False

    # æ‰§è¡Œè‡ªåŠ¨åŒ–åŠ¨ä½œ
    def execute_automation_action(rule, process_id):
        """æ‰§è¡Œè‡ªåŠ¨åŒ–åŠ¨ä½œ"""
        action_type = rule["action"]["action_type"]

        if action_type == "AutoApprove":
            # è‡ªåŠ¨å®¡æ‰¹
            storage.approve_process(process_id, rule["action"]["approver"])

            # å‘é€é€šçŸ¥
            if rule["action"]["notification"]:
                storage.send_notification(process_id, "æµç¨‹å·²è‡ªåŠ¨å®¡æ‰¹")

            return True
        return False

    # å¤„ç†æµç¨‹
    process_data = {
        "process_id": "PROC-001",
        "amount": 5000.0,
        "applicant": "USER-001"
    }

    # æ£€æŸ¥å¹¶æ‰§è¡Œè‡ªåŠ¨åŒ–
    for rule in automation_rules:
        if check_automation_condition(rule, process_data):
            print(f"Automation rule triggered: {rule['rule_name']}")
            result = execute_automation_action(rule, process_data["process_id"])

            if result:
                # è®°å½•è‡ªåŠ¨åŒ–æ‰§è¡Œ
                automation_data = {
                    "automation_id": "AUTO-PROC-20250121-001",
                    "automation_name": "è‡ªåŠ¨å®¡æ‰¹æµç¨‹",
                    "process_id": process_data["process_id"],
                    "rule_id": rule["rule_id"],
                    "execution_time": datetime.now(),
                    "status": "Success"
                }

                storage.store_automation_event(automation_data)
                print(f"Automation executed successfully")

    return automation_data

if __name__ == "__main__":
    process_automation_system()
```

---

## 14. æ¡ˆä¾‹13ï¼šåä½œæ•ˆç‡åˆ†æç³»ç»Ÿ

### 14.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
åä½œæ•ˆç‡åˆ†æç³»ç»Ÿåˆ†æå›¢é˜Ÿåä½œæ•°æ®ï¼Œ
è¯„ä¼°åä½œæ•ˆç‡ï¼Œè¯†åˆ«åä½œç“¶é¢ˆï¼Œæä¾›ä¼˜åŒ–å»ºè®®ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦åä½œæ•°æ®æ”¶é›†
- éœ€è¦æ•ˆç‡æŒ‡æ ‡è®¡ç®—
- éœ€è¦ç“¶é¢ˆè¯†åˆ«
- éœ€è¦ä¼˜åŒ–å»ºè®®ç”Ÿæˆ

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨OA_Schemaæ•´åˆåä½œæ•°æ®ï¼Œ
ä½¿ç”¨æ•°æ®åˆ†æç®—æ³•è¿›è¡Œæ•ˆç‡åˆ†æï¼Œ
ä½¿ç”¨OAStorageå­˜å‚¨åˆ†æç»“æœã€‚

### 14.2 Schemaå®šä¹‰

**åä½œæ•ˆç‡åˆ†æSchema**ï¼š

```dsl
schema CollaborationEfficiencyAnalysis {
  analysis_session_id: String @value("COLLAB-ANALYSIS-20250121-001") @required
  team_id: String @value("TEAM-001") @required
  analysis_period: {
    start_date: Date @value("2025-01-01")
    end_date: Date @value("2025-01-21")
  } @required

  collaboration_metrics: {
    total_collaborations: Integer @value(150)
    average_response_time: Decimal @value(2.5) @unit("hours")
    collaboration_frequency: Decimal @value(7.1) @unit("per day")
    document_sharing_count: Integer @value(80)
    meeting_count: Integer @value(25)
    average_meeting_duration: Decimal @value(45.0) @unit("minutes")
  } @required

  efficiency_analysis: {
    overall_efficiency_score: Decimal @value(0.78) @range(0.0, 1.0)
    efficiency_level: Enum { Good } @value(Good)
    bottlenecks: [
      {
        bottleneck_type: String @value("Slow response time")
        severity: Enum { Medium } @value(Medium)
        impact: String @value("å½±å“ä»»åŠ¡å®Œæˆé€Ÿåº¦")
      }
    ]
    recommendations: [
      {
        recommendation: String @value("ä¼˜åŒ–å“åº”æ—¶é—´")
        priority: Enum { High } @value(High)
        expected_improvement: Decimal @value(0.15)
      }
    ]
  } @required
} @standard("BPMN")
```

### 14.3 å®ç°ä»£ç 

```python
from oa_storage import OAStorage
from datetime import datetime, date, timedelta

def collaboration_efficiency_analysis():
    """åä½œæ•ˆç‡åˆ†æç³»ç»Ÿç¤ºä¾‹"""
    storage = OAStorage("postgresql://user:password@localhost/oa_db")

    # åä½œæŒ‡æ ‡æ•°æ®
    team_id = "TEAM-001"
    start_date = date(2025, 1, 1)
    end_date = date(2025, 1, 21)

    collaboration_metrics = {
        "total_collaborations": 150,
        "average_response_time": 2.5,  # hours
        "collaboration_frequency": 7.1,  # per day
        "document_sharing_count": 80,
        "meeting_count": 25,
        "average_meeting_duration": 45.0  # minutes
    }

    # æ•ˆç‡åˆ†æç®—æ³•
    def analyze_efficiency(metrics):
        """åˆ†æåä½œæ•ˆç‡"""
        efficiency_score = 0.0
        bottlenecks = []
        recommendations = []

        # å“åº”æ—¶é—´è¯„åˆ†
        if metrics["average_response_time"] <= 1.0:
            response_score = 1.0
        elif metrics["average_response_time"] <= 2.0:
            response_score = 0.8
        else:
            response_score = 0.6
            bottlenecks.append({
                "bottleneck_type": "Slow response time",
                "severity": "Medium",
                "impact": "å½±å“ä»»åŠ¡å®Œæˆé€Ÿåº¦"
            })
            recommendations.append({
                "recommendation": "ä¼˜åŒ–å“åº”æ—¶é—´",
                "priority": "High",
                "expected_improvement": 0.15
            })

        # åä½œé¢‘ç‡è¯„åˆ†
        if metrics["collaboration_frequency"] >= 10:
            frequency_score = 1.0
        elif metrics["collaboration_frequency"] >= 5:
            frequency_score = 0.8
        else:
            frequency_score = 0.6

        # ä¼šè®®æ•ˆç‡è¯„åˆ†
        if metrics["average_meeting_duration"] <= 30:
            meeting_score = 1.0
        elif metrics["average_meeting_duration"] <= 60:
            meeting_score = 0.8
        else:
            meeting_score = 0.6
            bottlenecks.append({
                "bottleneck_type": "Long meeting duration",
                "severity": "Low",
                "impact": "å½±å“æ—¶é—´åˆ©ç”¨æ•ˆç‡"
            })
            recommendations.append({
                "recommendation": "ä¼˜åŒ–ä¼šè®®æ—¶é•¿",
                "priority": "Medium",
                "expected_improvement": 0.10
            })

        # ç»¼åˆæ•ˆç‡è¯„åˆ†
        efficiency_score = (
            response_score * 0.4 +
            frequency_score * 0.3 +
            meeting_score * 0.3
        )

        # ç¡®å®šæ•ˆç‡ç­‰çº§
        if efficiency_score >= 0.8:
            efficiency_level = "Excellent"
        elif efficiency_score >= 0.7:
            efficiency_level = "Good"
        elif efficiency_score >= 0.6:
            efficiency_level = "Fair"
        else:
            efficiency_level = "Poor"

        return {
            "overall_efficiency_score": efficiency_score,
            "efficiency_level": efficiency_level,
            "bottlenecks": bottlenecks,
            "recommendations": recommendations
        }

    # æ‰§è¡Œæ•ˆç‡åˆ†æ
    efficiency_analysis = analyze_efficiency(collaboration_metrics)

    # å­˜å‚¨åˆ†æç»“æœ
    analysis_data = {
        "analysis_session_id": "COLLAB-ANALYSIS-20250121-001",
        "team_id": team_id,
        "analysis_start_date": start_date,
        "analysis_end_date": end_date,
        "total_collaborations": collaboration_metrics["total_collaborations"],
        "average_response_time": collaboration_metrics["average_response_time"],
        "collaboration_frequency": collaboration_metrics["collaboration_frequency"],
        "document_sharing_count": collaboration_metrics["document_sharing_count"],
        "meeting_count": collaboration_metrics["meeting_count"],
        "average_meeting_duration": collaboration_metrics["average_meeting_duration"],
        "overall_efficiency_score": efficiency_analysis["overall_efficiency_score"],
        "efficiency_level": efficiency_analysis["efficiency_level"],
        "bottlenecks": efficiency_analysis["bottlenecks"],
        "recommendations": efficiency_analysis["recommendations"]
    }

    # å­˜å‚¨åˆ°æ•°æ®åº“
    analysis_id = storage.store_collaboration_analysis(analysis_data)
    print(f"Collaboration efficiency analysis stored: {analysis_id}")

    print(f"\nCollaboration Efficiency Analysis:")
    print(f"  Team: {team_id}")
    print(f"  Overall efficiency score: {efficiency_analysis['overall_efficiency_score']:.2f}")
    print(f"  Efficiency level: {efficiency_analysis['efficiency_level']}")
    print(f"  Bottlenecks: {len(efficiency_analysis['bottlenecks'])}")
    print(f"  Recommendations: {len(efficiency_analysis['recommendations'])}")

    return analysis_data

if __name__ == "__main__":
    collaboration_efficiency_analysis()
```

---

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
