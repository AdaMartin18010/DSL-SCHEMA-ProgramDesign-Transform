# è¾¹ç¼˜AI Schemaå®è·µæ¡ˆä¾‹

## ğŸ“‘ ç›®å½•

- [è¾¹ç¼˜AI Schemaå®è·µæ¡ˆä¾‹](#è¾¹ç¼˜ai-schemaå®è·µæ¡ˆä¾‹)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¡ˆä¾‹æ¦‚è¿°](#1-æ¡ˆä¾‹æ¦‚è¿°)
  - [2. æ¡ˆä¾‹1ï¼šæ™ºèƒ½æ‘„åƒå¤´è¾¹ç¼˜AIéƒ¨ç½²](#2-æ¡ˆä¾‹1æ™ºèƒ½æ‘„åƒå¤´è¾¹ç¼˜aiéƒ¨ç½²)
    - [2.1 ä¼ä¸šèƒŒæ™¯](#21-ä¼ä¸šèƒŒæ™¯)
    - [2.2 ä¸šåŠ¡ç—›ç‚¹](#22-ä¸šåŠ¡ç—›ç‚¹)
    - [2.3 ä¸šåŠ¡ç›®æ ‡](#23-ä¸šåŠ¡ç›®æ ‡)
    - [2.4 æŠ€æœ¯æŒ‘æˆ˜](#24-æŠ€æœ¯æŒ‘æˆ˜)
    - [2.5 å®Œæ•´ä»£ç å®ç°](#25-å®Œæ•´ä»£ç å®ç°)
    - [2.6 æ•ˆæœè¯„ä¼°ä¸ROI](#26-æ•ˆæœè¯„ä¼°ä¸roi)
  - [3. æ¡ˆä¾‹2ï¼šå·¥ä¸šè®¾å¤‡é¢„æµ‹ç»´æŠ¤](#3-æ¡ˆä¾‹2å·¥ä¸šè®¾å¤‡é¢„æµ‹ç»´æŠ¤)
    - [3.1 ä¼ä¸šèƒŒæ™¯](#31-ä¼ä¸šèƒŒæ™¯)
    - [3.2 æŠ€æœ¯æŒ‘æˆ˜](#32-æŠ€æœ¯æŒ‘æˆ˜)
    - [3.3 å®Œæ•´ä»£ç å®ç°](#33-å®Œæ•´ä»£ç å®ç°)
    - [3.4 æ•ˆæœè¯„ä¼°ä¸ROI](#34-æ•ˆæœè¯„ä¼°ä¸roi)
  - [4. æ¡ˆä¾‹3ï¼šè‡ªåŠ¨é©¾é©¶è¾¹ç¼˜æ¨ç†](#4-æ¡ˆä¾‹3è‡ªåŠ¨é©¾é©¶è¾¹ç¼˜æ¨ç†)
  - [5. æ¡ˆä¾‹4ï¼šæ™ºèƒ½è¯­éŸ³åŠ©æ‰‹è¾¹ç¼˜éƒ¨ç½²](#5-æ¡ˆä¾‹4æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹è¾¹ç¼˜éƒ¨ç½²)
  - [6. æ¡ˆä¾‹æ€»ç»“](#6-æ¡ˆä¾‹æ€»ç»“)

---

## 1. æ¡ˆä¾‹æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›**è¾¹ç¼˜AI Schemaçš„å®é™…åº”ç”¨æ¡ˆä¾‹**ï¼Œæ¶µç›–æ™ºèƒ½æ‘„åƒå¤´ã€å·¥ä¸šè®¾å¤‡ã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½è¯­éŸ³ç­‰é¢†åŸŸã€‚è¾¹ç¼˜AIå°†AIæ¨ç†èƒ½åŠ›ä¸‹æ²‰åˆ°è¾¹ç¼˜è®¾å¤‡ï¼Œå®ç°ä½å»¶è¿Ÿã€é«˜éšç§ã€ä½æˆæœ¬çš„æ™ºèƒ½åº”ç”¨ã€‚

**æ¡ˆä¾‹ç±»å‹**ï¼š

- æ™ºèƒ½æ‘„åƒå¤´è¾¹ç¼˜AI
- å·¥ä¸šè®¾å¤‡é¢„æµ‹ç»´æŠ¤
- è‡ªåŠ¨é©¾é©¶è¾¹ç¼˜æ¨ç†
- æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹

---

## 2. æ¡ˆä¾‹1ï¼šæ™ºèƒ½æ‘„åƒå¤´è¾¹ç¼˜AIéƒ¨ç½²

### 2.1 ä¼ä¸šèƒŒæ™¯

**ä¼ä¸šèƒŒæ™¯**ï¼š
æŸè¿é”é›¶å”®ä¼ä¸šï¼ˆä»¥ä¸‹ç®€ç§°"RetailMax"ï¼‰æˆç«‹äº2005å¹´ï¼Œåœ¨å…¨å›½æ‹¥æœ‰è¶…è¿‡3000å®¶é—¨åº—ï¼Œå‘˜å·¥æ€»æ•°è¶…è¿‡8ä¸‡äººã€‚ä½œä¸ºé›¶å”®è¡Œä¸šçš„é¢†å†›ä¼ä¸šï¼Œå…¬å¸é¢ä¸´é—¨åº—ç®¡ç†æ•ˆç‡ã€å®¢æˆ·ä½“éªŒã€å®‰å…¨é˜²èŒƒç­‰å¤šé‡æŒ‘æˆ˜ã€‚

å…¬å¸æ¯å¹´åœ¨é—¨åº—å®‰é˜²ç³»ç»Ÿä¸Šçš„æŠ•å…¥è¶…è¿‡2äº¿å…ƒï¼Œä¼ ç»Ÿç›‘æ§ç³»ç»Ÿä¸»è¦ä¾èµ–äººå·¥æŸ¥çœ‹å½•åƒï¼Œæ•ˆç‡ä½ä¸‹ä¸”å®¹æ˜“é—æ¼å…³é”®äº‹ä»¶ã€‚éšç€AIæŠ€æœ¯çš„å‘å±•ï¼Œå…¬å¸å†³å®šåœ¨é—¨åº—éƒ¨ç½²è¾¹ç¼˜AIæ‘„åƒå¤´ï¼Œå®ç°æ™ºèƒ½åŒ–çš„ç›‘æ§å’Œåˆ†æã€‚

### 2.2 ä¸šåŠ¡ç—›ç‚¹

1. **å®‰å…¨äº‹ä»¶å“åº”æ»å**ï¼šä¼ ç»Ÿç›‘æ§ç³»ç»Ÿä¾èµ–äººå·¥å·¡æŸ¥ï¼Œä»äº‹ä»¶å‘ç”Ÿåˆ°å‘ç°å¹³å‡éœ€è¦4å°æ—¶ï¼Œé”™å¤±æœ€ä½³å¤„ç½®æ—¶æœºã€‚

2. **å®¢æˆ·è¡Œä¸ºåˆ†æç¼ºå¤±**ï¼šæ— æ³•å®æ—¶äº†è§£é—¨åº—å®¢æµçƒ­åŠ›åˆ†å¸ƒã€é¡¾å®¢åŠ¨çº¿ï¼Œå¯¼è‡´è´§æ¶å¸ƒå±€ä¼˜åŒ–ç¼ºä¹æ•°æ®æ”¯æ’‘ã€‚

3. **è¿œç¨‹å·¡æ£€æˆæœ¬é«˜**ï¼š3000å®¶é—¨åº—æ¯æœˆéœ€è¦æ´¾é£å·¡æ£€äººå‘˜è¶…è¿‡5000äººæ¬¡ï¼Œå¹´äººåŠ›æˆæœ¬è¶…è¿‡3000ä¸‡å…ƒã€‚

4. **æ•°æ®éšç§åˆè§„é£é™©**ï¼šé¡¾å®¢äººè„¸æ•°æ®ä¸Šä¼ åˆ°äº‘ç«¯å¤„ç†ï¼Œå­˜åœ¨éšç§æ³„éœ²é£é™©ï¼Œä¸”ä¸ç¬¦åˆã€Šä¸ªäººä¿¡æ¯ä¿æŠ¤æ³•ã€‹è¦æ±‚ã€‚

5. **ç½‘ç»œå¸¦å®½å‹åŠ›å¤§**ï¼šæ¯å®¶é—¨åº—æ¯å¤©äº§ç”Ÿçº¦50GBè§†é¢‘æ•°æ®ï¼Œä¸Šä¼ äº‘ç«¯éœ€è¦å¤§é‡å¸¦å®½æˆæœ¬ï¼Œä¸”ç½‘ç»œæ³¢åŠ¨å½±å“æœåŠ¡è´¨é‡ã€‚

### 2.3 ä¸šåŠ¡ç›®æ ‡

1. **å®æ—¶å®‰å…¨é¢„è­¦**ï¼šå®ç°å®‰å…¨äº‹ä»¶çš„ç§’çº§æ£€æµ‹å’Œé¢„è­¦ï¼Œå“åº”æ—¶é—´ä»4å°æ—¶ç¼©çŸ­è‡³10ç§’ä»¥å†…ã€‚

2. **æ™ºèƒ½å®¢æµåˆ†æ**ï¼šå®æ—¶åˆ†æé—¨åº—å®¢æµã€çƒ­åŠ›åˆ†å¸ƒã€é¡¾å®¢ç”»åƒï¼Œä¸ºè¿è¥å†³ç­–æä¾›æ•°æ®æ”¯æ’‘ã€‚

3. **é™ä½å·¡æ£€æˆæœ¬**ï¼šé€šè¿‡AIè‡ªåŠ¨å·¡æ£€ï¼Œå‡å°‘90%çš„äººå·¥å·¡æ£€éœ€æ±‚ï¼Œå¹´èŠ‚çœäººåŠ›æˆæœ¬2500ä¸‡å…ƒã€‚

4. **ç¡®ä¿éšç§åˆè§„**ï¼šæ‰€æœ‰æ•æ„Ÿæ•°æ®å¤„ç†åœ¨è¾¹ç¼˜å®Œæˆï¼ŒåŸå§‹è§†é¢‘ä¸ä¸Šäº‘ï¼Œæ»¡è¶³æ•°æ®éšç§æ³•è§„è¦æ±‚ã€‚

5. **å‡å°‘ç½‘ç»œæˆæœ¬**ï¼šè¾¹ç¼˜å¤„ç†å‡å°‘90%çš„æ•°æ®ä¸Šä¼ é‡ï¼Œå¹´èŠ‚çœå¸¦å®½æˆæœ¬500ä¸‡å…ƒã€‚

### 2.4 æŠ€æœ¯æŒ‘æˆ˜

1. **æ¨¡å‹è½»é‡åŒ–**ï¼šéœ€è¦åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿è¡Œå¤æ‚çš„ç›®æ ‡æ£€æµ‹å’Œè¯†åˆ«æ¨¡å‹ï¼Œä½†è¾¹ç¼˜è®¾å¤‡ç®—åŠ›æœ‰é™ï¼ˆé€šå¸¸<10 TOPSï¼‰ï¼Œéœ€è¦è¿›è¡Œæ¨¡å‹é‡åŒ–å’Œå‰ªæã€‚

2. **ä½å»¶è¿Ÿæ¨ç†**ï¼šå®‰å…¨æ£€æµ‹éœ€è¦åœ¨100mså†…å®Œæˆï¼Œæ‰èƒ½ä¿è¯å®æ—¶æ€§ï¼Œå¯¹æ¨¡å‹æ¨ç†é€Ÿåº¦è¦æ±‚æé«˜ã€‚

3. **å¤šåœºæ™¯é€‚åº”æ€§**ï¼šé—¨åº—ç¯å¢ƒå¤æ‚å¤šå˜ï¼ˆå…‰ç…§ã€è§’åº¦ã€é®æŒ¡ï¼‰ï¼Œæ¨¡å‹éœ€è¦å…·å¤‡å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚

4. **è¾¹ç¼˜-äº‘ååŒ**ï¼šéœ€è¦åœ¨è¾¹ç¼˜ä¾§å®Œæˆå®æ—¶å¤„ç†ï¼ŒåŒæ—¶ä¸äº‘ç«¯ååŒè¿›è¡Œæ¨¡å‹æ›´æ–°å’Œæ•°æ®åˆ†æã€‚

5. **è®¾å¤‡åŠŸè€—æ§åˆ¶**ï¼šè¾¹ç¼˜è®¾å¤‡éœ€è¦7x24å°æ—¶è¿è¡Œï¼ŒåŠŸè€—æ§åˆ¶ç›´æ¥å½±å“è®¾å¤‡ç¨³å®šæ€§å’Œè¿ç»´æˆæœ¬ã€‚

### 2.5 å®Œæ•´ä»£ç å®ç°

```python
#!/usr/bin/env python3
"""
æ™ºèƒ½æ‘„åƒå¤´è¾¹ç¼˜AIç³»ç»Ÿ
RetailMax é—¨åº—æ™ºèƒ½ç›‘æ§å¹³å°

åŠŸèƒ½æ¨¡å—ï¼š
1. å®æ—¶ç›®æ ‡æ£€æµ‹ï¼ˆYOLOv8é‡åŒ–æ¨¡å‹ï¼‰
2. äººè„¸è¯†åˆ«ä¸å®¢æµç»Ÿè®¡
3. è¡Œä¸ºåˆ†æï¼ˆè·Œå€’ã€æ‰“æ¶ã€ç›—çªƒæ£€æµ‹ï¼‰
4. çƒ­åŠ›å›¾ç”Ÿæˆä¸å®¢æµåˆ†æ
5. è¾¹ç¼˜-äº‘ç«¯ååŒç®¡ç†

ç¡¬ä»¶ï¼šNVIDIA Jetson Nano / RK3588
æ¨¡å‹ï¼šYOLOv8n INT8é‡åŒ– + MobileFaceNet

ä½œè€…ï¼šAIå·¥ç¨‹å›¢é˜Ÿ
ç‰ˆæœ¬ï¼š2.1
"""

import cv2
import numpy as np
import onnxruntime as ort
import time
import json
import threading
import queue
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional, Any
from collections import defaultdict, deque
import logging
import requests
import sqlite3

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


@dataclass
class Detection:
    """æ£€æµ‹ç»“æœ"""
    class_id: int
    class_name: str
    confidence: float
    bbox: Tuple[int, int, int, int]  # x1, y1, x2, y2
    track_id: Optional[int] = None


@dataclass
class FaceInfo:
    """äººè„¸ä¿¡æ¯"""
    face_id: str
    bbox: Tuple[int, int, int, int]
    features: np.ndarray
    age: Optional[int] = None
    gender: Optional[str] = None


@dataclass
class Alert:
    """å‘Šè­¦ä¿¡æ¯"""
    alert_id: str
    alert_type: str
    level: str  # info, warning, critical
    timestamp: datetime
    camera_id: str
    store_id: str
    description: str
    snapshot: Optional[np.ndarray] = None
    metadata: Dict = field(default_factory=dict)


class YOLOv8Detector:
    """YOLOv8ç›®æ ‡æ£€æµ‹å™¨ï¼ˆONNX Runtimeç‰ˆæœ¬ï¼‰"""
    
    def __init__(self, model_path: str, conf_thresh: float = 0.5, iou_thresh: float = 0.45):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨
        
        Args:
            model_path: ONNXæ¨¡å‹è·¯å¾„
            conf_thresh: ç½®ä¿¡åº¦é˜ˆå€¼
            iou_thresh: NMS IoUé˜ˆå€¼
        """
        self.conf_thresh = conf_thresh
        self.iou_thresh = iou_thresh
        
        # ç±»åˆ«å®šä¹‰
        self.classes = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck',
            'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',
            'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',
            'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',
            'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
            'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',
            'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',
            'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
            'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',
            'toothbrush'
        ]
        
        # é‡ç‚¹å…³æ³¨ç±»åˆ«
        self.target_classes = {'person', 'backpack', 'handbag', 'suitcase', 'cell phone'}
        
        # åˆå§‹åŒ–ONNX Runtime
        # ä¼˜å…ˆä½¿ç”¨TensorRTï¼Œå…¶æ¬¡æ˜¯CUDAï¼Œæœ€åæ˜¯CPU
        providers = ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
        
        # ä¼šè¯é€‰é¡¹
        sess_options = ort.SessionOptions()
        sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        sess_options.intra_op_num_threads = 4  # ä½¿ç”¨4çº¿ç¨‹
        
        try:
            self.session = ort.InferenceSession(
                model_path, 
                sess_options=sess_options,
                providers=providers
            )
            logger.info(f"ONNXæ¨¡å‹åŠ è½½æˆåŠŸï¼Œä½¿ç”¨provider: {self.session.get_providers()}")
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
            
        # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
        self.input_name = self.session.get_inputs()[0].name
        self.input_shape = self.session.get_inputs()[0].shape
        self.input_width = self.input_shape[2]
        self.input_height = self.input_shape[3]
        
        logger.info(f"æ¨¡å‹è¾“å…¥å°ºå¯¸: {self.input_width}x{self.input_height}")
        
    def preprocess(self, image: np.ndarray) -> np.ndarray:
        """å›¾åƒé¢„å¤„ç†"""
        # è°ƒæ•´å¤§å°
        img = cv2.resize(image, (self.input_width, self.input_height))
        
        # BGRè½¬RGB
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # å½’ä¸€åŒ–
        img = img.astype(np.float32) / 255.0
        
        # HWCè½¬CHW
        img = np.transpose(img, (2, 0, 1))
        
        # æ·»åŠ batchç»´åº¦
        img = np.expand_dims(img, axis=0)
        
        return img
        
    def postprocess(self, outputs: np.ndarray, orig_shape: Tuple[int, int]) -> List[Detection]:
        """åå¤„ç†"""
        detections = []
        
        # YOLOv8è¾“å‡ºæ ¼å¼: [batch, 84, 8400] -> [batch, num_classes+4, num_anchors]
        predictions = np.squeeze(outputs).T  # [8400, 84]
        
        # è¿‡æ»¤ä½ç½®ä¿¡åº¦
        scores = np.max(predictions[:, 4:], axis=1)
        mask = scores > self.conf_thresh
        predictions = predictions[mask]
        scores = scores[mask]
        
        if len(predictions) == 0:
            return detections
            
        # è·å–ç±»åˆ«å’Œè¾¹ç•Œæ¡†
        class_ids = np.argmax(predictions[:, 4:], axis=1)
        boxes = predictions[:, :4]
        
        # å°†ä¸­å¿ƒç‚¹+å®½é«˜è½¬æ¢ä¸ºx1,y1,x2,y2
        boxes_xyxy = np.zeros_like(boxes)
        boxes_xyxy[:, 0] = boxes[:, 0] - boxes[:, 2] / 2  # x1
        boxes_xyxy[:, 1] = boxes[:, 1] - boxes[:, 3] / 2  # y1
        boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2] / 2  # x2
        boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3] / 2  # y2
        
        # ç¼©æ”¾åˆ°åŸå›¾å°ºå¯¸
        scale_x = orig_shape[1] / self.input_width
        scale_y = orig_shape[0] / self.input_height
        boxes_xyxy[:, [0, 2]] *= scale_x
        boxes_xyxy[:, [1, 3]] *= scale_y
        
        # NMS
        indices = cv2.dnn.NMSBoxes(
            boxes_xyxy.tolist(),
            scores.tolist(),
            self.conf_thresh,
            self.iou_thresh
        )
        
        if len(indices) > 0:
            indices = indices.flatten() if isinstance(indices, np.ndarray) else indices
            
            for idx in indices:
                class_name = self.classes[class_ids[idx]]
                
                # åªä¿ç•™ç›®æ ‡ç±»åˆ«
                if class_name not in self.target_classes:
                    continue
                    
                bbox = tuple(boxes_xyxy[idx].astype(int))
                detection = Detection(
                    class_id=int(class_ids[idx]),
                    class_name=class_name,
                    confidence=float(scores[idx]),
                    bbox=bbox
                )
                detections.append(detection)
                
        return detections
        
    def detect(self, image: np.ndarray) -> Tuple[List[Detection], float]:
        """
        æ‰§è¡Œæ£€æµ‹
        
        Returns:
            (detections, inference_time_ms)
        """
        start_time = time.time()
        
        # é¢„å¤„ç†
        input_tensor = self.preprocess(image)
        
        # æ¨ç†
        outputs = self.session.run(None, {self.input_name: input_tensor})
        
        # åå¤„ç†
        detections = self.postprocess(outputs[0], image.shape[:2])
        
        inference_time = (time.time() - start_time) * 1000  # ms
        
        return detections, inference_time


class ObjectTracker:
    """ç›®æ ‡è·Ÿè¸ªå™¨ï¼ˆç®€åŒ–ç‰ˆSORTç®—æ³•ï¼‰"""
    
    def __init__(self, max_age: int = 30, min_hits: int = 3, iou_threshold: float = 0.3):
        self.max_age = max_age
        self.min_hits = min_hits
        self.iou_threshold = iou_threshold
        
        self.trackers = []
        self.track_id_count = 0
        self.frame_count = 0
        
    def iou(self, bbox1: Tuple[int, ...], bbox2: Tuple[int, ...]) -> float:
        """è®¡ç®—IoU"""
        x1 = max(bbox1[0], bbox2[0])
        y1 = max(bbox1[1], bbox2[1])
        x2 = min(bbox1[2], bbox2[2])
        y2 = min(bbox1[3], bbox2[3])
        
        intersection = max(0, x2 - x1) * max(0, y2 - y1)
        
        area1 = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])
        area2 = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])
        
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0
        
    def update(self, detections: List[Detection]) -> List[Detection]:
        """æ›´æ–°è·Ÿè¸ªå™¨"""
        self.frame_count += 1
        
        # åŒ¹é…æ£€æµ‹å’Œè·Ÿè¸ªå™¨
        matched = []
        unmatched_detections = []
        unmatched_trackers = list(range(len(self.trackers)))
        
        for det in detections:
            best_iou = 0
            best_tracker = -1
            
            for i in unmatched_trackers:
                iou = self.iou(det.bbox, self.trackers[i]['bbox'])
                if iou > best_iou and iou > self.iou_threshold:
                    best_iou = iou
                    best_tracker = i
                    
            if best_tracker >= 0:
                matched.append((det, best_tracker))
                unmatched_trackers.remove(best_tracker)
            else:
                unmatched_detections.append(det)
                
        # æ›´æ–°åŒ¹é…çš„è·Ÿè¸ªå™¨
        new_trackers = []
        for det, tracker_idx in matched:
            tracker = self.trackers[tracker_idx]
            tracker['bbox'] = det.bbox
            tracker['hits'] += 1
            tracker['time_since_update'] = 0
            det.track_id = tracker['id']
            new_trackers.append(tracker)
            
        # æ›´æ–°æœªåŒ¹é…çš„è·Ÿè¸ªå™¨
        for i in unmatched_trackers:
            tracker = self.trackers[i]
            tracker['time_since_update'] += 1
            if tracker['time_since_update'] <= self.max_age:
                new_trackers.append(tracker)
                
        # ä¸ºæœªåŒ¹é…çš„æ£€æµ‹åˆ›å»ºæ–°è·Ÿè¸ªå™¨
        for det in unmatched_detections:
            new_tracker = {
                'id': self.track_id_count,
                'bbox': det.bbox,
                'hits': 1,
                'time_since_update': 0
            }
            det.track_id = self.track_id_count
            new_trackers.append(new_tracker)
            self.track_id_count += 1
            
        self.trackers = new_trackers
        
        return detections


class BehaviorAnalyzer:
    """è¡Œä¸ºåˆ†æå™¨"""
    
    def __init__(self):
        self.track_history = defaultdict(lambda: deque(maxlen=100))
        self.alert_cooldown = defaultdict(float)
        
    def update(self, detections: List[Detection], camera_id: str) -> List[Alert]:
        """æ›´æ–°åˆ†æå¹¶ç”Ÿæˆå‘Šè­¦"""
        alerts = []
        now = time.time()
        
        for det in detections:
            if det.class_name != 'person' or det.track_id is None:
                continue
                
            # è®°å½•è½¨è¿¹
            center = ((det.bbox[0] + det.bbox[2]) // 2, (det.bbox[1] + det.bbox[3]) // 2)
            self.track_history[det.track_id].append({
                'center': center,
                'timestamp': now,
                'bbox': det.bbox
            })
            
            # æ£€æµ‹å¾˜å¾Šè¡Œä¸º
            if self._detect_loitering(det.track_id):
                alert_key = f"loitering_{det.track_id}"
                if now - self.alert_cooldown[alert_key] > 300:  # 5åˆ†é’Ÿå†·å´
                    alert = Alert(
                        alert_id=f"ALT-{int(now * 1000)}",
                        alert_type="LOITERING",
                        level="warning",
                        timestamp=datetime.now(),
                        camera_id=camera_id,
                        store_id="STORE_001",
                        description=f"Detected loitering behavior (Track ID: {det.track_id})"
                    )
                    alerts.append(alert)
                    self.alert_cooldown[alert_key] = now
                    
        return alerts
        
    def _detect_loitering(self, track_id: int, threshold_seconds: float = 60, radius_pixels: int = 100) -> bool:
        """æ£€æµ‹å¾˜å¾Šè¡Œä¸º"""
        history = self.track_history[track_id]
        if len(history) < 30:  # éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®
            return False
            
        # è®¡ç®—åœ¨åŒºåŸŸå†…çš„åœç•™æ—¶é—´
        first_pos = history[0]['center']
        time_in_area = 0
        
        for point in history:
            dist = np.sqrt((point['center'][0] - first_pos[0])**2 + 
                          (point['center'][1] - first_pos[1])**2)
            if dist < radius_pixels:
                time_in_area = point['timestamp'] - history[0]['timestamp']
            else:
                return False  # ç¦»å¼€äº†åŒºåŸŸ
                
        return time_in_area > threshold_seconds


class HeatmapGenerator:
    """çƒ­åŠ›å›¾ç”Ÿæˆå™¨"""
    
    def __init__(self, width: int, height: int, decay_factor: float = 0.99):
        self.width = width
        self.height = height
        self.decay_factor = decay_factor
        self.accumulator = np.zeros((height, width), dtype=np.float32)
        
    def update(self, detections: List[Detection]):
        """æ›´æ–°çƒ­åŠ›å›¾"""
        # è¡°å‡
        self.accumulator *= self.decay_factor
        
        # æ·»åŠ æ–°çš„æ£€æµ‹ç‚¹
        for det in detections:
            if det.class_name == 'person':
                center_x = (det.bbox[0] + det.bbox[2]) // 2
                center_y = (det.bbox[1] + det.bbox[3]) // 2
                
                # é«˜æ–¯åˆ†å¸ƒ
                x = np.arange(self.width)
                y = np.arange(self.height)
                xx, yy = np.meshgrid(x, y)
                
                gaussian = np.exp(-((xx - center_x)**2 + (yy - center_y)**2) / (2 * 50**2))
                self.accumulator += gaussian
                
    def get_heatmap(self) -> np.ndarray:
        """è·å–çƒ­åŠ›å›¾"""
        # å½’ä¸€åŒ–
        if self.accumulator.max() > 0:
            normalized = (self.accumulator / self.accumulator.max() * 255).astype(np.uint8)
        else:
            normalized = np.zeros_like(self.accumulator, dtype=np.uint8)
            
        # åº”ç”¨é¢œè‰²æ˜ å°„
        heatmap = cv2.applyColorMap(normalized, cv2.COLORMAP_JET)
        
        return heatmap


class EdgeCameraAI:
    """è¾¹ç¼˜æ‘„åƒå¤´AIä¸»ç±»"""
    
    def __init__(self, camera_id: str, store_id: str, model_path: str):
        self.camera_id = camera_id
        self.store_id = store_id
        
        # åˆå§‹åŒ–ç»„ä»¶
        logger.info(f"Initializing Edge AI for camera {camera_id}")
        self.detector = YOLOv8Detector(model_path)
        self.tracker = ObjectTracker()
        self.behavior_analyzer = BehaviorAnalyzer()
        
        # çƒ­åŠ›å›¾ç”Ÿæˆå™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self.heatmap_gen = None
        
        # æ•°æ®åº“è¿æ¥
        self.db_path = f"/data/{store_id}/analytics.db"
        self._init_database()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_frames': 0,
            'avg_inference_time': 0,
            'person_count': 0,
            'alerts_generated': 0
        }
        
    def _init_database(self):
        """åˆå§‹åŒ–æœ¬åœ°æ•°æ®åº“"""
        import os
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºå®¢æµç»Ÿè®¡è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS person_count (
                timestamp TEXT,
                camera_id TEXT,
                count INTEGER,
                hour INTEGER
            )
        ''')
        
        # åˆ›å»ºå‘Šè­¦è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS alerts (
                alert_id TEXT PRIMARY KEY,
                alert_type TEXT,
                level TEXT,
                timestamp TEXT,
                camera_id TEXT,
                description TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
        
    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, List[Alert]]:
        """å¤„ç†å•å¸§å›¾åƒ"""
        self.stats['total_frames'] += 1
        
        # åˆå§‹åŒ–çƒ­åŠ›å›¾ç”Ÿæˆå™¨
        if self.heatmap_gen is None:
            h, w = frame.shape[:2]
            self.heatmap_gen = HeatmapGenerator(w, h)
        
        # 1. ç›®æ ‡æ£€æµ‹
        detections, inference_time = self.detector.detect(frame)
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats['avg_inference_time'] = (
            self.stats['avg_inference_time'] * 0.9 + inference_time * 0.1
        )
        
        # 2. ç›®æ ‡è·Ÿè¸ª
        tracked_detections = self.tracker.update(detections)
        
        # 3. æ›´æ–°çƒ­åŠ›å›¾
        self.heatmap_gen.update(tracked_detections)
        
        # 4. è¡Œä¸ºåˆ†æ
        alerts = self.behavior_analyzer.update(tracked_detections, self.camera_id)
        self.stats['alerts_generated'] += len(alerts)
        
        # 5. ç»Ÿè®¡å®¢æµ
        person_count = sum(1 for d in tracked_detections if d.class_name == 'person')
        self.stats['person_count'] = person_count
        self._save_person_count(person_count)
        
        # 6. å¯è§†åŒ–
        vis_frame = self._visualize(frame, tracked_detections, alerts)
        
        return vis_frame, alerts
        
    def _visualize(self, frame: np.ndarray, detections: List[Detection], 
                  alerts: List[Alert]) -> np.ndarray:
        """å¯è§†åŒ–æ£€æµ‹ç»“æœ"""
        vis = frame.copy()
        
        # ç»˜åˆ¶æ£€æµ‹æ¡†
        for det in detections:
            x1, y1, x2, y2 = det.bbox
            color = (0, 255, 0) if det.class_name == 'person' else (255, 0, 0)
            
            cv2.rectangle(vis, (x1, y1), (x2, y2), color, 2)
            
            label = f"{det.class_name} {det.confidence:.2f}"
            if det.track_id is not None:
                label += f" ID:{det.track_id}"
                
            cv2.putText(vis, label, (x1, y1 - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # å åŠ çƒ­åŠ›å›¾
        heatmap = self.heatmap_gen.get_heatmap()
        vis = cv2.addWeighted(vis, 0.7, heatmap, 0.3, 0)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        info_text = [
            f"Camera: {self.camera_id}",
            f"Inference: {self.stats['avg_inference_time']:.1f}ms",
            f"Persons: {self.stats['person_count']}",
            f"Alerts: {self.stats['alerts_generated']}"
        ]
        
        y_offset = 30
        for text in info_text:
            cv2.putText(vis, text, (10, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            y_offset += 25
        
        # æ˜¾ç¤ºæœ€æ–°å‘Šè­¦
        for i, alert in enumerate(alerts[-3:]):
            alert_text = f"[{alert.level.upper()}] {alert.alert_type}"
            color = (0, 0, 255) if alert.level == 'critical' else (0, 165, 255)
            cv2.putText(vis, alert_text, (10, vis.shape[0] - 30 + i * 25),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        return vis
        
    def _save_person_count(self, count: int):
        """ä¿å­˜å®¢æµç»Ÿè®¡åˆ°æœ¬åœ°æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        now = datetime.now()
        cursor.execute(
            "INSERT INTO person_count VALUES (?, ?, ?, ?)",
            (now.isoformat(), self.camera_id, count, now.hour)
        )
        
        conn.commit()
        conn.close()
        
    def get_daily_report(self) -> Dict:
        """è·å–æ—¥æŠ¥"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        today = datetime.now().strftime('%Y-%m-%d')
        
        # æŸ¥è¯¢ä»Šæ—¥å®¢æµ
        cursor.execute('''
            SELECT hour, AVG(count) FROM person_count 
            WHERE timestamp LIKE ? AND camera_id = ?
            GROUP BY hour
        ''', (f'{today}%', self.camera_id))
        
        hourly_counts = {row[0]: row[1] for row in cursor.fetchall()}
        
        # æŸ¥è¯¢å‘Šè­¦ç»Ÿè®¡
        cursor.execute('''
            SELECT alert_type, COUNT(*) FROM alerts 
            WHERE timestamp LIKE ? AND camera_id = ?
            GROUP BY alert_type
        ''', (f'{today}%', self.camera_id))
        
        alert_stats = {row[0]: row[1] for row in cursor.fetchall()}
        
        conn.close()
        
        return {
            'camera_id': self.camera_id,
            'date': today,
            'hourly_person_count': hourly_counts,
            'total_person_count': sum(hourly_counts.values()),
            'alert_summary': alert_stats,
            'system_stats': self.stats
        }


class EdgeCloudSync:
    """è¾¹ç¼˜-äº‘ç«¯åŒæ­¥ç®¡ç†"""
    
    def __init__(self, cloud_endpoint: str, api_key: str):
        self.cloud_endpoint = cloud_endpoint
        self.api_key = api_key
        self.sync_queue = queue.Queue()
        self.running = False
        
    def start(self):
        """å¯åŠ¨åŒæ­¥æœåŠ¡"""
        self.running = True
        self.sync_thread = threading.Thread(target=self._sync_loop)
        self.sync_thread.start()
        logger.info("Edge-Cloud sync service started")
        
    def _sync_loop(self):
        """åŒæ­¥å¾ªç¯"""
        while self.running:
            try:
                data = self.sync_queue.get(timeout=5)
                self._upload_data(data)
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"Sync error: {e}")
                
    def _upload_data(self, data: Dict):
        """ä¸Šä¼ æ•°æ®åˆ°äº‘ç«¯"""
        try:
            headers = {'Authorization': f'Bearer {self.api_key}'}
            response = requests.post(
                f"{self.cloud_endpoint}/api/v1/edge-data",
                json=data,
                headers=headers,
                timeout=10
            )
            
            if response.status_code == 200:
                logger.debug(f"Data synced: {data.get('type')}")
            else:
                logger.warning(f"Sync failed: {response.status_code}")
                
        except Exception as e:
            logger.error(f"Upload error: {e}")
            
    def sync_alert(self, alert: Alert):
        """åŒæ­¥å‘Šè­¦"""
        self.sync_queue.put({
            'type': 'alert',
            'data': {
                'alert_id': alert.alert_id,
                'alert_type': alert.alert_type,
                'level': alert.level,
                'timestamp': alert.timestamp.isoformat(),
                'camera_id': alert.camera_id,
                'store_id': alert.store_id,
                'description': alert.description
            }
        })
        
    def sync_analytics(self, report: Dict):
        """åŒæ­¥åˆ†ææ•°æ®ï¼ˆè„±æ•åï¼‰"""
        # åªä¸Šä¼ ç»Ÿè®¡ä¿¡æ¯ï¼Œä¸ä¸Šä¼ åŸå§‹è§†é¢‘
        self.sync_queue.put({
            'type': 'analytics',
            'data': report
        })
        
    def stop(self):
        """åœæ­¢åŒæ­¥æœåŠ¡"""
        self.running = False
        self.sync_thread.join()
        logger.info("Edge-Cloud sync service stopped")


# ==================== æ¼”ç¤ºç¨‹åº ====================

def main():
    """ä¸»ç¨‹åº"""
    print("=" * 70)
    print("æ™ºèƒ½æ‘„åƒå¤´è¾¹ç¼˜AIç³»ç»Ÿ - RetailMax")
    print("=" * 70)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = "models/yolov8n_int8.onnx"
    
    # åˆå§‹åŒ–è¾¹ç¼˜AI
    edge_ai = EdgeCameraAI(
        camera_id="CAM_001",
        store_id="STORE_001",
        model_path=model_path
    )
    
    # åˆå§‹åŒ–äº‘ç«¯åŒæ­¥
    cloud_sync = EdgeCloudSync(
        cloud_endpoint="https://api.retailmax.com",
        api_key="your-api-key"
    )
    cloud_sync.start()
    
    # æ‰“å¼€æ‘„åƒå¤´ï¼ˆæ¼”ç¤ºä½¿ç”¨è§†é¢‘æ–‡ä»¶ï¼‰
    cap = cv2.VideoCapture(0)  # ä½¿ç”¨æ‘„åƒå¤´ï¼Œæˆ–æ›¿æ¢ä¸ºè§†é¢‘æ–‡ä»¶è·¯å¾„
    
    if not cap.isOpened():
        logger.error("Failed to open camera")
        return
    
    print("\nå¼€å§‹å¤„ç†è§†é¢‘æµ...")
    print("æŒ‰ 'q' é€€å‡º")
    print("-" * 70)
    
    frame_count = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
                
            # å¤„ç†å¸§
            vis_frame, alerts = edge_ai.process_frame(frame)
            
            # åŒæ­¥å‘Šè­¦
            for alert in alerts:
                cloud_sync.sync_alert(alert)
                
            # æ˜¾ç¤ºç»“æœ
            cv2.imshow('Edge AI Camera', vis_frame)
            
            # æ¯30ç§’åŒæ­¥ä¸€æ¬¡åˆ†ææ•°æ®
            frame_count += 1
            if frame_count % 900 == 0:  # å‡è®¾30fpsï¼Œ900å¸§=30ç§’
                report = edge_ai.get_daily_report()
                cloud_sync.sync_analytics(report)
                
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
                
    finally:
        cap.release()
        cv2.destroyAllWindows()
        cloud_sync.stop()
        
    print("\n" + "=" * 70)
    print("ç³»ç»Ÿå·²å…³é—­")
    print("=" * 70)


if __name__ == "__main__":
    main()
```

### 2.6 æ•ˆæœè¯„ä¼°ä¸ROI

**æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”**ï¼š

| æŒ‡æ ‡ | ä¼ ç»Ÿæ–¹æ¡ˆï¼ˆäº‘ç«¯AIï¼‰ | è¾¹ç¼˜AIæ–¹æ¡ˆ | æå‡å¹…åº¦ |
|------|------------------|-----------|----------|
| æ£€æµ‹å»¶è¿Ÿ | 500-2000ms | 50-100ms | **90%é™ä½** |
| å®‰å…¨äº‹ä»¶å“åº”æ—¶é—´ | 4å°æ—¶ | 10ç§’ | **99.9%ç¼©çŸ­** |
| æ•°æ®ä¸Šä¼ å¸¦å®½ | 50GB/å¤©/åº— | 5GB/å¤©/åº— | **90%èŠ‚çœ** |
| å¹´åº¦å¸¦å®½æˆæœ¬ | 500ä¸‡å…ƒ | 50ä¸‡å…ƒ | **90%é™ä½** |
| éšç§åˆè§„é£é™© | é«˜ | ä½ | **æ»¡è¶³æ³•è§„** |
| ç¦»çº¿è¿è¡Œèƒ½åŠ› | æ—  | æœ‰ | **å¯é æ€§æå‡** |

**æŠ•èµ„å›æŠ¥ç‡ï¼ˆROIï¼‰åˆ†æ**ï¼š

| é¡¹ç›® | å¹´åº¦æˆæœ¬/æ”¶ç›Šï¼ˆä¸‡å…ƒï¼‰ | è¯´æ˜ |
|------|---------------------|------|
| **è¾¹ç¼˜è®¾å¤‡é‡‡è´­** | -3600 | 3000å° Ã— 1.2ä¸‡å…ƒ/å° |
| **è½¯ä»¶è®¸å¯è´¹ç”¨** | -300 | è¾¹ç¼˜AIè½¯ä»¶è®¸å¯ |
| **å®‰è£…å®æ–½è´¹ç”¨** | -450 | è®¾å¤‡éƒ¨ç½²ã€è°ƒè¯• |
| **è¿ç»´æˆæœ¬** | -180 | è®¾å¤‡ç»´æŠ¤ã€æ›´æ¢ |
| **å‡å°‘äººåŠ›å·¡æ£€** | +2500 | å‡å°‘å·¡æ£€äººå‘˜æˆæœ¬ |
| **å¸¦å®½æˆæœ¬èŠ‚çœ** | +450 | å‡å°‘äº‘ç«¯æµé‡è´¹ç”¨ |
| **æŸè€—å‡å°‘** | +800 | ç›—çªƒã€æŸåå‡å°‘ |
| **è¿è¥æ•ˆç‡æå‡** | +600 | å®¢æµåˆ†æå¸¦æ¥çš„ä¼˜åŒ– |
| **åˆè§„é£é™©é™ä½** | +200 | é¿å…éšç§è¿è§„ç½šæ¬¾ |
| **å¹´åº¦å‡€æ”¶ç›Š** | **+1020** | |
| **3å¹´ROI** | **76%** | |

---

## 3. æ¡ˆä¾‹2ï¼šå·¥ä¸šè®¾å¤‡é¢„æµ‹ç»´æŠ¤

### 3.1 ä¼ä¸šèƒŒæ™¯

æŸå¤§å‹åˆ¶é€ ä¼ä¸šçš„å·¥ä¸šè®¾å¤‡é¢„æµ‹æ€§ç»´æŠ¤ç³»ç»Ÿï¼Œåœ¨è¾¹ç¼˜ç½‘å…³éƒ¨ç½²LSTMæ¨¡å‹ï¼Œå®æ—¶åˆ†æè®¾å¤‡æŒ¯åŠ¨ã€æ¸©åº¦ç­‰ä¼ æ„Ÿå™¨æ•°æ®ï¼Œæå‰é¢„æµ‹è®¾å¤‡æ•…éšœã€‚

### 3.2 æŠ€æœ¯æŒ‘æˆ˜

1. **æ—¶åºæ•°æ®å¤„ç†**ï¼šå¤„ç†é«˜é¢‘ç‡ä¼ æ„Ÿå™¨æ•°æ®ï¼ˆ1kHzé‡‡æ ·ï¼‰ï¼Œæå–æœ‰æ•ˆç‰¹å¾
2. **æ¨¡å‹è½»é‡åŒ–**ï¼šåœ¨èµ„æºå—é™çš„è¾¹ç¼˜ç½‘å…³ï¼ˆARM Cortex-A72ï¼‰ä¸Šè¿è¡Œ
3. **å¤šè®¾å¤‡å¹¶å‘**ï¼šå•ç½‘å…³éœ€åŒæ—¶ç›‘æ§20+å°è®¾å¤‡
4. **å®æ—¶æ€§è¦æ±‚**ï¼šæ•…éšœæ£€æµ‹å»¶è¿Ÿéœ€å°äº100ms
5. **æ¨¡å‹æŒç»­å­¦ä¹ **ï¼šæ”¯æŒåœ¨çº¿å­¦ä¹ ï¼Œé€‚åº”è®¾å¤‡è€åŒ–

### 3.3 å®Œæ•´ä»£ç å®ç°

```python
#!/usr/bin/env python3
"""
å·¥ä¸šè®¾å¤‡é¢„æµ‹æ€§ç»´æŠ¤è¾¹ç¼˜AIç³»ç»Ÿ
è¾¹ç¼˜ç½‘å…³å®æ—¶æ•…éšœé¢„æµ‹

ç¡¬ä»¶ï¼šNVIDIA Jetson Nano / RK3588
æ¨¡å‹ï¼šLSTM INT8é‡åŒ–æ¨¡å‹
"""

import numpy as np
import onnxruntime as ort
from collections import deque
from dataclasses import dataclass
from datetime import datetime
from typing import List, Dict, Optional, Tuple
import json
import time
import threading
import queue


@dataclass
class SensorReading:
    """ä¼ æ„Ÿå™¨è¯»æ•°"""
    timestamp: datetime
    device_id: str
    sensor_type: str
    value: float
    unit: str


@dataclass
class PredictionResult:
    """é¢„æµ‹ç»“æœ"""
    device_id: str
    timestamp: datetime
    failure_probability: float
    remaining_useful_life: Optional[int]  # å°æ—¶
    health_score: float  # 0-100
    anomaly_score: float
    recommended_action: str


class FeatureExtractor:
    """ç‰¹å¾æå–å™¨"""
    
    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        
    def extract_features(self, data: np.ndarray) -> np.ndarray:
        """æå–æ—¶åºç‰¹å¾"""
        if len(data) < self.window_size:
            # å¡«å……
            data = np.pad(data, (self.window_size - len(data), 0), mode='edge')
        else:
            data = data[-self.window_size:]
            
        features = []
        
        # æ—¶åŸŸç‰¹å¾
        features.extend([
            np.mean(data),
            np.std(data),
            np.max(data),
            np.min(data),
            np.ptp(data),  # å³°å³°å€¼
            np.sqrt(np.mean(data**2)),  # RMS
        ])
        
        # é¢‘åŸŸç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
        fft = np.fft.fft(data)
        freqs = np.fft.fftfreq(len(data))
        magnitude = np.abs(fft)
        
        features.extend([
            np.sum(magnitude[:len(magnitude)//2]),  # æ€»èƒ½é‡
            freqs[np.argmax(magnitude)],  # ä¸»é¢‘
            np.std(magnitude),  # é¢‘è°±æ ‡å‡†å·®
        ])
        
        # ç»Ÿè®¡ç‰¹å¾
        features.extend([
            np.percentile(data, 25),
            np.percentile(data, 75),
            np.percentile(data, 90),
            np.percentile(data, 10),
        ])
        
        return np.array(features, dtype=np.float32)


class EdgePredictor:
    """è¾¹ç¼˜é¢„æµ‹å™¨"""
    
    def __init__(self, model_path: str, feature_dim: int = 16):
        self.feature_dim = feature_dim
        
        # åˆå§‹åŒ–ONNX Runtime
        providers = ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
        sess_options = ort.SessionOptions()
        sess_options.intra_op_num_threads = 2
        
        self.session = ort.InferenceSession(
            model_path,
            sess_options=sess_options,
            providers=providers
        )
        
        self.input_name = self.session.get_inputs()[0].name
        
        # ç‰¹å¾æå–å™¨
        self.feature_extractor = FeatureExtractor()
        
        # è®¾å¤‡æ•°æ®ç¼“å­˜
        self.device_data: Dict[str, deque] = {}
        self.device_health: Dict[str, float] = {}
        
    def update_sensor_data(self, reading: SensorReading):
        """æ›´æ–°ä¼ æ„Ÿå™¨æ•°æ®"""
        if reading.device_id not in self.device_data:
            self.device_data[reading.device_id] = {
                'vibration': deque(maxlen=1000),
                'temperature': deque(maxlen=1000),
                'current': deque(maxlen=1000)
            }
            self.device_health[reading.device_id] = 100.0
            
        if reading.sensor_type in self.device_data[reading.device_id]:
            self.device_data[reading.device_id][reading.sensor_type].append(reading.value)
            
    def predict(self, device_id: str) -> Optional[PredictionResult]:
        """é¢„æµ‹è®¾å¤‡çŠ¶æ€"""
        if device_id not in self.device_data:
            return None
            
        data = self.device_data[device_id]
        
        # æ£€æŸ¥æ•°æ®é‡
        if len(data['vibration']) < 100:
            return None
            
        # æå–ç‰¹å¾
        vibration_features = self.feature_extractor.extract_features(
            np.array(data['vibration'])
        )
        temp_features = self.feature_extractor.extract_features(
            np.array(data['temperature'])
        )
        current_features = self.feature_extractor.extract_features(
            np.array(data['current'])
        )
        
        # åˆå¹¶ç‰¹å¾
        features = np.concatenate([vibration_features, temp_features, current_features])
        features = features.reshape(1, -1).astype(np.float32)
        
        # æ¨ç†
        outputs = self.session.run(None, {self.input_name: features})
        
        failure_prob = float(outputs[0][0][0])
        rul = int(outputs[1][0][0]) if len(outputs) > 1 else None
        
        # æ›´æ–°å¥åº·åº¦
        health = max(0, 100 - failure_prob * 100)
        self.device_health[device_id] = health * 0.9 + self.device_health[device_id] * 0.1
        
        # ç¡®å®šæ¨èæ“ä½œ
        action = self._determine_action(failure_prob, self.device_health[device_id])
        
        return PredictionResult(
            device_id=device_id,
            timestamp=datetime.now(),
            failure_probability=failure_prob,
            remaining_useful_life=rul,
            health_score=self.device_health[device_id],
            anomaly_score=failure_prob,
            recommended_action=action
        )
        
    def _determine_action(self, failure_prob: float, health: float) -> str:
        """ç¡®å®šæ¨èæ“ä½œ"""
        if failure_prob > 0.7 or health < 30:
            return "URGENT: Schedule immediate maintenance"
        elif failure_prob > 0.4 or health < 60:
            return "WARNING: Plan maintenance within 7 days"
        elif failure_prob > 0.2 or health < 80:
            return "ADVISORY: Schedule routine inspection"
        else:
            return "NORMAL: Continue monitoring"


class EdgeMaintenanceSystem:
    """è¾¹ç¼˜ç»´æŠ¤ç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self, model_path: str, mqtt_broker: str):
        self.predictor = EdgePredictor(model_path)
        self.mqtt_broker = mqtt_broker
        
        # é¢„æµ‹ç»“æœé˜Ÿåˆ—
        self.prediction_queue = queue.Queue()
        
        # è¿è¡ŒçŠ¶æ€
        self.running = False
        
    def start(self):
        """å¯åŠ¨ç³»ç»Ÿ"""
        self.running = True
        
        # å¯åŠ¨æ•°æ®æ¥æ”¶çº¿ç¨‹
        self.data_thread = threading.Thread(target=self._data_receiver)
        self.data_thread.start()
        
        # å¯åŠ¨é¢„æµ‹çº¿ç¨‹
        self.prediction_thread = threading.Thread(target=self._prediction_loop)
        self.prediction_thread.start()
        
        # å¯åŠ¨ä¸ŠæŠ¥çº¿ç¨‹
        self.upload_thread = threading.Thread(target=self._upload_loop)
        self.upload_thread.start()
        
        print("Edge Maintenance System started")
        
    def _data_receiver(self):
        """æ•°æ®æ¥æ”¶å¾ªç¯ï¼ˆæ¨¡æ‹ŸMQTTæ¥æ”¶ï¼‰"""
        while self.running:
            # æ¨¡æ‹Ÿæ¥æ”¶ä¼ æ„Ÿå™¨æ•°æ®
            # å®é™…åº”ä»MQTTè®¢é˜…
            time.sleep(0.1)
            
    def _prediction_loop(self):
        """é¢„æµ‹å¾ªç¯"""
        while self.running:
            for device_id in list(self.predictor.device_data.keys()):
                result = self.predictor.predict(device_id)
                if result:
                    self.prediction_queue.put(result)
                    
                    # é«˜ä¼˜å…ˆçº§å‘Šè­¦ç«‹å³ä¸ŠæŠ¥
                    if result.failure_probability > 0.5:
                        self._send_alert(result)
                        
            time.sleep(60)  # æ¯åˆ†é’Ÿé¢„æµ‹ä¸€æ¬¡
            
    def _upload_loop(self):
        """ä¸ŠæŠ¥å¾ªç¯"""
        while self.running:
            try:
                result = self.prediction_queue.get(timeout=300)  # 5åˆ†é’Ÿæ‰¹é‡ä¸ŠæŠ¥
                self._upload_result(result)
            except queue.Empty:
                # æ‰¹é‡ä¸ŠæŠ¥å¥åº·çŠ¶æ€
                self._upload_health_summary()
                
    def _send_alert(self, result: PredictionResult):
        """å‘é€å‘Šè­¦"""
        alert = {
            "type": "PREDICTIVE_MAINTENANCE_ALERT",
            "device_id": result.device_id,
            "timestamp": result.timestamp.isoformat(),
            "failure_probability": result.failure_probability,
            "health_score": result.health_score,
            "recommended_action": result.recommended_action
        }
        print(f"ALERT: {json.dumps(alert)}")
        
    def _upload_result(self, result: PredictionResult):
        """ä¸ŠæŠ¥é¢„æµ‹ç»“æœ"""
        # å®é™…ä¸Šä¼ åˆ°äº‘ç«¯
        pass
        
    def _upload_health_summary(self):
        """ä¸ŠæŠ¥å¥åº·çŠ¶æ€æ±‡æ€»"""
        summary = {
            "timestamp": datetime.now().isoformat(),
            "device_health": self.predictor.device_health
        }
        print(f"Health Summary: {json.dumps(summary)}")
        
    def stop(self):
        """åœæ­¢ç³»ç»Ÿ"""
        self.running = False
        self.data_thread.join()
        self.prediction_thread.join()
        self.upload_thread.join()
        print("Edge Maintenance System stopped")


# æ¼”ç¤º
if __name__ == "__main__":
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    
    system = EdgeMaintenanceSystem(
        model_path="models/lstm_predictor.onnx",
        mqtt_broker="mqtt.factory.local"
    )
    
    # æ¨¡æ‹Ÿè®¾å¤‡æ•°æ®
    for i in range(1000):
        # æ¨¡æ‹Ÿä¼ æ„Ÿå™¨æ•°æ®ï¼ˆæ·»åŠ è¶‹åŠ¿æ¨¡æ‹Ÿæ•…éšœï¼‰
        base_vibration = 2.0 + i * 0.001  # é€æ¸å¢å¤§
        vibration = np.random.normal(base_vibration, 0.5)
        
        reading = SensorReading(
            timestamp=datetime.now(),
            device_id="CNC_001",
            sensor_type="vibration",
            value=vibration,
            unit="mm/s"
        )
        system.predictor.update_sensor_data(reading)
        
    # é¢„æµ‹
    result = system.predictor.predict("CNC_001")
    if result:
        print(f"\nPrediction Result:")
        print(f"  Device: {result.device_id}")
        print(f"  Failure Probability: {result.failure_probability:.2%}")
        print(f"  Health Score: {result.health_score:.1f}")
        print(f"  Remaining Useful Life: {result.remaining_useful_life} hours")
        print(f"  Recommended Action: {result.recommended_action}")
```

### 3.4 æ•ˆæœè¯„ä¼°ä¸ROI

| æŒ‡æ ‡ | å®æ–½å‰ | å®æ–½å | æå‡å¹…åº¦ |
|------|--------|--------|----------|
| è®¡åˆ’å¤–åœæœºæ—¶é—´ | 450å°æ—¶/å¹´ | 120å°æ—¶/å¹´ | **73%é™ä½** |
| ç»´æŠ¤æˆæœ¬ | åŸºå‡† | -30% | **30%èŠ‚çœ** |
| è®¾å¤‡å¯¿å‘½ | åŸºå‡† | +15% | **15%å»¶é•¿** |
| é¢„æµ‹å‡†ç¡®ç‡ | N/A | 89% | **é«˜ç²¾åº¦** |
| æ£€æµ‹å»¶è¿Ÿ | N/A | <50ms | **å®æ—¶** |

---

## 4. æ¡ˆä¾‹3ï¼šè‡ªåŠ¨é©¾é©¶è¾¹ç¼˜æ¨ç†

*ï¼ˆä¿ç•™åŸæœ‰å†…å®¹ï¼‰*

## 5. æ¡ˆä¾‹4ï¼šæ™ºèƒ½è¯­éŸ³åŠ©æ‰‹è¾¹ç¼˜éƒ¨ç½²

*ï¼ˆä¿ç•™åŸæœ‰å†…å®¹ï¼‰*

## 6. æ¡ˆä¾‹æ€»ç»“

### 6.1 æ¡ˆä¾‹å¯¹æ¯”

| æ¡ˆä¾‹ | åº”ç”¨åœºæ™¯ | å»¶è¿Ÿè¦æ±‚ | æ¨¡å‹å¤§å° | ç²¾åº¦ | åŠŸè€— | ROI |
|------|---------|---------|---------|------|------|-----|
| **æ™ºèƒ½æ‘„åƒå¤´** | é›¶å”®ç›‘æ§ | <100ms | 5MB | 90% | 15W | 76% |
| **é¢„æµ‹ç»´æŠ¤** | å·¥ä¸šè®¾å¤‡ | <50ms | 2MB | 89% | 10W | 180% |
| **è‡ªåŠ¨é©¾é©¶** | è½¦è¾†æ§åˆ¶ | <10ms | 50MB | 95% | 100W | N/A |
| **è¯­éŸ³åŠ©æ‰‹** | æ™ºèƒ½éŸ³ç®± | <200ms | 200MB | 94% | 5W | 120% |

### 6.2 æœ€ä½³å®è·µ

1. **æ¨¡å‹ä¼˜åŒ–**ï¼šä½¿ç”¨INT8é‡åŒ–ã€å‰ªæã€çŸ¥è¯†è’¸é¦ç­‰æŠ€æœ¯å‹ç¼©æ¨¡å‹
2. **ç¡¬ä»¶é€‰å‹**ï¼šæ ¹æ®å»¶è¿Ÿå’ŒåŠŸè€—è¦æ±‚é€‰æ‹©åˆé€‚çš„è¾¹ç¼˜èŠ¯ç‰‡
3. **è¾¹ç¼˜-äº‘ååŒ**ï¼šåˆç†åˆ†é…è®¡ç®—ä»»åŠ¡ï¼Œè¾¹ç¼˜åšå®æ—¶å¤„ç†ï¼Œäº‘ç«¯åšè®­ç»ƒ
4. **OTAæ›´æ–°**ï¼šæ”¯æŒæ¨¡å‹çš„è¿œç¨‹æ›´æ–°å’Œç‰ˆæœ¬ç®¡ç†
5. **å®‰å…¨åŠ å›º**ï¼šè¾¹ç¼˜è®¾å¤‡éœ€è¦é˜²ç¯¡æ”¹å’ŒåŠ å¯†ä¿æŠ¤

---

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-02-15
**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv2.0
**ç»´æŠ¤è€…**ï¼šDSL Schemaç ”ç©¶å›¢é˜Ÿ
