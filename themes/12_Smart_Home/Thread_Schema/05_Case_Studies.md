# Thread Schemaå®è·µæ¡ˆä¾‹

## ğŸ“‘ ç›®å½•

- [Thread Schemaå®è·µæ¡ˆä¾‹](#thread-schemaå®è·µæ¡ˆä¾‹)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¡ˆä¾‹æ¦‚è¿°](#1-æ¡ˆä¾‹æ¦‚è¿°)
  - [2. æ¡ˆä¾‹1ï¼šThread Meshç½‘ç»œæ„å»º](#2-æ¡ˆä¾‹1thread-meshç½‘ç»œæ„å»º)
    - [2.1 åœºæ™¯æè¿°](#21-åœºæ™¯æè¿°)
    - [2.2 Schemaå®šä¹‰](#22-schemaå®šä¹‰)
    - [2.3 å®ç°ä»£ç ](#23-å®ç°ä»£ç )
  - [3. æ¡ˆä¾‹2ï¼šThreadè·¯ç”±ç®¡ç†å’Œä¼˜åŒ–](#3-æ¡ˆä¾‹2threadè·¯ç”±ç®¡ç†å’Œä¼˜åŒ–)
    - [3.1 åœºæ™¯æè¿°](#31-åœºæ™¯æè¿°)
    - [3.2 Schemaå®šä¹‰](#32-schemaå®šä¹‰)
    - [3.3 å®ç°ä»£ç ](#33-å®ç°ä»£ç )
  - [4. æ¡ˆä¾‹3ï¼šThreadç½‘ç»œå®‰å…¨å’Œå¯†é’¥ç®¡ç†](#4-æ¡ˆä¾‹3threadç½‘ç»œå®‰å…¨å’Œå¯†é’¥ç®¡ç†)
    - [4.1 åœºæ™¯æè¿°](#41-åœºæ™¯æè¿°)
    - [4.2 Schemaå®šä¹‰](#42-schemaå®šä¹‰)
    - [4.3 å®ç°ä»£ç ](#43-å®ç°ä»£ç )
  - [5. æ¡ˆä¾‹4ï¼šThreadç½‘ç»œæ€§èƒ½ç›‘æ§](#5-æ¡ˆä¾‹4threadç½‘ç»œæ€§èƒ½ç›‘æ§)
    - [5.1 åœºæ™¯æè¿°](#51-åœºæ™¯æè¿°)
    - [5.2 å®ç°ä»£ç ](#52-å®ç°ä»£ç )
  - [6. æ¡ˆä¾‹5ï¼šThreadåˆ°Zigbeeç½‘ç»œè½¬æ¢](#6-æ¡ˆä¾‹5threadåˆ°zigbeeç½‘ç»œè½¬æ¢)
    - [6.1 åœºæ™¯æè¿°](#61-åœºæ™¯æè¿°)
    - [6.2 å®ç°ä»£ç ](#62-å®ç°ä»£ç )
  - [7. æ¡ˆä¾‹6ï¼šThreadæ•°æ®å­˜å‚¨å’Œåˆ†æç³»ç»Ÿ](#7-æ¡ˆä¾‹6threadæ•°æ®å­˜å‚¨å’Œåˆ†æç³»ç»Ÿ)
    - [7.1 åœºæ™¯æè¿°](#71-åœºæ™¯æè¿°)
    - [7.2 å®ç°ä»£ç ](#72-å®ç°ä»£ç )
    - [7.3 æ•°æ®åˆ†æç¤ºä¾‹](#73-æ•°æ®åˆ†æç¤ºä¾‹)
  - [8. æ¡ˆä¾‹7ï¼šThreadç½‘ç»œæ‰©å±•ï¼ˆæ·»åŠ æ–°èŠ‚ç‚¹ï¼‰](#8-æ¡ˆä¾‹7threadç½‘ç»œæ‰©å±•æ·»åŠ æ–°èŠ‚ç‚¹)
    - [8.1 åœºæ™¯æè¿°](#81-åœºæ™¯æè¿°)
    - [8.2 Schemaå®šä¹‰](#82-schemaå®šä¹‰)
    - [8.3 å®ç°ä»£ç ](#83-å®ç°ä»£ç )
  - [9. æ¡ˆä¾‹8ï¼šThreadç½‘ç»œæ•…éšœæ¢å¤](#9-æ¡ˆä¾‹8threadç½‘ç»œæ•…éšœæ¢å¤)
    - [9.1 åœºæ™¯æè¿°](#91-åœºæ™¯æè¿°)
    - [9.2 Schemaå®šä¹‰](#92-schemaå®šä¹‰)
    - [9.3 å®ç°ä»£ç ](#93-å®ç°ä»£ç )

---

## 1. æ¡ˆä¾‹æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›Thread Schemaåœ¨å®é™…åº”ç”¨ä¸­çš„å®è·µæ¡ˆä¾‹ã€‚

---

## 2. æ¡ˆä¾‹1ï¼šThread Meshç½‘ç»œæ„å»º

### 2.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
ç”¨æˆ·éœ€è¦æ„å»ºä¸€ä¸ªThread Meshç½‘ç»œï¼Œè¿æ¥å¤šä¸ªæ™ºèƒ½å®¶å±…è®¾å¤‡ï¼Œ
åŒ…æ‹¬æ™ºèƒ½ç¯ã€ä¼ æ„Ÿå™¨ã€é—¨é”ç­‰ï¼Œå®ç°è®¾å¤‡é—´çš„Meshé€šä¿¡ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦åˆ›å»ºThreadç½‘ç»œå¹¶é…ç½®ç½‘ç»œå‚æ•°
- éœ€è¦å°†å¤šä¸ªè®¾å¤‡åŠ å…¥ç½‘ç»œ
- éœ€è¦ç®¡ç†ç½‘ç»œæ‹“æ‰‘
- éœ€è¦ç›‘æ§ç½‘ç»œçŠ¶æ€

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨ThreadNetworkManageråˆ›å»ºå’Œç®¡ç†Threadç½‘ç»œï¼Œå®ç°è®¾å¤‡çš„
è‡ªåŠ¨å‘ç°å’ŒåŠ å…¥ç½‘ç»œåŠŸèƒ½ã€‚

### 2.2 Schemaå®šä¹‰

è¯¦è§ç¬¬2.2èŠ‚åŸå§‹å®šä¹‰ã€‚

### 2.3 å®ç°ä»£ç 

**å®Œæ•´çš„Thread Meshç½‘ç»œæ„å»ºå®ç°**ï¼š

```python
import asyncio
from thread_network_manager import ThreadNetworkManager
from thread_storage import ThreadStorage

# åˆå§‹åŒ–å­˜å‚¨å’Œç®¡ç†å™¨
storage = ThreadStorage("postgresql://user:pass@localhost/thread")
network_manager = ThreadNetworkManager()

async def build_thread_mesh_network():
    """æ„å»ºThread Meshç½‘ç»œ"""
    try:
        # åˆ›å»ºThreadç½‘ç»œ
        network_name = "SmartHomeNet"
        pan_id = 0x1234
        channel = 15
        network_key = "00112233445566778899AABBCCDDEEFF"

        print(f"Creating Thread network: {network_name}")
        success = network_manager.create_network(
            network_name, pan_id, channel, network_key
        )

        if not success:
            print("Failed to create network")
            return

        # å­˜å‚¨ç½‘ç»œä¿¡æ¯
        network_data = {
            "network_name": network_name,
            "pan_id": pan_id,
            "extended_pan_id": "DEADBEEF00CAFE00",
            "channel": channel,
            "network_key": network_key,
            "partition_id": 1
        }
        storage.store_network(network_data)

        # èŠ‚ç‚¹åˆ—è¡¨
        nodes = [
            {"node_id": "000D6F0000123456", "type": "Router"},
            {"node_id": "000D6F0000654321", "type": "EndDevice"},
            {"node_id": "000D6F0000789012", "type": "EndDevice"}
        ]

        # å°†èŠ‚ç‚¹åŠ å…¥ç½‘ç»œ
        for node in nodes:
            print(f"Joining node {node['node_id']} to network...")
            success = network_manager.join_network(
                node["node_id"],
                network_name,
                network_key,
                pan_id,
                channel
            )

            if success:
                # è·å–èŠ‚ç‚¹ä¿¡æ¯
                node_info = network_manager.get_node_info(node["node_id"])
                if node_info:
                    # å­˜å‚¨èŠ‚ç‚¹ä¿¡æ¯
                    storage.store_node(node_info)
                    print(f"Node {node['node_id']} joined successfully")
                    print(f"  Type: {node_info['node_type']}")
                    print(f"  Mesh Local: {node_info['mesh_local_address']}")
            else:
                print(f"Failed to join node {node['node_id']}")

        # è·å–ç½‘ç»œæ‹“æ‰‘
        topology = network_manager.get_network_topology(network_name)
        print(f"\nNetwork Topology:")
        print(f"  Total nodes: {len(topology['nodes'])}")
        print(f"  Routers: {len(topology['routers'])}")
        print(f"  End Devices: {len(topology['end_devices'])}")

        # æŸ¥è¯¢ç½‘ç»œå¥åº·çŠ¶æ€
        health = storage.get_network_health_status(network_name)
        print(f"\nNetwork Health:")
        print(f"  Health Score: {health['health_score']:.1f}/100")
        print(f"  Avg Link Quality: {health['avg_link_quality']:.1f}")
        print(f"  Low Battery Nodes: {health['low_battery_count']}")

    except Exception as e:
        print(f"Error building network: {e}")

# è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    asyncio.run(build_thread_mesh_network())
```

---

## 3. æ¡ˆä¾‹2ï¼šThreadè·¯ç”±ç®¡ç†å’Œä¼˜åŒ–

### 3.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
ç³»ç»Ÿéœ€è¦ç®¡ç†Threadç½‘ç»œçš„è·¯ç”±è¡¨ï¼Œç›‘æ§è·¯ç”±æ€§èƒ½ï¼Œ
å¹¶åœ¨è·¯ç”±å¤±æ•ˆæ—¶è‡ªåŠ¨æ›´æ–°è·¯ç”±è¡¨ï¼Œç¡®ä¿ç½‘ç»œè¿é€šæ€§ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦å®šæœŸæ›´æ–°è·¯ç”±è¡¨
- éœ€è¦ç›‘æ§è·¯ç”±æ€§èƒ½
- éœ€è¦æ£€æµ‹è·¯ç”±å¤±æ•ˆ
- éœ€è¦ä¼˜åŒ–è·¯ç”±è·¯å¾„

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨ThreadRoutingManagerç®¡ç†è·¯ç”±è¡¨ï¼Œå®šæœŸæ›´æ–°è·¯ç”±ä¿¡æ¯
å¹¶ç›‘æ§è·¯ç”±æ€§èƒ½ã€‚

### 3.2 Schemaå®šä¹‰

è¯¦è§ç¬¬3.2èŠ‚åŸå§‹å®šä¹‰ã€‚

### 3.3 å®ç°ä»£ç 

**å®Œæ•´çš„è·¯ç”±ç®¡ç†å®ç°**ï¼š

```python
import asyncio
from thread_network_manager import ThreadNetworkManager
from thread_routing_manager import ThreadRoutingManager
from thread_storage import ThreadStorage
import time

# åˆå§‹åŒ–ç»„ä»¶
storage = ThreadStorage("postgresql://user:pass@localhost/thread")
network_manager = ThreadNetworkManager()
routing_manager = ThreadRoutingManager(network_manager)

async def manage_thread_routing():
    """ç®¡ç†Threadè·¯ç”±"""
    try:
        network_name = "SmartHomeNet"

        # è·å–ç½‘ç»œä¸­çš„æ‰€æœ‰èŠ‚ç‚¹
        topology = network_manager.get_network_topology(network_name)
        nodes = topology["nodes"]

        print(f"Managing routing for {len(nodes)} nodes")

        # æ›´æ–°æ‰€æœ‰èŠ‚ç‚¹çš„è·¯ç”±è¡¨
        for node in nodes:
            node_id = node["node_id"]
            print(f"Updating routing table for node {node_id}...")

            # æ›´æ–°è·¯ç”±è¡¨
            routing_manager.update_routing_table(node_id)

            # è·å–è·¯ç”±è¡¨
            routes = routing_manager.get_node_routes(node_id)
            print(f"  Found {len(routes)} routes")

            # å­˜å‚¨è·¯ç”±è¡¨åˆ°æ•°æ®åº“
            storage.store_routing_table(node_id, routes)

            # æ˜¾ç¤ºè·¯ç”±ç»Ÿè®¡
            route_stats = storage.get_routing_statistics(node_id)
            print(f"  Route count: {route_stats['route_count']}")
            print(f"  Avg cost: {route_stats['avg_cost']:.2f}")
            print(f"  Max hops: {route_stats['max_cost']}")

        # è·å–ç½‘ç»œè·¯ç”±ç»Ÿè®¡
        network_stats = routing_manager.get_network_routing_statistics(network_name)
        print(f"\nNetwork Routing Statistics:")
        print(f"  Total nodes: {network_stats['total_nodes']}")
        print(f"  Total routes: {network_stats['total_routes']}")
        print(f"  Avg routes per node: {network_stats['avg_routes_per_node']:.2f}")
        print(f"  Avg cost: {network_stats['avg_cost']:.2f}")
        print(f"  Max hops: {network_stats['max_hops']}")

        # æµ‹è¯•è·¯ç”±æŸ¥æ‰¾
        if len(nodes) >= 2:
            source_node = nodes[0]["node_id"]
            dest_address = nodes[1].get("mesh_local_address")

            if dest_address:
                route = routing_manager.find_route(source_node, dest_address)
                if route:
                    print(f"\nRoute from {source_node} to {dest_address}:")
                    print(f"  Next hop: {route['next_hop']}")
                    print(f"  Cost: {route['cost']}")
                else:
                    print(f"\nNo route found from {source_node} to {dest_address}")

    except Exception as e:
        print(f"Error managing routing: {e}")

# è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    asyncio.run(manage_thread_routing())
```

---

## 4. æ¡ˆä¾‹3ï¼šThreadç½‘ç»œå®‰å…¨å’Œå¯†é’¥ç®¡ç†

### 4.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
ç³»ç»Ÿéœ€è¦ç®¡ç†Threadç½‘ç»œçš„å®‰å…¨å¯†é’¥ï¼Œå®šæœŸè½®æ¢ç½‘ç»œå¯†é’¥ï¼Œ
ç¡®ä¿ç½‘ç»œå®‰å…¨ï¼Œå¹¶ç›‘æ§å®‰å…¨äº‹ä»¶ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦å®šæœŸè½®æ¢ç½‘ç»œå¯†é’¥
- éœ€è¦åŒæ­¥å¯†é’¥åˆ°æ‰€æœ‰èŠ‚ç‚¹
- éœ€è¦ç›‘æ§å®‰å…¨äº‹ä»¶
- éœ€è¦å¤„ç†å¯†é’¥è½®æ¢å¤±è´¥çš„æƒ…å†µ

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨ThreadSecurityManagerç®¡ç†ç½‘ç»œå¯†é’¥ï¼Œå®ç°å¯†é’¥è½®æ¢
å’Œå®‰å…¨ç›‘æ§åŠŸèƒ½ã€‚

### 4.2 Schemaå®šä¹‰

è¯¦è§ç¬¬4.2èŠ‚åŸå§‹å®šä¹‰ã€‚

### 4.3 å®ç°ä»£ç 

**å®Œæ•´çš„å®‰å…¨ç®¡ç†å®ç°**ï¼š

```python
import asyncio
from thread_security_manager import ThreadSecurityManager
from thread_storage import ThreadStorage
from datetime import datetime, timedelta

# åˆå§‹åŒ–ç»„ä»¶
storage = ThreadStorage("postgresql://user:pass@localhost/thread")
security_manager = ThreadSecurityManager(storage)

async def manage_thread_security():
    """ç®¡ç†Threadç½‘ç»œå®‰å…¨"""
    try:
        network_name = "SmartHomeNet"

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è½®æ¢å¯†é’¥
        # è¿™é‡Œåº”è¯¥ä»æ•°æ®åº“æŸ¥è¯¢ä¸Šæ¬¡è½®æ¢æ—¶é—´
        last_rotation_time = datetime.now() - timedelta(days=2)
        rotation_interval = timedelta(days=1)

        if datetime.now() - last_rotation_time > rotation_interval:
            print("Rotating network key...")
            success = security_manager.rotate_network_key(network_name)

            if success:
                print("Network key rotated successfully")
                # è¿™é‡Œéœ€è¦é€šçŸ¥æ‰€æœ‰èŠ‚ç‚¹æ›´æ–°å¯†é’¥
                # å®é™…å®ç°éœ€è¦è°ƒç”¨OpenThread APIæ›´æ–°æ‰€æœ‰èŠ‚ç‚¹
            else:
                print("Failed to rotate network key")
        else:
            print("Network key is still valid, no rotation needed")

        # æŸ¥è¯¢å®‰å…¨ç»Ÿè®¡
        # è¿™é‡Œå¯ä»¥æŸ¥è¯¢å®‰å…¨äº‹ä»¶ã€å¯†é’¥ä½¿ç”¨æƒ…å†µç­‰

    except Exception as e:
        print(f"Error managing security: {e}")

# è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    asyncio.run(manage_thread_security())
```

---

## 5. æ¡ˆä¾‹4ï¼šThreadç½‘ç»œæ€§èƒ½ç›‘æ§

### 5.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
ç³»ç»Ÿéœ€è¦ç›‘æ§Threadç½‘ç»œçš„æ€§èƒ½æŒ‡æ ‡ï¼ŒåŒ…æ‹¬å»¶è¿Ÿã€ä¸¢åŒ…ç‡ã€
ååé‡ç­‰ï¼ŒåŠæ—¶å‘ç°ç½‘ç»œé—®é¢˜å¹¶ä¼˜åŒ–ç½‘ç»œæ€§èƒ½ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦å®æ—¶æ”¶é›†æ€§èƒ½æ•°æ®
- éœ€è¦åˆ†ææ€§èƒ½è¶‹åŠ¿
- éœ€è¦è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
- éœ€è¦ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨ThreadStorageå­˜å‚¨æ€§èƒ½æ•°æ®ï¼Œå®šæœŸæ”¶é›†å’Œåˆ†æç½‘ç»œæ€§èƒ½ã€‚

### 5.2 å®ç°ä»£ç 

**å®Œæ•´çš„æ€§èƒ½ç›‘æ§å®ç°**ï¼š

```python
import asyncio
from thread_network_manager import ThreadNetworkManager
from thread_storage import ThreadStorage
import time

# åˆå§‹åŒ–ç»„ä»¶
storage = ThreadStorage("postgresql://user:pass@localhost/thread")
network_manager = ThreadNetworkManager()

async def monitor_thread_performance():
    """ç›‘æ§Threadç½‘ç»œæ€§èƒ½"""
    try:
        network_name = "SmartHomeNet"

        # è·å–ç½‘ç»œä¸­çš„æ‰€æœ‰èŠ‚ç‚¹
        topology = network_manager.get_network_topology(network_name)
        nodes = topology["nodes"]

        print(f"Monitoring performance for {len(nodes)} nodes")

        # æ”¶é›†æ€§èƒ½æ•°æ®
        for node in nodes:
            node_id = node["node_id"]

            # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®æ”¶é›†
            # å®é™…å®ç°éœ€è¦ä»OpenThreadè·å–çœŸå®æ•°æ®
            performance_data = {
                "latency_ms": 50 + (hash(node_id) % 50),  # æ¨¡æ‹Ÿå»¶è¿Ÿ
                "packet_loss_rate": (hash(node_id) % 5) / 100.0,  # æ¨¡æ‹Ÿä¸¢åŒ…ç‡
                "throughput_kbps": 100 + (hash(node_id) % 200)  # æ¨¡æ‹Ÿååé‡
            }

            # å­˜å‚¨æ€§èƒ½æ•°æ®
            storage.store_performance_data(node_id, performance_data)

            print(f"Node {node_id}:")
            print(f"  Latency: {performance_data['latency_ms']}ms")
            print(f"  Packet Loss: {performance_data['packet_loss_rate']*100:.2f}%")
            print(f"  Throughput: {performance_data['throughput_kbps']}kbps")

        # æŸ¥è¯¢ç½‘ç»œæ€§èƒ½ç»Ÿè®¡
        perf_stats = storage.get_network_performance_statistics(network_name, hours=24)
        print(f"\nNetwork Performance Statistics (24h):")
        print(f"  Avg Latency: {perf_stats['avg_latency']:.2f}ms")
        print(f"  Avg Packet Loss: {perf_stats['avg_packet_loss']*100:.2f}%")
        print(f"  Avg Throughput: {perf_stats['avg_throughput']:.2f}kbps")
        print(f"  Monitored Nodes: {perf_stats['monitored_nodes']}")

        # æŸ¥è¯¢èŠ‚ç‚¹æ€§èƒ½å†å²
        if nodes:
            node_id = nodes[0]["node_id"]
            history = storage.get_node_performance_history(node_id, hours=1)
            print(f"\nPerformance History for {node_id} (1h):")
            print(f"  Data points: {len(history)}")
            if history:
                print(f"  Latest latency: {history[0]['latency_ms']}ms")

    except Exception as e:
        print(f"Error monitoring performance: {e}")

# è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    asyncio.run(monitor_thread_performance())
```

---

## 6. æ¡ˆä¾‹5ï¼šThreadåˆ°Zigbeeç½‘ç»œè½¬æ¢

### 6.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
éœ€è¦å°†Threadç½‘ç»œè½¬æ¢ä¸ºZigbeeç½‘ç»œï¼Œä»¥ä¾¿ä¸ç°æœ‰çš„Zigbeeç³»ç»Ÿé›†æˆï¼Œ
å®ç°è·¨åè®®è®¾å¤‡é€šä¿¡ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦è½¬æ¢èŠ‚ç‚¹ç±»å‹
- éœ€è¦è½¬æ¢ç½‘ç»œåœ°å€
- éœ€è¦ä¿æŒç½‘ç»œæ‹“æ‰‘ä¸€è‡´æ€§
- éœ€è¦å¤„ç†åè®®å·®å¼‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨ThreadToZigbeeConverterå®ç°Threadåˆ°Zigbeeçš„è½¬æ¢ã€‚

### 6.2 å®ç°ä»£ç 

è¯¦è§ `04_Transformation.md` ç¬¬2.2ç« ã€‚

---

## 7. æ¡ˆä¾‹6ï¼šThreadæ•°æ®å­˜å‚¨å’Œåˆ†æç³»ç»Ÿ

### 7.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
ä½¿ç”¨PostgreSQLå­˜å‚¨Threadç½‘ç»œæ•°æ®ï¼Œæ”¯æŒç½‘ç»œæ‹“æ‰‘åˆ†æã€
æ€§èƒ½ç›‘æ§å’Œå¥åº·çŠ¶æ€è¯„ä¼°ã€‚

### 7.2 å®ç°ä»£ç 

è¯¦è§ `04_Transformation.md` ç¬¬6ç« ã€‚

### 7.3 æ•°æ®åˆ†æç¤ºä¾‹

**ç½‘ç»œå¥åº·çŠ¶æ€æŸ¥è¯¢**ï¼š

```python
from thread_storage import ThreadStorage

storage = ThreadStorage("postgresql://user:pass@localhost/thread")

# æŸ¥è¯¢ç½‘ç»œå¥åº·çŠ¶æ€
health = storage.get_network_health_status("SmartHomeNet")
print("Network Health Status:")
print(f"  Total Nodes: {health['total_nodes']}")
print(f"  Routers: {health['router_count']}")
print(f"  End Devices: {health['end_device_count']}")
print(f"  Avg Link Quality: {health['avg_link_quality']:.1f}")
print(f"  Avg RSSI: {health['avg_rssi']:.1f}dBm")
print(f"  Low Battery Nodes: {health['low_battery_count']}")
print(f"  Health Score: {health['health_score']:.1f}/100")

# æŸ¥è¯¢ç½‘ç»œæ‹“æ‰‘ç»Ÿè®¡
topology_stats = storage.get_network_topology_statistics("SmartHomeNet")
print("\nTopology Statistics:")
for stat in topology_stats:
    print(f"  {stat['node_type']}: {stat['count']} nodes")
    print(f"    Avg Link Quality: {stat['avg_link_quality']:.1f}")
    print(f"    Avg RSSI: {stat['avg_rssi']:.1f}dBm")
```

---

## 8. æ¡ˆä¾‹7ï¼šThreadç½‘ç»œæ‰©å±•ï¼ˆæ·»åŠ æ–°èŠ‚ç‚¹ï¼‰

### 8.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
ç”¨æˆ·éœ€è¦åœ¨ç°æœ‰çš„Threadç½‘ç»œä¸­åŠ¨æ€æ·»åŠ æ–°çš„æ™ºèƒ½è®¾å¤‡ï¼ŒåŒ…æ‹¬æ–°çš„Routerå’ŒEnd Deviceï¼Œ
ç¡®ä¿æ–°èŠ‚ç‚¹èƒ½å¤Ÿé¡ºåˆ©åŠ å…¥ç½‘ç»œå¹¶å»ºç«‹æ­£ç¡®çš„è·¯ç”±å…³ç³»ã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦æ£€æµ‹æ–°èŠ‚ç‚¹å¹¶å¼•å¯¼å…¶åŠ å…¥ç½‘ç»œ
- éœ€è¦ä¸ºæ–°èŠ‚ç‚¹åˆ†é…ç½‘ç»œåœ°å€å’Œè·¯ç”±ä¿¡æ¯
- éœ€è¦æ›´æ–°ç°æœ‰èŠ‚ç‚¹çš„è·¯ç”±è¡¨
- éœ€è¦å¤„ç†èŠ‚ç‚¹åŠ å…¥å¤±è´¥çš„æƒ…å†µ
- éœ€è¦ä¼˜åŒ–ç½‘ç»œæ‹“æ‰‘ä»¥é€‚åº”æ–°èŠ‚ç‚¹

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨ThreadNetworkManagerçš„èŠ‚ç‚¹åŠ å…¥åŠŸèƒ½ï¼Œç»“åˆè·¯ç”±ç®¡ç†å™¨çš„è‡ªåŠ¨è·¯ç”±æ›´æ–°ï¼Œ
å®ç°æ–°èŠ‚ç‚¹çš„æ— ç¼åŠ å…¥å’Œç½‘ç»œæ‰©å±•ã€‚

### 8.2 Schemaå®šä¹‰

**ç½‘ç»œæ‰©å±•Schema**ï¼š

```json
{
  "network_name": "SmartHomeNet",
  "new_nodes": [
    {
      "node_id": "000D6F0000ABCDEF",
      "node_type": "Router",
      "expected_role": "Router",
      "join_credentials": {
        "network_key": "00112233445566778899AABBCCDDEEFF",
        "pan_id": 4660,
        "channel": 15
      }
    },
    {
      "node_id": "000D6F0000FEDCBA",
      "node_type": "EndDevice",
      "expected_role": "EndDevice",
      "join_credentials": {
        "network_key": "00112233445566778899AABBCCDDEEFF",
        "pan_id": 4660,
        "channel": 15
      }
    }
  ],
  "expansion_strategy": {
    "update_routing_tables": true,
    "optimize_topology": true,
    "verify_connectivity": true
  }
}
```

### 8.3 å®ç°ä»£ç 

**å®Œæ•´çš„ç½‘ç»œæ‰©å±•å®ç°**ï¼š

```python
import logging
from datetime import datetime
from thread_network_manager import ThreadNetworkManager
from thread_routing_manager import ThreadRoutingManager
from thread_storage import ThreadStorage
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–ç»„ä»¶
storage = ThreadStorage("postgresql://user:pass@localhost/thread")
network_manager = ThreadNetworkManager()
routing_manager = ThreadRoutingManager(network_manager)

def expand_thread_network(network_name: str, new_nodes: List[Dict]) -> Dict:
    """æ‰©å±•Threadç½‘ç»œ - æ·»åŠ æ–°èŠ‚ç‚¹"""
    results = {
        "network_name": network_name,
        "timestamp": datetime.now().isoformat(),
        "successful_joins": [],
        "failed_joins": [],
        "routing_updates": [],
        "topology_changes": {}
    }

    try:
        # 1. è·å–å½“å‰ç½‘ç»œçŠ¶æ€
        current_topology = network_manager.get_network_topology(network_name)
        initial_node_count = len(current_topology["nodes"])
        logger.info(f"Current network has {initial_node_count} nodes")

        # 2. æ·»åŠ æ–°èŠ‚ç‚¹
        for new_node in new_nodes:
            node_id = new_node["node_id"]
            node_type = new_node.get("node_type", "EndDevice")
            credentials = new_node.get("join_credentials", {})

            logger.info(f"Adding new node {node_id} (type: {node_type})...")

            try:
                # åŠ å…¥ç½‘ç»œ
                success = network_manager.join_network(
                    node_id,
                    network_name,
                    credentials.get("network_key"),
                    credentials.get("pan_id"),
                    credentials.get("channel")
                )

                if success:
                    # è·å–èŠ‚ç‚¹ä¿¡æ¯
                    node_info = network_manager.get_node_info(node_id)
                    if node_info:
                        # å­˜å‚¨èŠ‚ç‚¹ä¿¡æ¯
                        storage.store_node(node_info)

                        # è®°å½•äº‹ä»¶
                        storage.store_event(
                            network_name,
                            "node_joined",
                            {
                                "node_id": node_id,
                                "node_type": node_type,
                                "mesh_local_address": node_info.get("mesh_local_address")
                            },
                            node_id
                        )

                        results["successful_joins"].append({
                            "node_id": node_id,
                            "node_type": node_type,
                            "mesh_local_address": node_info.get("mesh_local_address"),
                            "parent_node_id": node_info.get("parent_node_id"),
                            "router_id": node_info.get("router_id")
                        })

                        logger.info(f"Node {node_id} joined successfully")

                        # ç­‰å¾…èŠ‚ç‚¹ç¨³å®š
                        time.sleep(2)
                    else:
                        raise Exception("Failed to get node info after join")
                else:
                    raise Exception("Failed to join network")

            except Exception as e:
                logger.error(f"Failed to add node {node_id}: {e}")
                results["failed_joins"].append({
                    "node_id": node_id,
                    "error": str(e)
                })

        # 3. æ›´æ–°è·¯ç”±è¡¨
        logger.info("Updating routing tables...")
        updated_count = routing_manager.update_all_routing_tables(network_name)
        results["routing_updates"] = {
            "updated_nodes": updated_count,
            "timestamp": datetime.now().isoformat()
        }

        # 4. ä¼˜åŒ–è·¯ç”±è¡¨
        logger.info("Optimizing routing tables...")
        topology = network_manager.get_network_topology(network_name)
        optimized_count = 0
        for node in topology["nodes"]:
            node_id = node["node_id"]
            if routing_manager.optimize_routing_table(node_id):
                optimized_count += 1

        results["routing_updates"]["optimized_nodes"] = optimized_count

        # 5. éªŒè¯è¿é€šæ€§
        logger.info("Verifying network connectivity...")
        final_topology = network_manager.get_network_topology(network_name)
        final_node_count = len(final_topology["nodes"])

        results["topology_changes"] = {
            "initial_node_count": initial_node_count,
            "final_node_count": final_node_count,
            "added_nodes": final_node_count - initial_node_count,
            "router_count": len(final_topology["routers"]),
            "end_device_count": len(final_topology["end_devices"])
        }

        # 6. ç½‘ç»œè¯Šæ–­
        logger.info("Running network diagnosis...")
        diagnosis = network_manager.diagnose_network(network_name)
        storage.store_diagnosis(network_name, diagnosis)

        results["diagnosis"] = {
            "issues_count": len(diagnosis.get("issues", [])),
            "connectivity_score": len(diagnosis["connectivity"]["connected_nodes"]) / final_node_count if final_node_count > 0 else 0,
            "routing_efficiency": diagnosis["routing"].get("complete_tables", [])
        }

        logger.info(f"Network expansion completed: {len(results['successful_joins'])} nodes added")
        return results

    except Exception as e:
        logger.error(f"Network expansion failed: {e}")
        results["error"] = str(e)
        return results

# æµ‹è¯•ç”¨ä¾‹
def test_network_expansion():
    """æµ‹è¯•ç½‘ç»œæ‰©å±•"""
    network_name = "SmartHomeNet"

    new_nodes = [
        {
            "node_id": "000D6F0000ABCDEF",
            "node_type": "Router",
            "join_credentials": {
                "network_key": "00112233445566778899AABBCCDDEEFF",
                "pan_id": 4660,
                "channel": 15
            }
        },
        {
            "node_id": "000D6F0000FEDCBA",
            "node_type": "EndDevice",
            "join_credentials": {
                "network_key": "00112233445566778899AABBCCDDEEFF",
                "pan_id": 4660,
                "channel": 15
            }
        }
    ]

    results = expand_thread_network(network_name, new_nodes)

    print(f"\nNetwork Expansion Results:")
    print(f"  Successful joins: {len(results['successful_joins'])}")
    print(f"  Failed joins: {len(results['failed_joins'])}")
    print(f"  Initial nodes: {results['topology_changes']['initial_node_count']}")
    print(f"  Final nodes: {results['topology_changes']['final_node_count']}")
    print(f"  Added nodes: {results['topology_changes']['added_nodes']}")

    if results.get("diagnosis"):
        print(f"  Connectivity score: {results['diagnosis']['connectivity_score']:.2%}")
        print(f"  Issues found: {results['diagnosis']['issues_count']}")

if __name__ == "__main__":
    test_network_expansion()
```

**è¿è¡Œç»“æœç¤ºä¾‹**ï¼š

```text
INFO:__main__:Current network has 3 nodes
INFO:__main__:Adding new node 000D6F0000ABCDEF (type: Router)...
INFO:__main__:Node 000D6F0000ABCDEF joined successfully
INFO:__main__:Adding new node 000D6F0000FEDCBA (type: EndDevice)...
INFO:__main__:Node 000D6F0000FEDCBA joined successfully
INFO:__main__:Updating routing tables...
INFO:__main__:Updated routing tables for 5/5 nodes
INFO:__main__:Optimizing routing tables...
INFO:__main__:Running network diagnosis...
INFO:__main__:Network expansion completed: 2 nodes added

Network Expansion Results:
  Successful joins: 2
  Failed joins: 0
  Initial nodes: 3
  Final nodes: 5
  Added nodes: 2
  Connectivity score: 100.00%
  Issues found: 0
```

---

## 9. æ¡ˆä¾‹8ï¼šThreadç½‘ç»œæ•…éšœæ¢å¤

### 9.1 åœºæ™¯æè¿°

**ä¸šåŠ¡èƒŒæ™¯**ï¼š
Threadç½‘ç»œä¸­çš„æŸäº›èŠ‚ç‚¹å¯èƒ½å‡ºç°æ•…éšœï¼ˆå¦‚æ–­ç”µã€ä¿¡å·ä¸¢å¤±ã€ç¡¬ä»¶æ•…éšœï¼‰ï¼Œ
ç³»ç»Ÿéœ€è¦è‡ªåŠ¨æ£€æµ‹æ•…éšœï¼Œæ‰§è¡Œæ•…éšœæ¢å¤æµç¨‹ï¼ŒåŒ…æ‹¬èŠ‚ç‚¹é‡æ–°åŠ å…¥ã€è·¯ç”±é‡å»ºã€
ç½‘ç»œåˆ†åŒºåˆå¹¶ç­‰æ“ä½œã€‚

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š

- éœ€è¦å®æ—¶æ£€æµ‹èŠ‚ç‚¹æ•…éšœ
- éœ€è¦åŒºåˆ†ä¸´æ—¶æ•…éšœå’Œæ°¸ä¹…æ•…éšœ
- éœ€è¦è‡ªåŠ¨æ‰§è¡Œæ¢å¤æµç¨‹
- éœ€è¦å¤„ç†ç½‘ç»œåˆ†åŒºæƒ…å†µ
- éœ€è¦æ¢å¤è·¯ç”±è¡¨å®Œæ•´æ€§

**è§£å†³æ–¹æ¡ˆ**ï¼š
ä½¿ç”¨ç½‘ç»œè¯Šæ–­åŠŸèƒ½æ£€æµ‹æ•…éšœï¼Œç»“åˆåˆ†åŒºç®¡ç†å’Œè·¯ç”±é‡å»ºåŠŸèƒ½ï¼Œ
å®ç°è‡ªåŠ¨åŒ–çš„æ•…éšœæ£€æµ‹å’Œæ¢å¤æµç¨‹ã€‚

### 9.2 Schemaå®šä¹‰

**æ•…éšœæ¢å¤Schema**ï¼š

```json
{
  "network_name": "SmartHomeNet",
  "fault_detection": {
    "check_interval_seconds": 30,
    "fault_threshold": {
      "no_response_count": 3,
      "low_link_quality": 1,
      "low_rssi": -90
    }
  },
  "recovery_strategy": {
    "auto_rejoin": true,
    "rebuild_routes": true,
    "merge_partitions": true,
    "notify_administrator": true
  },
  "fault_types": [
    "node_unreachable",
    "low_link_quality",
    "routing_failure",
    "partition_detected"
  ]
}
```

### 9.3 å®ç°ä»£ç 

**å®Œæ•´çš„æ•…éšœæ¢å¤å®ç°**ï¼š

```python
import logging
from datetime import datetime, timedelta
from thread_network_manager import ThreadNetworkManager
from thread_routing_manager import ThreadRoutingManager
from thread_storage import ThreadStorage
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–ç»„ä»¶
storage = ThreadStorage("postgresql://user:pass@localhost/thread")
network_manager = ThreadNetworkManager()
routing_manager = ThreadRoutingManager(network_manager)

class ThreadFaultRecovery:
    """Threadç½‘ç»œæ•…éšœæ¢å¤ç®¡ç†å™¨"""

    def __init__(self, network_name: str, check_interval: int = 30):
        self.network_name = network_name
        self.check_interval = check_interval
        self.fault_history = {}
        self.recovery_actions = []

    def detect_faults(self) -> List[Dict]:
        """æ£€æµ‹ç½‘ç»œæ•…éšœ"""
        faults = []

        try:
            # æ‰§è¡Œç½‘ç»œè¯Šæ–­
            diagnosis = network_manager.diagnose_network(self.network_name)

            # 1. æ£€æµ‹æ–­å¼€è¿æ¥çš„èŠ‚ç‚¹
            disconnected_nodes = diagnosis["connectivity"].get("disconnected_nodes", [])
            for node_id in disconnected_nodes:
                fault = {
                    "node_id": node_id,
                    "fault_type": "node_unreachable",
                    "severity": "high",
                    "detected_at": datetime.now().isoformat(),
                    "details": "Node is not responding"
                }
                faults.append(fault)

            # 2. æ£€æµ‹ä¸å¥åº·èŠ‚ç‚¹
            unhealthy_nodes = diagnosis["node_health"].get("unhealthy_nodes", [])
            for node_id in unhealthy_nodes:
                health_details = diagnosis["node_health"]["health_details"].get(node_id, {})
                issues = health_details.get("issues", [])

                fault = {
                    "node_id": node_id,
                    "fault_type": "node_unhealthy",
                    "severity": "medium",
                    "detected_at": datetime.now().isoformat(),
                    "details": "; ".join(issues)
                }
                faults.append(fault)

            # 3. æ£€æµ‹è·¯ç”±è¡¨ä¸å®Œæ•´
            incomplete_tables = diagnosis["routing"].get("incomplete_tables", [])
            for node_id in incomplete_tables:
                fault = {
                    "node_id": node_id,
                    "fault_type": "routing_failure",
                    "severity": "medium",
                    "detected_at": datetime.now().isoformat(),
                    "details": "Routing table is incomplete"
                }
                faults.append(fault)

            # 4. æ£€æµ‹ç½‘ç»œåˆ†åŒº
            network = network_manager.networks.get(self.network_name)
            if network and "partitions" in network:
                partitions = network["partitions"]
                if len(partitions) > 1:
                    fault = {
                        "node_id": None,
                        "fault_type": "partition_detected",
                        "severity": "high",
                        "detected_at": datetime.now().isoformat(),
                        "details": f"Network partitioned into {len(partitions)} partitions",
                        "partition_count": len(partitions)
                    }
                    faults.append(fault)

            logger.info(f"Detected {len(faults)} faults in network {self.network_name}")
            return faults

        except Exception as e:
            logger.error(f"Fault detection failed: {e}")
            return []

    def recover_from_fault(self, fault: Dict) -> bool:
        """ä»æ•…éšœä¸­æ¢å¤"""
        fault_type = fault["fault_type"]
        node_id = fault.get("node_id")

        logger.info(f"Recovering from fault: {fault_type} (node: {node_id})")

        try:
            if fault_type == "node_unreachable":
                return self._recover_unreachable_node(node_id)
            elif fault_type == "node_unhealthy":
                return self._recover_unhealthy_node(node_id)
            elif fault_type == "routing_failure":
                return self._recover_routing_failure(node_id)
            elif fault_type == "partition_detected":
                return self._recover_partition()
            else:
                logger.warning(f"Unknown fault type: {fault_type}")
                return False
        except Exception as e:
            logger.error(f"Recovery failed for fault {fault_type}: {e}")
            return False

    def _recover_unreachable_node(self, node_id: str) -> bool:
        """æ¢å¤ä¸å¯è¾¾èŠ‚ç‚¹"""
        try:
            # å°è¯•é‡æ–°åŠ å…¥ç½‘ç»œ
            network = network_manager.networks.get(self.network_name)
            if not network:
                return False

            logger.info(f"Attempting to rejoin node {node_id}...")
            success = network_manager._rejoin_network(node_id, self.network_name)

            if success:
                # æ›´æ–°èŠ‚ç‚¹ä¿¡æ¯
                node_info = network_manager.get_node_info(node_id)
                if node_info:
                    storage.store_node(node_info)

                    # è®°å½•æ¢å¤äº‹ä»¶
                    storage.store_event(
                        self.network_name,
                        "node_recovered",
                        {
                            "node_id": node_id,
                            "recovery_type": "rejoin",
                            "mesh_local_address": node_info.get("mesh_local_address")
                        },
                        node_id
                    )

                    logger.info(f"Node {node_id} recovered successfully")
                    return True

            return False
        except Exception as e:
            logger.error(f"Failed to recover unreachable node {node_id}: {e}")
            return False

    def _recover_unhealthy_node(self, node_id: str) -> bool:
        """æ¢å¤ä¸å¥åº·èŠ‚ç‚¹"""
        try:
            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            node_info = network_manager.get_node_info(node_id)
            if not node_info:
                return False

            # å¦‚æœèŠ‚ç‚¹æœ‰çˆ¶èŠ‚ç‚¹ï¼Œå°è¯•é‡æ–°é€‰æ‹©çˆ¶èŠ‚ç‚¹
            if node_info.get("node_type") == "EndDevice":
                # è®©èŠ‚ç‚¹é‡æ–°åŠ å…¥ä»¥é€‰æ‹©æ›´å¥½çš„çˆ¶èŠ‚ç‚¹
                return self._recover_unreachable_node(node_id)

            # å¯¹äºRouterèŠ‚ç‚¹ï¼Œæ›´æ–°è·¯ç”±è¡¨
            routing_manager.update_routing_table(node_id)
            routing_manager.optimize_routing_table(node_id)

            # è®°å½•æ¢å¤äº‹ä»¶
            storage.store_event(
                self.network_name,
                "node_health_improved",
                {"node_id": node_id},
                node_id
            )

            return True
        except Exception as e:
            logger.error(f"Failed to recover unhealthy node {node_id}: {e}")
            return False

    def _recover_routing_failure(self, node_id: str) -> bool:
        """æ¢å¤è·¯ç”±æ•…éšœ"""
        try:
            # æ›´æ–°è·¯ç”±è¡¨
            routing_manager.update_routing_table(node_id)

            # ä¼˜åŒ–è·¯ç”±è¡¨
            routing_manager.optimize_routing_table(node_id)

            # éªŒè¯è·¯ç”±è¡¨
            routes = routing_manager.routing_tables.get(node_id, [])
            if len(routes) > 0:
                # å­˜å‚¨è·¯ç”±è¡¨
                storage.store_routing_table(node_id, routes)

                # è®°å½•æ¢å¤äº‹ä»¶
                storage.store_event(
                    self.network_name,
                    "routing_recovered",
                    {
                        "node_id": node_id,
                        "route_count": len(routes)
                    },
                    node_id
                )

                logger.info(f"Routing recovered for node {node_id}: {len(routes)} routes")
                return True

            return False
        except Exception as e:
            logger.error(f"Failed to recover routing for node {node_id}: {e}")
            return False

    def _recover_partition(self) -> bool:
        """æ¢å¤ç½‘ç»œåˆ†åŒº"""
        try:
            logger.info("Attempting to merge network partitions...")

            # æ£€æµ‹åˆ†åŒº
            network_manager.manage_partition(self.network_name, "detect")

            # åˆå¹¶åˆ†åŒº
            success = network_manager.manage_partition(self.network_name, "merge")

            if success:
                # æ›´æ–°æ‰€æœ‰è·¯ç”±è¡¨
                routing_manager.update_all_routing_tables(self.network_name)

                # è®°å½•æ¢å¤äº‹ä»¶
                storage.store_event(
                    self.network_name,
                    "partition_merged",
                    {"recovery_type": "automatic"}
                )

                logger.info("Network partitions merged successfully")
                return True

            return False
        except Exception as e:
            logger.error(f"Failed to recover partition: {e}")
            return False

    def run_continuous_monitoring(self):
        """æŒç»­ç›‘æ§å’Œæ¢å¤"""
        logger.info(f"Starting continuous fault monitoring for {self.network_name}")

        while True:
            try:
                # æ£€æµ‹æ•…éšœ
                faults = self.detect_faults()

                # å¤„ç†æ¯ä¸ªæ•…éšœ
                for fault in faults:
                    # æ£€æŸ¥æ•…éšœå†å²ï¼Œé¿å…é‡å¤å¤„ç†
                    fault_key = f"{fault['fault_type']}_{fault.get('node_id', 'network')}"
                    last_handled = self.fault_history.get(fault_key)

                    if last_handled:
                        # å¦‚æœæœ€è¿‘å¤„ç†è¿‡ï¼Œè·³è¿‡
                        time_since_handled = datetime.now() - datetime.fromisoformat(last_handled)
                        if time_since_handled.total_seconds() < 300:  # 5åˆ†é’Ÿå†…ä¸é‡å¤å¤„ç†
                            continue

                    # æ‰§è¡Œæ¢å¤
                    recovery_success = self.recover_from_fault(fault)

                    # è®°å½•æ¢å¤æ“ä½œ
                    self.recovery_actions.append({
                        "fault": fault,
                        "recovery_success": recovery_success,
                        "timestamp": datetime.now().isoformat()
                    })

                    # æ›´æ–°æ•…éšœå†å²
                    if recovery_success:
                        self.fault_history[fault_key] = datetime.now().isoformat()

                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                time.sleep(self.check_interval)

            except KeyboardInterrupt:
                logger.info("Stopping fault monitoring...")
                break
            except Exception as e:
                logger.error(f"Error in continuous monitoring: {e}")
                time.sleep(self.check_interval)

# æµ‹è¯•ç”¨ä¾‹
def test_fault_recovery():
    """æµ‹è¯•æ•…éšœæ¢å¤"""
    recovery_manager = ThreadFaultRecovery("SmartHomeNet", check_interval=30)

    # å•æ¬¡æ•…éšœæ£€æµ‹å’Œæ¢å¤
    faults = recovery_manager.detect_faults()
    print(f"\nDetected {len(faults)} faults:")

    for fault in faults:
        print(f"  - {fault['fault_type']}: {fault.get('node_id', 'N/A')} ({fault['severity']})")
        recovery_success = recovery_manager.recover_from_fault(fault)
        print(f"    Recovery: {'Success' if recovery_success else 'Failed'}")

if __name__ == "__main__":
    test_fault_recovery()
    # å–æ¶ˆæ³¨é‡Šä»¥è¿è¡ŒæŒç»­ç›‘æ§
    # recovery_manager = ThreadFaultRecovery("SmartHomeNet")
    # recovery_manager.run_continuous_monitoring()
```

**è¿è¡Œç»“æœç¤ºä¾‹**ï¼š

```text
INFO:__main__:Detected 2 faults in network SmartHomeNet
  - node_unreachable: 000D6F0000123456 (high)
    Recovery: Success
INFO:__main__:Attempting to rejoin node 000D6F0000123456...
INFO:__main__:Node 000D6F0000123456 recovered successfully
  - routing_failure: 000D6F0000654321 (medium)
    Recovery: Success
INFO:__main__:Routing recovered for node 000D6F0000654321: 5 routes
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `04_Transformation.md` - è½¬æ¢ä½“ç³»

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
