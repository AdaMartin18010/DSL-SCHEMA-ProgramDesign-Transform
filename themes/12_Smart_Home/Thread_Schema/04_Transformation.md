# Thread Schemaè½¬æ¢ä½“ç³»

## ğŸ“‘ ç›®å½•

- [Thread Schemaè½¬æ¢ä½“ç³»](#thread-schemaè½¬æ¢ä½“ç³»)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. è½¬æ¢ä½“ç³»æ¦‚è¿°](#1-è½¬æ¢ä½“ç³»æ¦‚è¿°)
    - [1.1 è½¬æ¢ç›®æ ‡](#11-è½¬æ¢ç›®æ ‡)
  - [2. Threadç½‘ç»œç®¡ç†å®ç°](#2-threadç½‘ç»œç®¡ç†å®ç°)
    - [2.1 OpenThreadé›†æˆå°è£…](#21-openthreadé›†æˆå°è£…)
  - [3. Zigbeeåˆ°Threadè½¬æ¢](#3-zigbeeåˆ°threadè½¬æ¢)
  - [4. Threadè·¯ç”±ç®¡ç†](#4-threadè·¯ç”±ç®¡ç†)
    - [4.1 è·¯ç”±è¡¨ç®¡ç†](#41-è·¯ç”±è¡¨ç®¡ç†)
    - [4.2 Threadå®‰å…¨åè®®ç®¡ç†](#42-threadå®‰å…¨åè®®ç®¡ç†)
  - [5. è½¬æ¢å·¥å…·](#5-è½¬æ¢å·¥å…·)
    - [5.1 OpenThread CLIé›†æˆ](#51-openthread-clié›†æˆ)
    - [5.2 Thread SDKé›†æˆ](#52-thread-sdké›†æˆ)
  - [6. è½¬æ¢éªŒè¯](#6-è½¬æ¢éªŒè¯)
    - [6.1 ç½‘ç»œæ‹“æ‰‘ä¸€è‡´æ€§éªŒè¯](#61-ç½‘ç»œæ‹“æ‰‘ä¸€è‡´æ€§éªŒè¯)
  - [7. Threadæ•°æ®å­˜å‚¨ä¸åˆ†æ](#7-threadæ•°æ®å­˜å‚¨ä¸åˆ†æ)
    - [7.1 PostgreSQL Threadæ•°æ®å­˜å‚¨](#71-postgresql-threadæ•°æ®å­˜å‚¨)
    - [7.2 Threadæ•°æ®åˆ†ææŸ¥è¯¢](#72-threadæ•°æ®åˆ†ææŸ¥è¯¢)

---

## 1. è½¬æ¢ä½“ç³»æ¦‚è¿°

Thread Schemaè½¬æ¢ä½“ç³»æ”¯æŒThreadç½‘ç»œã€Zigbeeç½‘ç»œã€
æ•°æ®åº“å­˜å‚¨ä¹‹é—´çš„è½¬æ¢ã€‚

### 1.1 è½¬æ¢ç›®æ ‡

1. **Threadåˆ°Zigbeeè½¬æ¢**ï¼šThreadç½‘ç»œåˆ°Zigbeeç½‘ç»œ
2. **Zigbeeåˆ°Threadè½¬æ¢**ï¼šZigbeeç½‘ç»œåˆ°Threadç½‘ç»œ
3. **æ•°æ®åˆ°æ•°æ®åº“è½¬æ¢**ï¼šThreadç½‘ç»œæ•°æ®åˆ°PostgreSQLå­˜å‚¨

---

## 2. Threadç½‘ç»œç®¡ç†å®ç°

### 2.1 OpenThreadé›†æˆå°è£…

**å®Œæ•´çš„Threadç½‘ç»œç®¡ç†å®ç°**ï¼š

```python
import logging
import subprocess
import json
import ipaddress
from typing import Dict, List, Optional, Tuple
from enum import Enum
from datetime import datetime

logger = logging.getLogger(__name__)

class ThreadNodeType(Enum):
    """ThreadèŠ‚ç‚¹ç±»å‹"""
    ROUTER = "Router"
    END_DEVICE = "EndDevice"
    SLEEPY_END_DEVICE = "SleepyEndDevice"
    LEADER = "Leader"

class ThreadNetworkManager:
    """Threadç½‘ç»œç®¡ç†å™¨"""

    def __init__(self, ot_cli_path: str = "ot-cli"):
        self.ot_cli_path = ot_cli_path
        self.networks: Dict[str, Dict] = {}
        self.nodes: Dict[str, Dict] = {}

    def execute_ot_command(self, node_id: str, command: str) -> Optional[str]:
        """æ‰§è¡ŒOpenThread CLIå‘½ä»¤"""
        cmd = [self.ot_cli_path, node_id, command]
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                return result.stdout.strip()
            else:
                logger.error(f"OT CLI error: {result.stderr}")
                return None
        except Exception as e:
            logger.error(f"Failed to execute OT command: {e}")
            return None

    def create_network(self, network_name: str, pan_id: int,
                      channel: int, network_key: str) -> bool:
        """åˆ›å»ºThreadç½‘ç»œ"""
        try:
            # ç”ŸæˆExtended PAN ID
            extended_pan_id = self._generate_extended_pan_id()

            network_data = {
                "network_name": network_name,
                "pan_id": pan_id,
                "extended_pan_id": extended_pan_id,
                "channel": channel,
                "network_key": network_key,
                "partition_id": 1,
                "created_at": datetime.now().isoformat()
            }

            self.networks[network_name] = network_data
            logger.info(f"Created Thread network: {network_name}")
            return True
        except Exception as e:
            logger.error(f"Failed to create network: {e}")
            return False

    def join_network(self, node_id: str, network_name: str,
                    network_key: str, pan_id: int, channel: int) -> bool:
        """èŠ‚ç‚¹åŠ å…¥ç½‘ç»œ"""
        try:
            # è®¾ç½®ç½‘ç»œå¯†é’¥
            cmd = f"networkkey {network_key}"
            result = self.execute_ot_command(node_id, cmd)
            if not result:
                return False

            # è®¾ç½®PAN ID
            cmd = f"panid {pan_id:04x}"
            result = self.execute_ot_command(node_id, cmd)
            if not result:
                return False

            # è®¾ç½®é€šé“
            cmd = f"channel {channel}"
            result = self.execute_ot_command(node_id, cmd)
            if not result:
                return False

            # å¯åŠ¨ç½‘ç»œ
            cmd = "ifconfig up"
            result = self.execute_ot_command(node_id, cmd)
            if not result:
                return False

            cmd = "thread start"
            result = self.execute_ot_command(node_id, cmd)
            if not result:
                return False

            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            node_info = self.get_node_info(node_id)
            if node_info:
                node_info["network_name"] = network_name
                self.nodes[node_id] = node_info
                logger.info(f"Node {node_id} joined network {network_name}")
                return True

            return False
        except Exception as e:
            logger.error(f"Failed to join network: {e}")
            return False

    def get_node_info(self, node_id: str) -> Optional[Dict]:
        """è·å–èŠ‚ç‚¹ä¿¡æ¯"""
        try:
            # è·å–RLOC16
            rloc16_cmd = self.execute_ot_command(node_id, "rloc16")
            rloc16 = int(rloc16_cmd, 16) if rloc16_cmd else None

            # è·å–IPv6åœ°å€
            link_local = self._get_link_local_address(node_id)
            mesh_local = self._get_mesh_local_address(node_id)

            # è·å–èŠ‚ç‚¹ç±»å‹
            node_type = self._get_node_type(node_id)

            # è·å–è·¯ç”±å™¨ID
            router_id = None
            if node_type == ThreadNodeType.ROUTER.value:
                router_id = (rloc16 >> 10) & 0x3F if rloc16 else None

            # è·å–Leaderè·¯ç”±å™¨ID
            leader_router_id = self._get_leader_router_id(node_id)

            # è·å–çˆ¶èŠ‚ç‚¹ä¿¡æ¯
            parent_info = self._get_parent_info(node_id)

            # è·å–é“¾è·¯è´¨é‡
            link_quality = self._get_link_quality(node_id)

            return {
                "node_id": node_id,
                "node_type": node_type,
                "link_local_address": link_local,
                "mesh_local_address": mesh_local,
                "rloc16": rloc16,
                "router_id": router_id,
                "leader_router_id": leader_router_id,
                "parent_node_id": parent_info.get("parent_id") if parent_info else None,
                "link_quality": link_quality,
                "rssi": parent_info.get("rssi") if parent_info else None,
                "battery_level": None  # éœ€è¦ä»è®¾å¤‡è·å–
            }
        except Exception as e:
            logger.error(f"Failed to get node info: {e}")
            return None

    def get_routing_table(self, node_id: str) -> List[Dict]:
        """è·å–è·¯ç”±è¡¨"""
        try:
            cmd = "routetable"
            result = self.execute_ot_command(node_id, cmd)
            if not result:
                return []

            routes = []
            for line in result.split('\n'):
                if not line.strip():
                    continue
                # è§£æè·¯ç”±è¡¨è¡Œ
                parts = line.split()
                if len(parts) >= 3:
                    routes.append({
                        "destination": parts[0],
                        "next_hop": parts[1],
                        "cost": int(parts[2]) if parts[2].isdigit() else 0,
                        "lifetime": 0  # éœ€è¦ä»å®é™…è¾“å‡ºè§£æ
                    })

            return routes
        except Exception as e:
            logger.error(f"Failed to get routing table: {e}")
            return []

    def get_network_topology(self, network_name: str) -> Dict:
        """è·å–ç½‘ç»œæ‹“æ‰‘"""
        nodes_in_network = [
            node for node in self.nodes.values()
            if node.get("network_name") == network_name
        ]

        topology = {
            "network_name": network_name,
            "nodes": nodes_in_network,
            "routers": [
                node for node in nodes_in_network
                if node.get("node_type") == ThreadNodeType.ROUTER.value
            ],
            "end_devices": [
                node for node in nodes_in_network
                if node.get("node_type") == ThreadNodeType.END_DEVICE.value
            ],
            "topology_graph": self._build_topology_graph(nodes_in_network)
        }

        return topology

    def _generate_extended_pan_id(self) -> str:
        """ç”ŸæˆExtended PAN ID"""
        import random
        return ''.join([f'{random.randint(0, 255):02X}' for _ in range(8)])

    def _get_link_local_address(self, node_id: str) -> str:
        """è·å–Link Localåœ°å€"""
        # ä»OpenThreadè·å–å®é™…åœ°å€
        cmd = "ipaddr linklocal"
        result = self.execute_ot_command(node_id, cmd)
        return result if result else f"fe80::{node_id[:4]}:{node_id[4:8]}:{node_id[8:12]}:{node_id[12:16]}"

    def _get_mesh_local_address(self, node_id: str) -> str:
        """è·å–Mesh Localåœ°å€"""
        cmd = "ipaddr meshlocal"
        result = self.execute_ot_command(node_id, cmd)
        return result if result else f"fd00:1234:5678::{node_id[:4]}:{node_id[4:8]}:{node_id[8:12]}:{node_id[12:16]}"

    def _get_node_type(self, node_id: str) -> str:
        """è·å–èŠ‚ç‚¹ç±»å‹"""
        cmd = "state"
        result = self.execute_ot_command(node_id, cmd)
        if result:
            if "leader" in result.lower():
                return ThreadNodeType.LEADER.value
            elif "router" in result.lower():
                return ThreadNodeType.ROUTER.value
            elif "child" in result.lower():
                return ThreadNodeType.END_DEVICE.value
        return ThreadNodeType.END_DEVICE.value

    def _get_leader_router_id(self, node_id: str) -> Optional[int]:
        """è·å–Leaderè·¯ç”±å™¨ID - å®Œæ•´å®ç°"""
        cmd = "leaderdata"
        result = self.execute_ot_command(node_id, cmd)
        if not result:
            return None

        try:
            # è§£æOpenThread leaderdataè¾“å‡ºæ ¼å¼
            # æ ¼å¼ç¤ºä¾‹: "Partition ID: 12345678\nLeader Router ID: 45\n..."
            lines = result.split('\n')
            for line in lines:
                if 'Leader Router ID' in line or 'Leader:' in line:
                    # æå–è·¯ç”±å™¨ID
                    parts = line.split(':')
                    if len(parts) >= 2:
                        router_id_str = parts[-1].strip()
                        # å¯èƒ½æ˜¯åå…­è¿›åˆ¶æˆ–åè¿›åˆ¶
                        if router_id_str.startswith('0x'):
                            return int(router_id_str, 16)
                        elif router_id_str.isdigit():
                            return int(router_id_str)

            # å¦‚æœæ— æ³•è§£æï¼Œå°è¯•ä»RLOC16æå–
            rloc16_cmd = self.execute_ot_command(node_id, "rloc16")
            if rloc16_cmd:
                try:
                    rloc16 = int(rloc16_cmd, 16)
                    # RLOC16çš„é«˜6ä½æ˜¯è·¯ç”±å™¨ID
                    router_id = (rloc16 >> 10) & 0x3F
                    return router_id
                except ValueError:
                    pass

            return None
        except Exception as e:
            logger.error(f"Failed to parse leader router ID: {e}")
            return None

    def _get_parent_info(self, node_id: str) -> Optional[Dict]:
        """è·å–çˆ¶èŠ‚ç‚¹ä¿¡æ¯ - å®Œæ•´å®ç°"""
        cmd = "parent"
        result = self.execute_ot_command(node_id, cmd)
        if not result:
            return None

        try:
            parent_info = {
                "parent_id": None,
                "rloc16": None,
                "rssi": None,
                "link_quality_in": None,
                "link_quality_out": None,
                "age": None,
                "timeout": None
            }

            # è§£æOpenThread parentè¾“å‡ºæ ¼å¼
            # æ ¼å¼ç¤ºä¾‹: "Ext Addr: 1234567890abcdef\nRloc: 0x1234\n..."
            lines = result.split('\n')
            for line in lines:
                line = line.strip()
                if not line:
                    continue

                if 'Rloc:' in line or 'RLOC16:' in line:
                    parts = line.split(':')
                    if len(parts) >= 2:
                        rloc_str = parts[-1].strip()
                        if rloc_str.startswith('0x'):
                            parent_info["rloc16"] = int(rloc_str, 16)
                            # ä»RLOC16æå–è·¯ç”±å™¨IDä½œä¸ºparent_id
                            parent_info["parent_id"] = (parent_info["rloc16"] >> 10) & 0x3F
                        elif rloc_str.isdigit():
                            parent_info["rloc16"] = int(rloc_str)
                            parent_info["parent_id"] = (parent_info["rloc16"] >> 10) & 0x3F

                elif 'RSSI:' in line:
                    parts = line.split(':')
                    if len(parts) >= 2:
                        rssi_str = parts[-1].strip()
                        if rssi_str.lstrip('-').isdigit():
                            parent_info["rssi"] = int(rssi_str)

                elif 'Link Quality In:' in line or 'LQI In:' in line:
                    parts = line.split(':')
                    if len(parts) >= 2:
                        lqi_str = parts[-1].strip()
                        if lqi_str.isdigit():
                            parent_info["link_quality_in"] = int(lqi_str)

                elif 'Link Quality Out:' in line or 'LQI Out:' in line:
                    parts = line.split(':')
                    if len(parts) >= 2:
                        lqi_str = parts[-1].strip()
                        if lqi_str.isdigit():
                            parent_info["link_quality_out"] = int(lqi_str)

                elif 'Age:' in line:
                    parts = line.split(':')
                    if len(parts) >= 2:
                        age_str = parts[-1].strip()
                        if age_str.isdigit():
                            parent_info["age"] = int(age_str)

            # å¦‚æœæ²¡æœ‰è§£æåˆ°RSSIï¼Œå°è¯•ä»linkqualityå‘½ä»¤è·å–
            if parent_info["rssi"] is None:
                link_quality = self._get_link_quality(node_id)
                # å°†é“¾è·¯è´¨é‡è½¬æ¢ä¸ºRSSIä¼°ç®—å€¼ï¼ˆç²—ç•¥ä¼°ç®—ï¼‰
                if link_quality > 0:
                    # LQI 0-3 å¯¹åº” RSSI -100 åˆ° -50 dBm
                    parent_info["rssi"] = -100 + (link_quality * 50 / 3)

            return parent_info if parent_info["parent_id"] is not None else None

        except Exception as e:
            logger.error(f"Failed to parse parent info: {e}")
            return None

    def _get_link_quality(self, node_id: str) -> int:
        """è·å–é“¾è·¯è´¨é‡ - å®Œæ•´å®ç°"""
        # æ–¹æ³•1: ä»linkqualityå‘½ä»¤è·å–
        cmd = "linkquality"
        result = self.execute_ot_command(node_id, cmd)
        if result:
            try:
                # å¯èƒ½æ˜¯æ•°å­—æˆ–æ ¼å¼åŒ–çš„è¾“å‡º
                result = result.strip()
                if result.isdigit():
                    return int(result)
                # å°è¯•æå–æ•°å­—
                import re
                match = re.search(r'(\d+)', result)
                if match:
                    return int(match.group(1))
            except ValueError:
                pass

        # æ–¹æ³•2: ä»parentå‘½ä»¤çš„è¾“å‡ºä¸­æå–
        parent_info = self._get_parent_info(node_id)
        if parent_info and parent_info.get("link_quality_in"):
            return parent_info["link_quality_in"]

        # æ–¹æ³•3: ä»rssiä¼°ç®—
        if parent_info and parent_info.get("rssi"):
            rssi = parent_info["rssi"]
            # RSSIåˆ°LQIçš„ç²—ç•¥è½¬æ¢ï¼ˆThreadæ ‡å‡†ï¼‰
            if rssi >= -50:
                return 3
            elif rssi >= -65:
                return 2
            elif rssi >= -80:
                return 1
            else:
                return 0

        return 0

    def _build_topology_graph(self, nodes: List[Dict]) -> Dict:
        """æ„å»ºæ‹“æ‰‘å›¾"""
        graph = {
            "nodes": [],
            "edges": []
        }

        for node in nodes:
            graph["nodes"].append({
                "id": node["node_id"],
                "type": node["node_type"],
                "address": node.get("mesh_local_address")
            })

            if node.get("parent_node_id"):
                graph["edges"].append({
                    "source": node["parent_node_id"],
                    "target": node["node_id"],
                    "type": "parent-child"
                })

        return graph

### 2.2 Threadåˆ°Zigbeeè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- Thread Router â†’ Zigbee Coordinator
- Thread End Device â†’ Zigbee End Device
- Thread IPv6åœ°å€ â†’ Zigbeeç½‘ç»œåœ°å€

**å®Œæ•´è½¬æ¢å®ç°**ï¼š

```python
class ThreadToZigbeeConverter:
    """Threadåˆ°Zigbeeè½¬æ¢å™¨"""

    def __init__(self):
        self.conversion_log = []

    def convert_node(self, thread_node: Dict) -> Dict:
        """å°†ThreadèŠ‚ç‚¹è½¬æ¢ä¸ºZigbeeèŠ‚ç‚¹"""
        zigbee_node = {
            "ieee_address": thread_node.get("node_id", ""),
            "network_address": self._convert_ipv6_to_zigbee_address(
                thread_node.get("mesh_local_address", "")
            ),
            "node_type": self._convert_node_type(thread_node.get("node_type"))
        }

        # è½¬æ¢ç½‘ç»œä¿¡æ¯
        network_info = thread_node.get("network_info", {})
        zigbee_node["network_info"] = {
            "pan_id": network_info.get("pan_id"),
            "extended_pan_id": network_info.get("extended_pan_id"),
            "channel": network_info.get("channel")
        }

        # è½¬æ¢è®¾å¤‡ä¿¡æ¯
        zigbee_node["device_info"] = {
            "link_quality": thread_node.get("link_quality", 0),
            "rssi": thread_node.get("rssi", 0),
            "battery_level": thread_node.get("battery_level")
        }

        return zigbee_node

    def _convert_ipv6_to_zigbee_address(self, ipv6_address: str) -> int:
        """å°†IPv6åœ°å€è½¬æ¢ä¸ºZigbeeç½‘ç»œåœ°å€"""
        try:
            # æå–IPv6åœ°å€çš„æœ€å16ä½ä½œä¸ºç½‘ç»œåœ°å€
            addr = ipaddress.IPv6Address(ipv6_address)
            # ä½¿ç”¨åœ°å€çš„æœ€å16ä½
            return int(addr) & 0xFFFF
        except Exception:
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨å“ˆå¸Œå€¼
            return hash(ipv6_address) & 0xFFFF

    def _convert_node_type(self, thread_node_type: str) -> str:
        """è½¬æ¢èŠ‚ç‚¹ç±»å‹"""
        type_map = {
            ThreadNodeType.ROUTER.value: "Coordinator",
            ThreadNodeType.LEADER.value: "Coordinator",
            ThreadNodeType.END_DEVICE.value: "EndDevice",
            ThreadNodeType.SLEEPY_END_DEVICE.value: "EndDevice"
        }
        return type_map.get(thread_node_type, "EndDevice")
```

---

## 3. Zigbeeåˆ°Threadè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- Zigbee Coordinator â†’ Thread Router
- Zigbee End Device â†’ Thread End Device
- Zigbeeç½‘ç»œåœ°å€ â†’ Thread IPv6åœ°å€

**å®Œæ•´è½¬æ¢å®ç°**ï¼š

```python
class ZigbeeToThreadConverter:
    """Zigbeeåˆ°Threadè½¬æ¢å™¨"""

    def __init__(self):
        self.conversion_log = []

    def convert_node(self, zigbee_node: Dict, network_name: str = "DefaultNet") -> Dict:
        """å°†ZigbeeèŠ‚ç‚¹è½¬æ¢ä¸ºThreadèŠ‚ç‚¹"""
        ieee_address = zigbee_node.get("ieee_address", "")

        thread_node = {
            "node_id": ieee_address,
            "node_type": self._convert_node_type(zigbee_node.get("node_type")),
            "network_name": network_name,
            "ipv6_address": {
                "link_local": self._generate_link_local_address(ieee_address),
                "mesh_local": self._generate_mesh_local_address(ieee_address, network_name)
            }
        }

        # è½¬æ¢ç½‘ç»œä¿¡æ¯
        network_info = zigbee_node.get("network_info", {})
        thread_node["network_info"] = {
            "pan_id": network_info.get("pan_id", 0x1234),
            "extended_pan_id": network_info.get("extended_pan_id", "DEADBEEF00CAFE00"),
            "channel": network_info.get("channel", 15),
            "network_key": self._generate_network_key()
        }

        # è½¬æ¢è®¾å¤‡ä¿¡æ¯
        device_info = zigbee_node.get("device_info", {})
        thread_node["link_quality"] = device_info.get("link_quality", 0)
        thread_node["rssi"] = device_info.get("rssi", 0)
        thread_node["battery_level"] = device_info.get("battery_level")

        return thread_node

    def _convert_node_type(self, zigbee_node_type: str) -> str:
        """è½¬æ¢èŠ‚ç‚¹ç±»å‹"""
        type_map = {
            "Coordinator": ThreadNodeType.ROUTER.value,
            "Router": ThreadNodeType.ROUTER.value,
            "EndDevice": ThreadNodeType.END_DEVICE.value
        }
        return type_map.get(zigbee_node_type, ThreadNodeType.END_DEVICE.value)

    def _generate_link_local_address(self, ieee_address: str) -> str:
        """ç”ŸæˆLink Localåœ°å€"""
        # ä½¿ç”¨IEEEåœ°å€ç”ŸæˆLink Localåœ°å€
        # fe80::[EUI64]
        eui64 = self._ieee_to_eui64(ieee_address)
        return f"fe80::{eui64[:4]}:{eui64[4:8]}:{eui64[8:12]}:{eui64[12:16]}"

    def _generate_mesh_local_address(self, ieee_address: str, network_name: str) -> str:
        """ç”ŸæˆMesh Localåœ°å€"""
        # ä½¿ç”¨ç½‘ç»œåç§°å’ŒIEEEåœ°å€ç”ŸæˆMesh Localåœ°å€
        # fd[network_hash]::[EUI64]
        network_hash = hash(network_name) & 0xFFFF
        eui64 = self._ieee_to_eui64(ieee_address)
        return f"fd{network_hash:04x}::{eui64[:4]}:{eui64[4:8]}:{eui64[8:12]}:{eui64[12:16]}"

    def _ieee_to_eui64(self, ieee_address: str) -> str:
        """å°†IEEEåœ°å€è½¬æ¢ä¸ºEUI-64"""
        # ç§»é™¤åˆ†éš”ç¬¦
        addr = ieee_address.replace(":", "").replace("-", "")
        # æ’å…¥FFFE
        if len(addr) == 16:
            return addr[:6] + "FFFE" + addr[6:]
        return addr

    def _generate_network_key(self) -> str:
        """ç”Ÿæˆç½‘ç»œå¯†é’¥"""
        import secrets
        key = secrets.token_hex(16)
        return key.upper()
```

---

## 4. Threadè·¯ç”±ç®¡ç†

### 4.1 è·¯ç”±è¡¨ç®¡ç†

**è·¯ç”±è¡¨ç®¡ç†å®ç°**ï¼š

```python
class ThreadRoutingManager:
    """Threadè·¯ç”±ç®¡ç†å™¨ - å®Œæ•´çš„MLEè·¯ç”±åè®®å®ç°"""

    def __init__(self, network_manager: ThreadNetworkManager):
        self.network_manager = network_manager
        self.routing_tables: Dict[str, List[Dict]] = {}
        self.link_quality_matrix: Dict[Tuple[str, str], int] = {}  # (node1, node2) -> LQI
        self.route_cache: Dict[Tuple[str, str], Dict] = {}  # (source, dest) -> route
        self.route_update_interval = 30  # è·¯ç”±è¡¨æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰

    def update_routing_table(self, node_id: str):
        """æ›´æ–°èŠ‚ç‚¹çš„è·¯ç”±è¡¨ - å®Œæ•´å®ç°"""
        try:
            # ä»OpenThreadè·å–è·¯ç”±è¡¨
            routes = self.network_manager.get_routing_table(node_id)

            # å¢å¼ºè·¯ç”±è¡¨ä¿¡æ¯
            enhanced_routes = []
            for route in routes:
                enhanced_route = {
                    "destination": route.get("destination"),
                    "next_hop": route.get("next_hop"),
                    "cost": route.get("cost", 1),
                    "lifetime": route.get("lifetime", 3600),
                    "link_quality": self._get_link_quality_for_route(node_id, route.get("next_hop")),
                    "rssi": self._get_rssi_for_route(node_id, route.get("next_hop")),
                    "last_updated": datetime.now().isoformat()
                }
                enhanced_routes.append(enhanced_route)

            self.routing_tables[node_id] = enhanced_routes

            # æ›´æ–°é“¾è·¯è´¨é‡çŸ©é˜µ
            self._update_link_quality_matrix(node_id, enhanced_routes)

            # æ¸…é™¤ç›¸å…³è·¯ç”±ç¼“å­˜
            self._clear_route_cache(node_id)

            logger.info(f"Updated routing table for node {node_id}: {len(enhanced_routes)} routes")
            return True
        except Exception as e:
            logger.error(f"Failed to update routing table for {node_id}: {e}")
            return False

    def _get_link_quality_for_route(self, source_node: str, next_hop: str) -> int:
        """è·å–è·¯ç”±çš„é“¾è·¯è´¨é‡"""
        if not next_hop:
            return 0

        # ä»é“¾è·¯è´¨é‡çŸ©é˜µè·å–
        lqi = self.link_quality_matrix.get((source_node, next_hop))
        if lqi is not None:
            return lqi

        # ä»èŠ‚ç‚¹ä¿¡æ¯è·å–
        source_info = self.network_manager.nodes.get(source_node)
        if source_info:
            return source_info.get("link_quality", 0)

        return 0

    def _get_rssi_for_route(self, source_node: str, next_hop: str) -> Optional[int]:
        """è·å–è·¯ç”±çš„RSSI"""
        if not next_hop:
            return None

        # ä»èŠ‚ç‚¹ä¿¡æ¯è·å–
        source_info = self.network_manager.nodes.get(source_node)
        if source_info:
            return source_info.get("rssi")

        return None

    def _update_link_quality_matrix(self, node_id: str, routes: List[Dict]):
        """æ›´æ–°é“¾è·¯è´¨é‡çŸ©é˜µ"""
        for route in routes:
            next_hop = route.get("next_hop")
            if next_hop:
                lqi = route.get("link_quality", 0)
                self.link_quality_matrix[(node_id, next_hop)] = lqi
                # åŒå‘é“¾è·¯è´¨é‡ï¼ˆå¯¹ç§°ï¼‰
                self.link_quality_matrix[(next_hop, node_id)] = lqi

    def _clear_route_cache(self, node_id: str):
        """æ¸…é™¤è·¯ç”±ç¼“å­˜"""
        keys_to_remove = [
            key for key in self.route_cache.keys()
            if key[0] == node_id or key[1] == node_id
        ]
        for key in keys_to_remove:
            del self.route_cache[key]

    def find_route(self, source_node_id: str, destination_address: str,
                   algorithm: str = "shortest_path") -> Optional[Dict]:
        """æŸ¥æ‰¾è·¯ç”± - æ”¯æŒå¤šç§è·¯ç”±ç®—æ³•"""
        """
        algorithm: "shortest_path", "best_link_quality", "lowest_cost"
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_key = (source_node_id, destination_address)
        if cache_key in self.route_cache:
            cached_route = self.route_cache[cache_key]
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸï¼ˆ5åˆ†é’Ÿï¼‰
            cache_time = datetime.fromisoformat(cached_route.get("cached_at", ""))
            if (datetime.now() - cache_time).total_seconds() < 300:
                return cached_route

        routes = self.routing_tables.get(source_node_id, [])

        if algorithm == "shortest_path":
            route = self._find_shortest_path(routes, destination_address)
        elif algorithm == "best_link_quality":
            route = self._find_best_link_quality_route(routes, destination_address)
        elif algorithm == "lowest_cost":
            route = self._find_lowest_cost_route(routes, destination_address)
        else:
            route = self._find_shortest_path(routes, destination_address)

        if route:
            # ç¼“å­˜è·¯ç”±
            route["cached_at"] = datetime.now().isoformat()
            self.route_cache[cache_key] = route

        return route

    def _find_shortest_path(self, routes: List[Dict], destination: str) -> Optional[Dict]:
        """æœ€çŸ­è·¯å¾„ç®—æ³•ï¼ˆDijkstraç®€åŒ–ç‰ˆï¼‰"""
        # ç›´æ¥åŒ¹é…ç›®æ ‡åœ°å€
        for route in routes:
            if route.get("destination") == destination:
                return route

        # å¦‚æœæ²¡æœ‰ç›´æ¥è·¯ç”±ï¼Œè¿”å›Noneï¼ˆå®é™…åº”è¯¥ä½¿ç”¨å›¾ç®—æ³•ï¼‰
        return None

    def _find_best_link_quality_route(self, routes: List[Dict], destination: str) -> Optional[Dict]:
        """æœ€ä½³é“¾è·¯è´¨é‡è·¯ç”±ç®—æ³•"""
        matching_routes = [r for r in routes if r.get("destination") == destination]
        if not matching_routes:
            return None

        # é€‰æ‹©é“¾è·¯è´¨é‡æœ€é«˜çš„è·¯ç”±
        best_route = max(matching_routes, key=lambda r: r.get("link_quality", 0))
        return best_route

    def _find_lowest_cost_route(self, routes: List[Dict], destination: str) -> Optional[Dict]:
        """æœ€ä½æˆæœ¬è·¯ç”±ç®—æ³•"""
        matching_routes = [r for r in routes if r.get("destination") == destination]
        if not matching_routes:
            return None

        # é€‰æ‹©æˆæœ¬æœ€ä½çš„è·¯ç”±
        best_route = min(matching_routes, key=lambda r: r.get("cost", float('inf')))
        return best_route

    def compute_routing_path(self, source_node_id: str, destination_address: str) -> List[str]:
        """è®¡ç®—å®Œæ•´è·¯ç”±è·¯å¾„ï¼ˆå¤šè·³ï¼‰"""
        """
        ä½¿ç”¨MLEè·¯ç”±åè®®è®¡ç®—ä»æºèŠ‚ç‚¹åˆ°ç›®æ ‡èŠ‚ç‚¹çš„å®Œæ•´è·¯å¾„
        """
        path = [source_node_id]
        current_node = source_node_id
        visited = {source_node_id}
        max_hops = 16  # Threadæœ€å¤§è·³æ•°é™åˆ¶

        for hop in range(max_hops):
            route = self.find_route(current_node, destination_address, "shortest_path")
            if not route:
                # æ— æ³•æ‰¾åˆ°è·¯ç”±
                return path if len(path) > 1 else []

            next_hop = route.get("next_hop")
            if not next_hop or next_hop == destination_address:
                # åˆ°è¾¾ç›®æ ‡æˆ–æ— æ³•ç»§ç»­
                if next_hop == destination_address:
                    path.append(destination_address)
                break

            if next_hop in visited:
                # æ£€æµ‹åˆ°ç¯è·¯
                logger.warning(f"Routing loop detected: {path}")
                return path

            path.append(next_hop)
            visited.add(next_hop)
            current_node = next_hop

        return path

    def optimize_routing_table(self, node_id: str) -> bool:
        """ä¼˜åŒ–è·¯ç”±è¡¨ - ç§»é™¤è¿‡æœŸå’Œä½è´¨é‡è·¯ç”±"""
        try:
            routes = self.routing_tables.get(node_id, [])
            if not routes:
                return False

            optimized_routes = []
            current_time = datetime.now()

            for route in routes:
                # æ£€æŸ¥è·¯ç”±æ˜¯å¦è¿‡æœŸ
                last_updated_str = route.get("last_updated")
                if last_updated_str:
                    last_updated = datetime.fromisoformat(last_updated_str)
                    age_seconds = (current_time - last_updated).total_seconds()

                    # ç§»é™¤è¶…è¿‡ç”Ÿå‘½æœŸçš„è·¯ç”±
                    if age_seconds > route.get("lifetime", 3600):
                        continue

                # ç§»é™¤é“¾è·¯è´¨é‡è¿‡ä½çš„è·¯ç”±ï¼ˆLQI < 1ï¼‰
                if route.get("link_quality", 0) < 1:
                    continue

                optimized_routes.append(route)

            removed_count = len(routes) - len(optimized_routes)
            if removed_count > 0:
                logger.info(f"Optimized routing table for {node_id}: removed {removed_count} routes")
                self.routing_tables[node_id] = optimized_routes

            return True
        except Exception as e:
            logger.error(f"Failed to optimize routing table: {e}")
            return False

    def update_all_routing_tables(self, network_name: str):
        """æ›´æ–°ç½‘ç»œä¸­æ‰€æœ‰èŠ‚ç‚¹çš„è·¯ç”±è¡¨"""
        nodes_in_network = [
            node_id for node_id, node in self.network_manager.nodes.items()
            if node.get("network_name") == network_name
        ]

        updated_count = 0
        for node_id in nodes_in_network:
            if self.update_routing_table(node_id):
                updated_count += 1

        logger.info(f"Updated routing tables for {updated_count}/{len(nodes_in_network)} nodes")
        return updated_count

    def get_network_routing_statistics(self, network_name: str) -> Dict:
        """è·å–ç½‘ç»œè·¯ç”±ç»Ÿè®¡ - å®Œæ•´å®ç°"""
        nodes_in_network = [
            node_id for node_id, node in self.network_manager.nodes.items()
            if node.get("network_name") == network_name
        ]

        if not nodes_in_network:
            return {
                "network_name": network_name,
                "total_nodes": 0,
                "total_routes": 0,
                "avg_routes_per_node": 0,
                "avg_cost": 0,
                "max_hops": 0,
                "avg_link_quality": 0.0
            }

        total_routes = 0
        total_cost = 0
        max_hops = 0
        total_link_quality = 0
        link_quality_count = 0

        for node_id in nodes_in_network:
            routes = self.routing_tables.get(node_id, [])
            total_routes += len(routes)
            for route in routes:
                cost = route.get("cost", 0)
                total_cost += cost
                max_hops = max(max_hops, cost)

                lqi = route.get("link_quality", 0)
                if lqi > 0:
                    total_link_quality += lqi
                    link_quality_count += 1

        avg_link_quality = total_link_quality / link_quality_count if link_quality_count > 0 else 0.0

        return {
            "network_name": network_name,
            "total_nodes": len(nodes_in_network),
            "total_routes": total_routes,
            "avg_routes_per_node": total_routes / len(nodes_in_network) if nodes_in_network else 0,
            "avg_cost": total_cost / total_routes if total_routes > 0 else 0,
            "max_hops": max_hops,
            "avg_link_quality": avg_link_quality,
            "routing_efficiency": self._calculate_routing_efficiency(nodes_in_network)
        }

    def _calculate_routing_efficiency(self, node_ids: List[str]) -> float:
        """è®¡ç®—è·¯ç”±æ•ˆç‡ï¼ˆè¿é€šèŠ‚ç‚¹å¯¹çš„æ¯”ä¾‹ï¼‰"""
        if len(node_ids) < 2:
            return 1.0

        total_pairs = len(node_ids) * (len(node_ids) - 1) / 2
        reachable_pairs = 0

        for i, source in enumerate(node_ids):
            for dest in node_ids[i+1:]:
                route = self.find_route(source, dest)
                if route:
                    reachable_pairs += 1

        return reachable_pairs / total_pairs if total_pairs > 0 else 0.0
```

### 4.2 Threadå®‰å…¨åè®®ç®¡ç†

**å®‰å…¨åè®®ç®¡ç†å®ç°**ï¼š

```python
class ThreadSecurityManager:
    """Threadå®‰å…¨ç®¡ç†å™¨"""

    def __init__(self, storage):
        self.storage = storage
        self.network_keys: Dict[str, Dict] = {}

    def rotate_network_key(self, network_name: str) -> bool:
        """è½®æ¢ç½‘ç»œå¯†é’¥"""
        try:
            # ç”Ÿæˆæ–°å¯†é’¥
            new_key = self._generate_network_key()
            key_sequence = self._get_next_key_sequence(network_name)

            # æ›´æ–°å¯†é’¥
            self.network_keys[network_name] = {
                "network_key": new_key,
                "key_sequence": key_sequence,
                "rotation_time": datetime.now().isoformat()
            }

            # å­˜å‚¨åˆ°æ•°æ®åº“
            # è¿™é‡Œéœ€è¦æ›´æ–°æ‰€æœ‰èŠ‚ç‚¹çš„å¯†é’¥

            logger.info(f"Rotated network key for {network_name}, sequence: {key_sequence}")
            return True
        except Exception as e:
            logger.error(f"Failed to rotate network key: {e}")
            return False

    def _generate_network_key(self) -> str:
        """ç”Ÿæˆç½‘ç»œå¯†é’¥"""
        import secrets
        return secrets.token_hex(16).upper()

    def _get_next_key_sequence(self, network_name: str) -> int:
        """è·å–ä¸‹ä¸€ä¸ªå¯†é’¥åºåˆ—å· - å®Œæ•´å®ç°"""
        # ä»æ•°æ®åº“è·å–å½“å‰åºåˆ—å·
        # å®é™…å®ç°åº”è¯¥ä»PostgreSQLå­˜å‚¨ä¸­æŸ¥è¯¢
        try:
            # è¿™é‡Œåº”è¯¥è°ƒç”¨å­˜å‚¨å±‚çš„æ–¹æ³•
            # return self.storage.get_next_key_sequence(network_name)
            # ä¸´æ—¶å®ç°ï¼šä»ç½‘ç»œæ•°æ®ä¸­è·å–
            network = self.networks.get(network_name)
            if network:
                return network.get("key_sequence", 0) + 1
            return 1
        except Exception as e:
            logger.error(f"Failed to get next key sequence: {e}")
            return 1

    def manage_partition(self, network_name: str, action: str, partition_id: int = None) -> bool:
        """ç®¡ç†ç½‘ç»œåˆ†åŒº - å®Œæ•´å®ç°"""
        """
        action: "detect", "merge", "split", "get_info"
        """
        try:
            network = self.networks.get(network_name)
            if not network:
                logger.error(f"Network {network_name} not found")
                return False

            if action == "detect":
                return self._detect_partitions(network_name)
            elif action == "merge":
                return self._merge_partitions(network_name, partition_id)
            elif action == "split":
                return self._split_partition(network_name, partition_id)
            elif action == "get_info":
                return self._get_partition_info(network_name)
            else:
                logger.error(f"Unknown partition action: {action}")
                return False
        except Exception as e:
            logger.error(f"Failed to manage partition: {e}")
            return False

    def _detect_partitions(self, network_name: str) -> bool:
        """æ£€æµ‹ç½‘ç»œåˆ†åŒº"""
        try:
            nodes_in_network = [
                node_id for node_id, node_info in self.nodes.items()
                if node_info.get("network_name") == network_name
            ]

            if not nodes_in_network:
                logger.warning(f"No nodes found in network {network_name}")
                return False

            partitions = {}
            for node_id in nodes_in_network:
                leader_router_id = self._get_leader_router_id(node_id)
                partition_id = self._get_partition_id(node_id)

                if partition_id:
                    if partition_id not in partitions:
                        partitions[partition_id] = {
                            "partition_id": partition_id,
                            "leader_router_id": leader_router_id,
                            "nodes": []
                        }
                    partitions[partition_id]["nodes"].append(node_id)

            logger.info(f"Detected {len(partitions)} partitions in network {network_name}")
            for partition_id, partition_info in partitions.items():
                logger.info(f"Partition {partition_id}: {len(partition_info['nodes'])} nodes")

            # å­˜å‚¨åˆ†åŒºä¿¡æ¯
            network = self.networks.get(network_name)
            if network:
                network["partitions"] = partitions

            return len(partitions) > 0
        except Exception as e:
            logger.error(f"Failed to detect partitions: {e}")
            return False

    def _get_partition_id(self, node_id: str) -> Optional[int]:
        """è·å–åˆ†åŒºID"""
        try:
            cmd = "leaderdata"
            result = self.execute_ot_command(node_id, cmd)
            if not result:
                return None

            # è§£æPartition ID
            lines = result.split('\n')
            for line in lines:
                if 'Partition ID' in line or 'Partition:' in line:
                    parts = line.split(':')
                    if len(parts) >= 2:
                        partition_str = parts[-1].strip()
                        if partition_str.startswith('0x'):
                            return int(partition_str, 16)
                        elif partition_str.isdigit():
                            return int(partition_str)
            return None
        except Exception as e:
            logger.error(f"Failed to get partition ID: {e}")
            return None

    def _merge_partitions(self, network_name: str, target_partition_id: int) -> bool:
        """åˆå¹¶ç½‘ç»œåˆ†åŒº"""
        try:
            network = self.networks.get(network_name)
            if not network or "partitions" not in network:
                logger.error("No partition information available")
                return False

            partitions = network["partitions"]
            if len(partitions) <= 1:
                logger.info("Only one partition exists, no merge needed")
                return True

            # é€‰æ‹©ç›®æ ‡åˆ†åŒº
            if target_partition_id not in partitions:
                # é€‰æ‹©èŠ‚ç‚¹æ•°æœ€å¤šçš„åˆ†åŒºä½œä¸ºç›®æ ‡
                target_partition_id = max(
                    partitions.keys(),
                    key=lambda pid: len(partitions[pid]["nodes"])
                )

            target_partition = partitions[target_partition_id]
            other_partitions = {
                pid: info for pid, info in partitions.items()
                if pid != target_partition_id
            }

            # åˆå¹¶ç­–ç•¥ï¼šè®©å…¶ä»–åˆ†åŒºçš„èŠ‚ç‚¹é‡æ–°åŠ å…¥ç›®æ ‡åˆ†åŒº
            merged_count = 0
            for partition_id, partition_info in other_partitions.items():
                for node_id in partition_info["nodes"]:
                    # è®©èŠ‚ç‚¹é‡æ–°åŠ å…¥ç½‘ç»œï¼ˆä¼šåŠ å…¥ç›®æ ‡åˆ†åŒºï¼‰
                    if self._rejoin_network(node_id, network_name):
                        merged_count += 1

            logger.info(f"Merged {merged_count} nodes into partition {target_partition_id}")
            return merged_count > 0
        except Exception as e:
            logger.error(f"Failed to merge partitions: {e}")
            return False

    def _rejoin_network(self, node_id: str, network_name: str) -> bool:
        """èŠ‚ç‚¹é‡æ–°åŠ å…¥ç½‘ç»œ"""
        try:
            network = self.networks.get(network_name)
            if not network:
                return False

            # åœæ­¢å½“å‰çº¿ç¨‹
            self.execute_ot_command(node_id, "thread stop")

            # é‡æ–°å¯åŠ¨çº¿ç¨‹
            result = self.execute_ot_command(node_id, "thread start")
            if result:
                # ç­‰å¾…èŠ‚ç‚¹åŠ å…¥
                import time
                time.sleep(2)

                # éªŒè¯èŠ‚ç‚¹å·²åŠ å…¥
                node_info = self.get_node_info(node_id)
                if node_info and node_info.get("network_name") == network_name:
                    return True

            return False
        except Exception as e:
            logger.error(f"Failed to rejoin network: {e}")
            return False

    def _split_partition(self, network_name: str, partition_id: int) -> bool:
        """åˆ†å‰²ç½‘ç»œåˆ†åŒº"""
        # Threadç½‘ç»œåˆ†åŒºé€šå¸¸æ˜¯è‡ªåŠ¨çš„ï¼Œæ‰‹åŠ¨åˆ†å‰²éœ€è¦ç‰¹æ®Šå¤„ç†
        logger.warning("Manual partition splitting is not typically supported in Thread")
        return False

    def _get_partition_info(self, network_name: str) -> Dict:
        """è·å–åˆ†åŒºä¿¡æ¯"""
        network = self.networks.get(network_name)
        if not network:
            return {}

        return network.get("partitions", {})

    def diagnose_network(self, network_name: str) -> Dict:
        """ç½‘ç»œè¯Šæ–­ - å®Œæ•´å®ç°"""
        """
        æ‰§è¡Œå…¨é¢çš„ç½‘ç»œè¯Šæ–­ï¼ŒåŒ…æ‹¬ï¼š
        - ç½‘ç»œè¿é€šæ€§æ£€æŸ¥
        - è·¯ç”±è¡¨å®Œæ•´æ€§æ£€æŸ¥
        - èŠ‚ç‚¹å¥åº·çŠ¶æ€æ£€æŸ¥
        - æ€§èƒ½æŒ‡æ ‡æ”¶é›†
        """
        diagnosis = {
            "network_name": network_name,
            "timestamp": datetime.now().isoformat(),
            "connectivity": {},
            "routing": {},
            "node_health": {},
            "performance": {},
            "issues": []
        }

        try:
            network = self.networks.get(network_name)
            if not network:
                diagnosis["issues"].append("Network not found")
                return diagnosis

            nodes_in_network = [
                node_id for node_id, node_info in self.nodes.items()
                if node_info.get("network_name") == network_name
            ]

            if not nodes_in_network:
                diagnosis["issues"].append("No nodes in network")
                return diagnosis

            # 1. è¿é€šæ€§æ£€æŸ¥
            diagnosis["connectivity"] = self._check_connectivity(nodes_in_network)

            # 2. è·¯ç”±è¡¨æ£€æŸ¥
            diagnosis["routing"] = self._check_routing_tables(nodes_in_network)

            # 3. èŠ‚ç‚¹å¥åº·æ£€æŸ¥
            diagnosis["node_health"] = self._check_node_health(nodes_in_network)

            # 4. æ€§èƒ½æŒ‡æ ‡
            diagnosis["performance"] = self._collect_performance_metrics(nodes_in_network)

            # 5. æ±‡æ€»é—®é¢˜
            if diagnosis["connectivity"].get("disconnected_nodes"):
                diagnosis["issues"].append(
                    f"Found {len(diagnosis['connectivity']['disconnected_nodes'])} disconnected nodes"
                )

            if diagnosis["routing"].get("incomplete_tables"):
                diagnosis["issues"].append(
                    f"Found {len(diagnosis['routing']['incomplete_tables'])} nodes with incomplete routing tables"
                )

            if diagnosis["node_health"].get("unhealthy_nodes"):
                diagnosis["issues"].append(
                    f"Found {len(diagnosis['node_health']['unhealthy_nodes'])} unhealthy nodes"
                )

            logger.info(f"Network diagnosis completed: {len(diagnosis['issues'])} issues found")
            return diagnosis

        except Exception as e:
            logger.error(f"Network diagnosis failed: {e}")
            diagnosis["issues"].append(f"Diagnosis error: {str(e)}")
            return diagnosis

    def _check_connectivity(self, node_ids: List[str]) -> Dict:
        """æ£€æŸ¥ç½‘ç»œè¿é€šæ€§"""
        connectivity = {
            "total_nodes": len(node_ids),
            "connected_nodes": [],
            "disconnected_nodes": [],
            "connectivity_matrix": {}
        }

        for node_id in node_ids:
            node_info = self.get_node_info(node_id)
            if node_info and node_info.get("mesh_local_address"):
                connectivity["connected_nodes"].append(node_id)
            else:
                connectivity["disconnected_nodes"].append(node_id)

        # æ„å»ºè¿é€šæ€§çŸ©é˜µï¼ˆç®€åŒ–ç‰ˆï¼šæ£€æŸ¥æ˜¯å¦èƒ½åˆ°è¾¾Leaderï¼‰
        for node_id in connectivity["connected_nodes"]:
            leader_id = self._get_leader_router_id(node_id)
            connectivity["connectivity_matrix"][node_id] = {
                "can_reach_leader": leader_id is not None,
                "leader_id": leader_id
            }

        return connectivity

    def _check_routing_tables(self, node_ids: List[str]) -> Dict:
        """æ£€æŸ¥è·¯ç”±è¡¨"""
        routing = {
            "total_routers": 0,
            "complete_tables": [],
            "incomplete_tables": [],
            "routing_table_stats": {}
        }

        for node_id in node_ids:
            node_info = self.nodes.get(node_id)
            if node_info and node_info.get("node_type") == ThreadNodeType.ROUTER.value:
                routing["total_routers"] += 1
                routes = self.get_routing_table(node_id)

                if len(routes) > 0:
                    routing["complete_tables"].append(node_id)
                    routing["routing_table_stats"][node_id] = {
                        "route_count": len(routes),
                        "routes": routes
                    }
                else:
                    routing["incomplete_tables"].append(node_id)

        return routing

    def _check_node_health(self, node_ids: List[str]) -> Dict:
        """æ£€æŸ¥èŠ‚ç‚¹å¥åº·çŠ¶æ€"""
        health = {
            "healthy_nodes": [],
            "unhealthy_nodes": [],
            "health_details": {}
        }

        for node_id in node_ids:
            node_info = self.get_node_info(node_id)
            if not node_info:
                health["unhealthy_nodes"].append(node_id)
                health["health_details"][node_id] = {"status": "unreachable"}
                continue

            # å¥åº·æ£€æŸ¥æ ‡å‡†
            is_healthy = True
            issues = []

            # æ£€æŸ¥é“¾è·¯è´¨é‡
            link_quality = node_info.get("link_quality", 0)
            if link_quality == 0:
                is_healthy = False
                issues.append("No link quality")

            # æ£€æŸ¥RSSI
            rssi = node_info.get("rssi")
            if rssi and rssi < -90:
                is_healthy = False
                issues.append(f"Low RSSI: {rssi} dBm")

            # æ£€æŸ¥æ˜¯å¦æœ‰çˆ¶èŠ‚ç‚¹ï¼ˆEnd Deviceï¼‰
            if node_info.get("node_type") == ThreadNodeType.END_DEVICE.value:
                if not node_info.get("parent_node_id"):
                    is_healthy = False
                    issues.append("No parent node")

            if is_healthy:
                health["healthy_nodes"].append(node_id)
            else:
                health["unhealthy_nodes"].append(node_id)

            health["health_details"][node_id] = {
                "status": "healthy" if is_healthy else "unhealthy",
                "issues": issues,
                "link_quality": link_quality,
                "rssi": rssi
            }

        return health

    def _collect_performance_metrics(self, node_ids: List[str]) -> Dict:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        metrics = {
            "average_link_quality": 0.0,
            "average_rssi": 0.0,
            "router_count": 0,
            "end_device_count": 0,
            "network_diameter": 0,
            "node_metrics": {}
        }

        link_qualities = []
        rssis = []

        for node_id in node_ids:
            node_info = self.get_node_info(node_id)
            if not node_info:
                continue

            if node_info.get("node_type") == ThreadNodeType.ROUTER.value:
                metrics["router_count"] += 1
            elif node_info.get("node_type") == ThreadNodeType.END_DEVICE.value:
                metrics["end_device_count"] += 1

            link_quality = node_info.get("link_quality", 0)
            if link_quality > 0:
                link_qualities.append(link_quality)

            rssi = node_info.get("rssi")
            if rssi:
                rssis.append(rssi)

            metrics["node_metrics"][node_id] = {
                "link_quality": link_quality,
                "rssi": rssi,
                "node_type": node_info.get("node_type")
            }

        if link_qualities:
            metrics["average_link_quality"] = sum(link_qualities) / len(link_qualities)

        if rssis:
            metrics["average_rssi"] = sum(rssis) / len(rssis)

        # è®¡ç®—ç½‘ç»œç›´å¾„ï¼ˆç®€åŒ–ï¼šæœ€å¤§è·³æ•°ï¼‰
        metrics["network_diameter"] = self._calculate_network_diameter(node_ids)

        return metrics

    def _calculate_network_diameter(self, node_ids: List[str]) -> int:
        """è®¡ç®—ç½‘ç»œç›´å¾„ï¼ˆæœ€å¤§è·³æ•°ï¼‰"""
        # ç®€åŒ–å®ç°ï¼šè¿”å›è·¯ç”±å™¨çš„æœ€å¤§è·¯ç”±è¡¨å¤§å°
        max_hops = 0
        for node_id in node_ids:
            node_info = self.nodes.get(node_id)
            if node_info and node_info.get("node_type") == ThreadNodeType.ROUTER.value:
                routes = self.get_routing_table(node_id)
                for route in routes:
                    cost = route.get("cost", 0)
                    if cost > max_hops:
                        max_hops = cost

        return max_hops
```

---

## 5. è½¬æ¢å·¥å…·

### 5.1 OpenThread CLIé›†æˆ

è¯¦è§ç¬¬2.1èŠ‚ThreadNetworkManagerå®ç°ã€‚

### 5.2 Thread SDKé›†æˆ

**Thread SDK Pythonå°è£…**ï¼š

```python
import socket
import struct
from typing import Optional

class ThreadSDKWrapper:
    """Thread SDKå°è£…ç±»"""

    def __init__(self, node_id: str):
        self.node_id = node_id
        self.socket = None

    def connect(self) -> bool:
        """è¿æ¥åˆ°ThreadèŠ‚ç‚¹"""
        try:
            # ä½¿ç”¨UnixåŸŸå¥—æ¥å­—è¿æ¥åˆ°OpenThread
            self.socket = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
            socket_path = f"/tmp/ot-{self.node_id}.sock"
            self.socket.connect(socket_path)
            return True
        except Exception as e:
            logger.error(f"Failed to connect to Thread node: {e}")
            return False

    def send_command(self, command: str) -> Optional[str]:
        """å‘é€å‘½ä»¤åˆ°ThreadèŠ‚ç‚¹"""
        if not self.socket:
            return None

        try:
            self.socket.sendall(command.encode() + b'\n')
            response = self.socket.recv(4096).decode()
            return response.strip()
        except Exception as e:
            logger.error(f"Failed to send command: {e}")
            return None

    def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        if self.socket:
            self.socket.close()
            self.socket = None
```

---

## 6. è½¬æ¢éªŒè¯

### 6.1 ç½‘ç»œæ‹“æ‰‘ä¸€è‡´æ€§éªŒè¯

**è½¬æ¢éªŒè¯å™¨å®ç°**ï¼š

```python
class ThreadConversionValidator:
    """Threadè½¬æ¢éªŒè¯å™¨"""

    def validate_thread_to_zigbee(self, thread_node: Dict,
                                  zigbee_node: Dict) -> bool:
        """éªŒè¯Threadåˆ°Zigbeeè½¬æ¢çš„æ­£ç¡®æ€§"""
        # éªŒè¯èŠ‚ç‚¹IDä¸€è‡´æ€§
        if thread_node.get("node_id") != zigbee_node.get("ieee_address"):
            return False

        # éªŒè¯èŠ‚ç‚¹ç±»å‹è½¬æ¢æ­£ç¡®æ€§
        thread_type = thread_node.get("node_type")
        zigbee_type = zigbee_node.get("node_type")

        type_map = {
            ThreadNodeType.ROUTER.value: "Coordinator",
            ThreadNodeType.LEADER.value: "Coordinator",
            ThreadNodeType.END_DEVICE.value: "EndDevice"
        }

        if type_map.get(thread_type) != zigbee_type:
            return False

        return True

    def validate_zigbee_to_thread(self, zigbee_node: Dict,
                                  thread_node: Dict) -> bool:
        """éªŒè¯Zigbeeåˆ°Threadè½¬æ¢çš„æ­£ç¡®æ€§"""
        # éªŒè¯èŠ‚ç‚¹IDä¸€è‡´æ€§
        if zigbee_node.get("ieee_address") != thread_node.get("node_id"):
            return False

        # éªŒè¯IPv6åœ°å€æ ¼å¼
        mesh_local = thread_node.get("ipv6_address", {}).get("mesh_local", "")
        if not mesh_local.startswith("fd"):
            return False

        return True
```

---

## 7. Threadæ•°æ®å­˜å‚¨ä¸åˆ†æ

### 7.1 PostgreSQL Threadæ•°æ®å­˜å‚¨

**Threadæ•°æ®å­˜å‚¨æ–¹æ¡ˆ**ï¼š

```python
import psycopg2
import json
from typing import Dict, List, Optional
from datetime import datetime

class ThreadStorage:
    """Threadæ•°æ®å­˜å‚¨ç³»ç»Ÿ"""

    def __init__(self, connection_string: str):
        self.conn = psycopg2.connect(connection_string)
        self.cur = self.conn.cursor()
        self._create_tables()

    def _create_tables(self):
        """åˆ›å»ºThreadæ•°æ®è¡¨"""
        # Threadç½‘ç»œè¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS thread_networks (
                id BIGSERIAL PRIMARY KEY,
                network_name VARCHAR(16) UNIQUE NOT NULL,
                pan_id INTEGER NOT NULL,
                extended_pan_id VARCHAR(16) UNIQUE NOT NULL,
                channel INTEGER NOT NULL,
                network_key VARCHAR(32) NOT NULL,
                partition_id INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # ThreadèŠ‚ç‚¹è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS thread_nodes (
                id BIGSERIAL PRIMARY KEY,
                node_id VARCHAR(16) UNIQUE NOT NULL,
                network_name VARCHAR(16) NOT NULL,
                node_type VARCHAR(20) NOT NULL,
                link_local_address VARCHAR(39) NOT NULL,
                mesh_local_address VARCHAR(39) NOT NULL,
                global_address VARCHAR(39),
                parent_node_id VARCHAR(16),
                router_id INTEGER,
                leader_router_id INTEGER,
                rloc16 INTEGER,
                link_quality INTEGER,
                rssi INTEGER,
                battery_level INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (network_name) REFERENCES thread_networks(network_name)
            )
        """)

        # Threadè·¯ç”±è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS thread_routes (
                id BIGSERIAL PRIMARY KEY,
                node_id VARCHAR(16) NOT NULL,
                destination VARCHAR(39) NOT NULL,
                next_hop VARCHAR(16) NOT NULL,
                cost INTEGER NOT NULL,
                lifetime INTEGER NOT NULL,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (node_id) REFERENCES thread_nodes(node_id),
                UNIQUE(node_id, destination)
            )
        """)

        # Threadå®‰å…¨ä¿¡æ¯è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS thread_security (
                id BIGSERIAL PRIMARY KEY,
                node_id VARCHAR(16) UNIQUE NOT NULL,
                network_key_sequence INTEGER NOT NULL,
                key_rotation_enabled BOOLEAN DEFAULT TRUE,
                key_rotation_interval INTEGER DEFAULT 86400,
                last_key_rotation TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (node_id) REFERENCES thread_nodes(node_id)
            )
        """)

        # Threadç½‘ç»œæ€§èƒ½è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS thread_performance (
                id BIGSERIAL PRIMARY KEY,
                node_id VARCHAR(16) NOT NULL,
                latency_ms INTEGER,
                packet_loss_rate DECIMAL(5,2),
                throughput_kbps DECIMAL(10,2),
                recorded_at TIMESTAMP NOT NULL,
                FOREIGN KEY (node_id) REFERENCES thread_nodes(node_id)
            )
        """)

        # Threadç½‘ç»œåˆ†åŒºè¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS thread_partitions (
                id BIGSERIAL PRIMARY KEY,
                network_name VARCHAR(16) NOT NULL,
                partition_id INTEGER NOT NULL,
                leader_router_id INTEGER,
                node_count INTEGER DEFAULT 0,
                detected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (network_name) REFERENCES thread_networks(network_name),
                UNIQUE(network_name, partition_id)
            )
        """)

        # Threadç½‘ç»œäº‹ä»¶è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS thread_events (
                id BIGSERIAL PRIMARY KEY,
                network_name VARCHAR(16) NOT NULL,
                node_id VARCHAR(16),
                event_type VARCHAR(50) NOT NULL,
                event_data JSONB,
                event_time TIMESTAMP NOT NULL,
                FOREIGN KEY (network_name) REFERENCES thread_networks(network_name),
                FOREIGN KEY (node_id) REFERENCES thread_nodes(node_id)
            )
        """)

        # Threadç½‘ç»œè¯Šæ–­è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS thread_diagnostics (
                id BIGSERIAL PRIMARY KEY,
                network_name VARCHAR(16) NOT NULL,
                diagnosis_data JSONB NOT NULL,
                issues_count INTEGER DEFAULT 0,
                diagnosed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (network_name) REFERENCES thread_networks(network_name)
            )
        """)

        # Threadé“¾è·¯è´¨é‡å†å²è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS thread_link_quality_history (
                id BIGSERIAL PRIMARY KEY,
                source_node_id VARCHAR(16) NOT NULL,
                target_node_id VARCHAR(16) NOT NULL,
                link_quality INTEGER NOT NULL,
                rssi INTEGER,
                recorded_at TIMESTAMP NOT NULL,
                FOREIGN KEY (source_node_id) REFERENCES thread_nodes(node_id),
                FOREIGN KEY (target_node_id) REFERENCES thread_nodes(node_id)
            )
        """)

        # Threadè·¯ç”±å†å²è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS thread_route_history (
                id BIGSERIAL PRIMARY KEY,
                node_id VARCHAR(16) NOT NULL,
                destination VARCHAR(39) NOT NULL,
                route_path JSONB NOT NULL,
                hop_count INTEGER NOT NULL,
                total_cost INTEGER NOT NULL,
                calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (node_id) REFERENCES thread_nodes(node_id)
            )
        """)

        # åˆ›å»ºç´¢å¼•
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_thread_nodes_node_id
            ON thread_nodes(node_id)
        """)

        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_thread_nodes_network_name
            ON thread_nodes(network_name)
        """)

        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_thread_routes_node_id
            ON thread_routes(node_id)
        """)

        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_thread_events_network_name
            ON thread_events(network_name, event_time DESC)
        """)

        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_thread_events_node_id
            ON thread_events(node_id, event_time DESC)
        """)

        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_thread_link_quality_history
            ON thread_link_quality_history(source_node_id, target_node_id, recorded_at DESC)
        """)

        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_thread_performance_node_id
            ON thread_performance(node_id, recorded_at DESC)
        """)

        self.conn.commit()

    def store_network(self, network_data: Dict) -> int:
        """å­˜å‚¨Threadç½‘ç»œ"""
        self.cur.execute("""
            INSERT INTO thread_networks (
                network_name, pan_id, extended_pan_id,
                channel, network_key, partition_id
            ) VALUES (%s, %s, %s, %s, %s, %s)
            ON CONFLICT (network_name) DO UPDATE SET
                updated_at = CURRENT_TIMESTAMP
            RETURNING id
        """, (
            network_data.get("network_name"),
            network_data.get("pan_id"),
            network_data.get("extended_pan_id"),
            network_data.get("channel"),
            network_data.get("network_key"),
            network_data.get("partition_id")
        ))
        return self.cur.fetchone()[0]

    def store_node(self, node_data: Dict) -> int:
        """å­˜å‚¨ThreadèŠ‚ç‚¹"""
        self.cur.execute("""
            INSERT INTO thread_nodes (
                node_id, network_name, node_type,
                link_local_address, mesh_local_address, global_address,
                parent_node_id, router_id, leader_router_id, rloc16,
                link_quality, rssi, battery_level
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (node_id) DO UPDATE SET
                network_name = EXCLUDED.network_name,
                node_type = EXCLUDED.node_type,
                link_local_address = EXCLUDED.link_local_address,
                mesh_local_address = EXCLUDED.mesh_local_address,
                parent_node_id = EXCLUDED.parent_node_id,
                router_id = EXCLUDED.router_id,
                leader_router_id = EXCLUDED.leader_router_id,
                rloc16 = EXCLUDED.rloc16,
                link_quality = EXCLUDED.link_quality,
                rssi = EXCLUDED.rssi,
                battery_level = EXCLUDED.battery_level,
                updated_at = CURRENT_TIMESTAMP
            RETURNING id
        """, (
            node_data.get("node_id"),
            node_data.get("network_name"),
            node_data.get("node_type"),
            node_data.get("link_local_address"),
            node_data.get("mesh_local_address"),
            node_data.get("global_address"),
            node_data.get("parent_node_id"),
            node_data.get("router_id"),
            node_data.get("leader_router_id"),
            node_data.get("rloc16"),
            node_data.get("link_quality"),
            node_data.get("rssi"),
            node_data.get("battery_level")
        ))
        self.conn.commit()
        return self.cur.fetchone()[0]

    def store_route(self, node_id: str, route_data: Dict) -> int:
        """å­˜å‚¨è·¯ç”±æ¡ç›®"""
        self.cur.execute("""
            INSERT INTO thread_routes (
                node_id, destination, next_hop, cost, lifetime
            ) VALUES (%s, %s, %s, %s, %s)
            ON CONFLICT (node_id, destination) DO UPDATE SET
                next_hop = EXCLUDED.next_hop,
                cost = EXCLUDED.cost,
                lifetime = EXCLUDED.lifetime,
                updated_at = CURRENT_TIMESTAMP
            RETURNING id
        """, (
            node_id,
            route_data.get("destination"),
            route_data.get("next_hop"),
            route_data.get("cost"),
            route_data.get("lifetime", 3600)
        ))
        self.conn.commit()
        return self.cur.fetchone()[0]

    def store_routing_table(self, node_id: str, routes: List[Dict]):
        """å­˜å‚¨æ•´ä¸ªè·¯ç”±è¡¨"""
        for route in routes:
            self.store_route(node_id, route)

    def store_performance_data(self, node_id: str, performance_data: Dict) -> int:
        """å­˜å‚¨æ€§èƒ½æ•°æ®"""
        self.cur.execute("""
            INSERT INTO thread_performance (
                node_id, latency_ms, packet_loss_rate, throughput_kbps, recorded_at
            ) VALUES (%s, %s, %s, %s, CURRENT_TIMESTAMP)
            RETURNING id
        """, (
            node_id,
            performance_data.get("latency_ms"),
            performance_data.get("packet_loss_rate"),
            performance_data.get("throughput_kbps")
        ))
        self.conn.commit()
        return self.cur.fetchone()[0]

    def get_node_routes(self, node_id: str) -> List[Dict]:
        """è·å–èŠ‚ç‚¹çš„è·¯ç”±è¡¨"""
        self.cur.execute("""
            SELECT destination, next_hop, cost, lifetime, updated_at
            FROM thread_routes
            WHERE node_id = %s
            ORDER BY cost, destination
        """, (node_id,))
        return [
            {
                "destination": row[0],
                "next_hop": row[1],
                "cost": row[2],
                "lifetime": row[3],
                "updated_at": row[4]
            }
            for row in self.cur.fetchall()
        ]

    def store_partition(self, network_name: str, partition_data: Dict) -> int:
        """å­˜å‚¨ç½‘ç»œåˆ†åŒºä¿¡æ¯"""
        self.cur.execute("""
            INSERT INTO thread_partitions (
                network_name, partition_id, leader_router_id, node_count
            ) VALUES (%s, %s, %s, %s)
            ON CONFLICT (network_name, partition_id) DO UPDATE SET
                leader_router_id = EXCLUDED.leader_router_id,
                node_count = EXCLUDED.node_count,
                detected_at = CURRENT_TIMESTAMP
            RETURNING id
        """, (
            network_name,
            partition_data.get("partition_id"),
            partition_data.get("leader_router_id"),
            partition_data.get("node_count", 0)
        ))
        partition_id = self.cur.fetchone()[0]
        self.conn.commit()
        return partition_id

    def store_event(self, network_name: str, event_type: str,
                   event_data: Dict, node_id: str = None) -> int:
        """å­˜å‚¨ç½‘ç»œäº‹ä»¶"""
        self.cur.execute("""
            INSERT INTO thread_events (
                network_name, node_id, event_type, event_data, event_time
            ) VALUES (%s, %s, %s, %s::jsonb, CURRENT_TIMESTAMP)
            RETURNING id
        """, (
            network_name,
            node_id,
            event_type,
            json.dumps(event_data)
        ))
        event_id = self.cur.fetchone()[0]
        self.conn.commit()
        return event_id

    def store_diagnosis(self, network_name: str, diagnosis_data: Dict) -> int:
        """å­˜å‚¨ç½‘ç»œè¯Šæ–­ç»“æœ"""
        issues = diagnosis_data.get("issues", [])
        issues_count = len(issues)

        self.cur.execute("""
            INSERT INTO thread_diagnostics (
                network_name, diagnosis_data, issues_count
            ) VALUES (%s, %s::jsonb, %s)
            RETURNING id
        """, (
            network_name,
            json.dumps(diagnosis_data),
            issues_count
        ))
        diagnosis_id = self.cur.fetchone()[0]
        self.conn.commit()
        return diagnosis_id

    def store_link_quality(self, source_node_id: str, target_node_id: str,
                          link_quality: int, rssi: int = None) -> int:
        """å­˜å‚¨é“¾è·¯è´¨é‡å†å²"""
        self.cur.execute("""
            INSERT INTO thread_link_quality_history (
                source_node_id, target_node_id, link_quality, rssi, recorded_at
            ) VALUES (%s, %s, %s, %s, CURRENT_TIMESTAMP)
            RETURNING id
        """, (source_node_id, target_node_id, link_quality, rssi))
        history_id = self.cur.fetchone()[0]
        self.conn.commit()
        return history_id

    def store_route_path(self, node_id: str, destination: str,
                        route_path: List[str], hop_count: int, total_cost: int) -> int:
        """å­˜å‚¨è·¯ç”±è·¯å¾„å†å²"""
        self.cur.execute("""
            INSERT INTO thread_route_history (
                node_id, destination, route_path, hop_count, total_cost
            ) VALUES (%s, %s, %s::jsonb, %s, %s)
            RETURNING id
        """, (
            node_id,
            destination,
            json.dumps(route_path),
            hop_count,
            total_cost
        ))
        route_history_id = self.cur.fetchone()[0]
        self.conn.commit()
        return route_history_id

    def get_network_nodes(self, network_name: str) -> List[Dict]:
        """è·å–ç½‘ç»œä¸­çš„æ‰€æœ‰èŠ‚ç‚¹"""
        self.cur.execute("""
            SELECT node_id, node_type, link_local_address, mesh_local_address,
                   parent_node_id, router_id, leader_router_id, link_quality, rssi
            FROM thread_nodes
            WHERE network_name = %s
            ORDER BY node_type, node_id
        """, (network_name,))
        return [
            {
                "node_id": row[0],
                "node_type": row[1],
                "link_local_address": row[2],
                "mesh_local_address": row[3],
                "parent_node_id": row[4],
                "router_id": row[5],
                "leader_router_id": row[6],
                "link_quality": row[7],
                "rssi": row[8]
            }
            for row in self.cur.fetchall()
        ]

    def get_node_by_id(self, node_id: str) -> Optional[Dict]:
        """æ ¹æ®IDè·å–èŠ‚ç‚¹"""
        self.cur.execute("""
            SELECT node_id, network_name, node_type, link_local_address,
                   mesh_local_address, parent_node_id, router_id, leader_router_id,
                   rloc16, link_quality, rssi, battery_level, created_at, updated_at
            FROM thread_nodes
            WHERE node_id = %s
        """, (node_id,))
        row = self.cur.fetchone()
        if row:
            return {
                "node_id": row[0],
                "network_name": row[1],
                "node_type": row[2],
                "link_local_address": row[3],
                "mesh_local_address": row[4],
                "parent_node_id": row[5],
                "router_id": row[6],
                "leader_router_id": row[7],
                "rloc16": row[8],
                "link_quality": row[9],
                "rssi": row[10],
                "battery_level": row[11],
                "created_at": row[12],
                "updated_at": row[13]
            }
        return None

    def get_recent_events(self, network_name: str = None, node_id: str = None,
                         event_type: str = None, limit: int = 100) -> List[Dict]:
        """è·å–æœ€è¿‘çš„äº‹ä»¶"""
        query = """
            SELECT id, network_name, node_id, event_type, event_data, event_time
            FROM thread_events
            WHERE 1=1
        """
        params = []

        if network_name:
            query += " AND network_name = %s"
            params.append(network_name)

        if node_id:
            query += " AND node_id = %s"
            params.append(node_id)

        if event_type:
            query += " AND event_type = %s"
            params.append(event_type)

        query += " ORDER BY event_time DESC LIMIT %s"
        params.append(limit)

        self.cur.execute(query, params)
        return [
            {
                "id": row[0],
                "network_name": row[1],
                "node_id": row[2],
                "event_type": row[3],
                "event_data": json.loads(row[4]) if row[4] else {},
                "event_time": row[5]
            }
            for row in self.cur.fetchall()
        ]

    def get_link_quality_history(self, source_node_id: str, target_node_id: str,
                                 hours: int = 24) -> List[Dict]:
        """è·å–é“¾è·¯è´¨é‡å†å²"""
        self.cur.execute("""
            SELECT link_quality, rssi, recorded_at
            FROM thread_link_quality_history
            WHERE source_node_id = %s AND target_node_id = %s
            AND recorded_at >= CURRENT_TIMESTAMP - INTERVAL '%s hours'
            ORDER BY recorded_at DESC
        """, (source_node_id, target_node_id, hours))
        return [
            {
                "link_quality": row[0],
                "rssi": row[1],
                "recorded_at": row[2]
            }
            for row in self.cur.fetchall()
        ]

    def get_network_statistics(self, network_name: str) -> Dict:
        """è·å–ç½‘ç»œç»Ÿè®¡ä¿¡æ¯"""
        # èŠ‚ç‚¹ç»Ÿè®¡
        self.cur.execute("""
            SELECT node_type, COUNT(*) as count,
                   AVG(link_quality) as avg_lqi, AVG(rssi) as avg_rssi
            FROM thread_nodes
            WHERE network_name = %s
            GROUP BY node_type
        """, (network_name,))
        node_stats = {
            row[0]: {
                "count": row[1],
                "avg_link_quality": float(row[2]) if row[2] else None,
                "avg_rssi": float(row[3]) if row[3] else None
            }
            for row in self.cur.fetchall()
        }

        # è·¯ç”±ç»Ÿè®¡
        self.cur.execute("""
            SELECT COUNT(DISTINCT node_id) as nodes_with_routes,
                   COUNT(*) as total_routes,
                   AVG(cost) as avg_cost,
                   MAX(cost) as max_hops
            FROM thread_routes
            WHERE node_id IN (
                SELECT node_id FROM thread_nodes WHERE network_name = %s
            )
        """, (network_name,))
        route_row = self.cur.fetchone()
        route_stats = {
            "nodes_with_routes": route_row[0] if route_row else 0,
            "total_routes": route_row[1] if route_row else 0,
            "avg_cost": float(route_row[2]) if route_row and route_row[2] else 0,
            "max_hops": route_row[3] if route_row else 0
        }

        # åˆ†åŒºç»Ÿè®¡
        self.cur.execute("""
            SELECT COUNT(*) as partition_count, SUM(node_count) as total_nodes_in_partitions
            FROM thread_partitions
            WHERE network_name = %s
        """, (network_name,))
        partition_row = self.cur.fetchone()
        partition_stats = {
            "partition_count": partition_row[0] if partition_row else 0,
            "total_nodes_in_partitions": partition_row[1] if partition_row else 0
        }

        return {
            "network_name": network_name,
            "node_statistics": node_stats,
            "routing_statistics": route_stats,
            "partition_statistics": partition_stats
        }

    def update_node_status(self, node_id: str, link_quality: int = None,
                          rssi: int = None, battery_level: int = None):
        """æ›´æ–°èŠ‚ç‚¹çŠ¶æ€"""
        updates = []
        params = []

        if link_quality is not None:
            updates.append("link_quality = %s")
            params.append(link_quality)

        if rssi is not None:
            updates.append("rssi = %s")
            params.append(rssi)

        if battery_level is not None:
            updates.append("battery_level = %s")
            params.append(battery_level)

        if updates:
            updates.append("updated_at = CURRENT_TIMESTAMP")
            params.append(node_id)

            query = f"""
                UPDATE thread_nodes
                SET {', '.join(updates)}
                WHERE node_id = %s
            """
            self.cur.execute(query, params)
            self.conn.commit()

    def delete_expired_routes(self, max_age_hours: int = 24):
        """åˆ é™¤è¿‡æœŸçš„è·¯ç”±"""
        self.cur.execute("""
            DELETE FROM thread_routes
            WHERE updated_at < CURRENT_TIMESTAMP - INTERVAL '%s hours'
        """, (max_age_hours,))
        deleted_count = self.cur.rowcount
        self.conn.commit()
        logger.info(f"Deleted {deleted_count} expired routes")
        return deleted_count

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.cur.close()
        self.conn.close()
```

### 7.2 Threadæ•°æ®åˆ†ææŸ¥è¯¢

**æŸ¥è¯¢ç¤ºä¾‹**ï¼š

```python
    def get_network_topology_statistics(self, network_name: str) -> List[Dict]:
        """æŸ¥è¯¢ç½‘ç»œæ‹“æ‰‘ç»Ÿè®¡"""
        self.cur.execute("""
            SELECT
                node_type,
                COUNT(*) as count,
                AVG(link_quality) as avg_link_quality,
                AVG(rssi) as avg_rssi,
                AVG(battery_level) as avg_battery_level
            FROM thread_nodes
            WHERE network_name = %s
            GROUP BY node_type
            ORDER BY node_type
        """, (network_name,))
        return [
            {
                "node_type": row[0],
                "count": row[1],
                "avg_link_quality": float(row[2]) if row[2] else None,
                "avg_rssi": float(row[3]) if row[3] else None,
                "avg_battery_level": float(row[4]) if row[4] else None
            }
            for row in self.cur.fetchall()
        ]

    def get_routing_statistics(self, node_id: str) -> Dict:
        """æŸ¥è¯¢è·¯ç”±ç»Ÿè®¡"""
        self.cur.execute("""
            SELECT
                COUNT(*) as route_count,
                AVG(cost) as avg_cost,
                MIN(cost) as min_cost,
                MAX(cost) as max_cost,
                AVG(lifetime) as avg_lifetime
            FROM thread_routes
            WHERE node_id = %s
        """, (node_id,))
        row = self.cur.fetchone()
        return {
            "route_count": row[0],
            "avg_cost": float(row[1]) if row[1] else 0,
            "min_cost": row[2] if row[2] else 0,
            "max_cost": row[3] if row[3] else 0,
            "avg_lifetime": float(row[4]) if row[4] else 0
        }

    def get_network_performance_statistics(self, network_name: str, hours: int = 24) -> Dict:
        """æŸ¥è¯¢ç½‘ç»œæ€§èƒ½ç»Ÿè®¡"""
        self.cur.execute("""
            SELECT
                AVG(p.latency_ms) as avg_latency,
                AVG(p.packet_loss_rate) as avg_packet_loss,
                AVG(p.throughput_kbps) as avg_throughput,
                COUNT(DISTINCT p.node_id) as monitored_nodes
            FROM thread_performance p
            JOIN thread_nodes n ON p.node_id = n.node_id
            WHERE n.network_name = %s
            AND p.recorded_at >= CURRENT_TIMESTAMP - INTERVAL '%s hours'
        """, (network_name, hours))
        row = self.cur.fetchone()
        return {
            "avg_latency": float(row[0]) if row[0] else None,
            "avg_packet_loss": float(row[1]) if row[1] else None,
            "avg_throughput": float(row[2]) if row[2] else None,
            "monitored_nodes": row[3]
        }

    def get_node_performance_history(self, node_id: str, hours: int = 24) -> List[Dict]:
        """æŸ¥è¯¢èŠ‚ç‚¹æ€§èƒ½å†å²"""
        self.cur.execute("""
            SELECT
                latency_ms,
                packet_loss_rate,
                throughput_kbps,
                recorded_at
            FROM thread_performance
            WHERE node_id = %s
            AND recorded_at >= CURRENT_TIMESTAMP - INTERVAL '%s hours'
            ORDER BY recorded_at DESC
        """, (node_id, hours))
        return [
            {
                "latency_ms": row[0],
                "packet_loss_rate": float(row[1]) if row[1] else None,
                "throughput_kbps": float(row[2]) if row[2] else None,
                "recorded_at": row[3]
            }
            for row in self.cur.fetchall()
        ]

    def get_network_health_status(self, network_name: str) -> Dict:
        """æŸ¥è¯¢ç½‘ç»œå¥åº·çŠ¶æ€"""
        self.cur.execute("""
            SELECT
                COUNT(*) as total_nodes,
                COUNT(CASE WHEN node_type = 'Router' THEN 1 END) as router_count,
                COUNT(CASE WHEN node_type = 'EndDevice' THEN 1 END) as end_device_count,
                AVG(link_quality) as avg_link_quality,
                AVG(rssi) as avg_rssi,
                COUNT(CASE WHEN battery_level < 20 THEN 1 END) as low_battery_count
            FROM thread_nodes
            WHERE network_name = %s
        """, (network_name,))
        row = self.cur.fetchone()

        return {
            "total_nodes": row[0],
            "router_count": row[1],
            "end_device_count": row[2],
            "avg_link_quality": float(row[3]) if row[3] else None,
            "avg_rssi": float(row[4]) if row[4] else None,
            "low_battery_count": row[5],
            "health_score": self._calculate_health_score(row)
        }

    def _calculate_health_score(self, stats_row: tuple) -> float:
        """è®¡ç®—å¥åº·åˆ†æ•°ï¼ˆ0-100ï¼‰"""
        total_nodes, router_count, end_device_count, avg_link_quality, avg_rssi, low_battery_count = stats_row

        if total_nodes == 0:
            return 0.0

        score = 100.0

        # é“¾è·¯è´¨é‡è¯„åˆ†ï¼ˆ0-255ï¼Œè¶Šé«˜è¶Šå¥½ï¼‰
        if avg_link_quality:
            link_quality_score = (avg_link_quality / 255.0) * 30
            score = min(score, link_quality_score + 70)

        # RSSIè¯„åˆ†ï¼ˆ-128åˆ°127ï¼Œè¶Šé«˜è¶Šå¥½ï¼‰
        if avg_rssi:
            rssi_score = ((avg_rssi + 128) / 255.0) * 20
            score = min(score, rssi_score + 80)

        # ä½ç”µé‡èŠ‚ç‚¹æ‰£åˆ†
        if total_nodes > 0:
            low_battery_ratio = low_battery_count / total_nodes
            score -= low_battery_ratio * 20

        # è·¯ç”±å™¨æ•°é‡è¯„åˆ†ï¼ˆè‡³å°‘éœ€è¦1ä¸ªè·¯ç”±å™¨ï¼‰
        if router_count == 0:
            score -= 30

        return max(0.0, min(100.0, score))
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `05_Case_Studies.md` - å®è·µæ¡ˆä¾‹

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
