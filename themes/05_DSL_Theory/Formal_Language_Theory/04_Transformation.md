# DSL Schemaè½¬æ¢å½¢å¼è¯­è¨€ç†è®ºåº”ç”¨

## ğŸ“‘ ç›®å½•

- [DSL Schemaè½¬æ¢å½¢å¼è¯­è¨€ç†è®ºåº”ç”¨](#dsl-schemaè½¬æ¢å½¢å¼è¯­è¨€ç†è®ºåº”ç”¨)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. åº”ç”¨æ¦‚è¿°](#1-åº”ç”¨æ¦‚è¿°)
  - [2. è¯­æ³•åˆ†æåº”ç”¨](#2-è¯­æ³•åˆ†æåº”ç”¨)
    - [2.1 Schemaè¯­æ³•åˆ†æ](#21-schemaè¯­æ³•åˆ†æ)
    - [2.2 è¯­æ³•æ ‘æ„å»º](#22-è¯­æ³•æ ‘æ„å»º)
  - [3. è¯­ä¹‰åˆ†æåº”ç”¨](#3-è¯­ä¹‰åˆ†æåº”ç”¨)
    - [3.1 è¯­ä¹‰æ¨¡å‹æ„å»º](#31-è¯­ä¹‰æ¨¡å‹æ„å»º)
    - [3.2 è¯­ä¹‰éªŒè¯](#32-è¯­ä¹‰éªŒè¯)
  - [4. è½¬æ¢åº”ç”¨](#4-è½¬æ¢åº”ç”¨)
    - [4.1 è¯­æ³•è½¬æ¢](#41-è¯­æ³•è½¬æ¢)
    - [4.2 è¯­ä¹‰è½¬æ¢](#42-è¯­ä¹‰è½¬æ¢)
  - [5. è¯­æ³•æ ‘å’Œè¯­ä¹‰æ¨¡å‹å­˜å‚¨](#5-è¯­æ³•æ ‘å’Œè¯­ä¹‰æ¨¡å‹å­˜å‚¨)
    - [5.1 PostgreSQLè¯­æ³•æ ‘å­˜å‚¨](#51-postgresqlè¯­æ³•æ ‘å­˜å‚¨)
    - [5.2 è¯­æ³•åˆ†ææŸ¥è¯¢](#52-è¯­æ³•åˆ†ææŸ¥è¯¢)
  - [6. å‚è€ƒæ–‡çŒ®](#6-å‚è€ƒæ–‡çŒ®)
    - [6.1 æŠ€æœ¯æ–‡æ¡£](#61-æŠ€æœ¯æ–‡æ¡£)

---

## 1. åº”ç”¨æ¦‚è¿°

å½¢å¼è¯­è¨€ç†è®ºåœ¨DSL Schemaè½¬æ¢ä¸­çš„åº”ç”¨åŒ…æ‹¬ï¼š

1. **è¯­æ³•åˆ†æ**ï¼šè§£æSchemaè¯­æ³•ç»“æ„
2. **è¯­ä¹‰åˆ†æ**ï¼šæ„å»ºè¯­ä¹‰æ¨¡å‹
3. **è½¬æ¢åº”ç”¨**ï¼šåº”ç”¨è¯­æ³•å’Œè¯­ä¹‰è½¬æ¢

---

## 2. è¯­æ³•åˆ†æåº”ç”¨

### 2.1 Schemaè¯­æ³•åˆ†æ

**Pythonå®ç°**ï¼š

```python
from typing import List, Dict, Any

class SchemaParser:
    """Schemaè¯­æ³•åˆ†æå™¨"""

    def parse(self, schema: Dict[str, Any]) -> Dict[str, Any]:
        """è§£æSchemaè¯­æ³•"""
        return {
            'types': self._parse_types(schema),
            'structure': self._parse_structure(schema),
            'constraints': self._parse_constraints(schema)
        }

    def _parse_types(self, schema: Dict[str, Any]) -> List[str]:
        """è§£æç±»å‹å®šä¹‰"""
        types = []
        if 'type' in schema:
            types.append(schema['type'])
        if 'properties' in schema:
            for prop in schema['properties'].values():
                types.extend(self._parse_types(prop))
        return types
```

### 2.2 è¯­æ³•æ ‘æ„å»º

**Pythonå®ç°**ï¼š

```python
class SyntaxTree:
    """è¯­æ³•æ ‘"""

    def __init__(self, node_type: str, value: Any = None):
        self.node_type = node_type
        self.value = value
        self.children = []

    def add_child(self, child: 'SyntaxTree'):
        """æ·»åŠ å­èŠ‚ç‚¹"""
        self.children.append(child)
```

---

## 3. è¯­ä¹‰åˆ†æåº”ç”¨

### 3.1 è¯­ä¹‰æ¨¡å‹æ„å»º

**Pythonå®ç°**ï¼š

```python
class SemanticModel:
    """è¯­ä¹‰æ¨¡å‹"""

    def __init__(self):
        self.domains = {}
        self.interpretations = {}

    def add_domain(self, name: str, domain: Any):
        """æ·»åŠ è¯­ä¹‰åŸŸ"""
        self.domains[name] = domain

    def add_interpretation(self, syntax: str, semantics: Any):
        """æ·»åŠ è§£é‡Šå‡½æ•°"""
        self.interpretations[syntax] = semantics
```

### 3.2 è¯­ä¹‰éªŒè¯

**Pythonå®ç°**ï¼š

```python
def validate_semantics(syntax_tree: SyntaxTree,
                       semantic_model: SemanticModel) -> bool:
    """éªŒè¯è¯­ä¹‰"""
    # å®ç°è¯­ä¹‰éªŒè¯é€»è¾‘
    return True
```

---

## 4. è½¬æ¢åº”ç”¨

### 4.1 è¯­æ³•è½¬æ¢

**Pythonå®ç°**ï¼š

```python
class SyntaxTransformer:
    """è¯­æ³•è½¬æ¢å™¨"""

    def transform(self, source_tree: SyntaxTree,
                  target_grammar: Dict[str, Any]) -> SyntaxTree:
        """è½¬æ¢è¯­æ³•æ ‘"""
        # å®ç°è¯­æ³•è½¬æ¢é€»è¾‘
        return target_tree
```

### 4.2 è¯­ä¹‰è½¬æ¢

**Pythonå®ç°**ï¼š

```python
class SemanticTransformer:
    """è¯­ä¹‰è½¬æ¢å™¨"""

    def transform(self, source_semantics: SemanticModel,
                  target_semantics: SemanticModel) -> SemanticModel:
        """è½¬æ¢è¯­ä¹‰æ¨¡å‹"""
        # å®ç°è¯­ä¹‰è½¬æ¢é€»è¾‘
        return target_semantics
```

---

## 5. è¯­æ³•æ ‘å’Œè¯­ä¹‰æ¨¡å‹å­˜å‚¨

### 5.1 PostgreSQLè¯­æ³•æ ‘å­˜å‚¨

**è¯­æ³•æ ‘æ•°æ®å­˜å‚¨æ–¹æ¡ˆ**ï¼š

```python
import psycopg2
import json
from typing import Dict, List, Optional
from dataclasses import dataclass, asdict

@dataclass
class SyntaxTreeNode:
    """è¯­æ³•æ ‘èŠ‚ç‚¹"""
    node_type: str
    value: any
    children: List['SyntaxTreeNode']
    position: Dict[str, int] = None

class SyntaxTreeStorage:
    """è¯­æ³•æ ‘å­˜å‚¨ç³»ç»Ÿ"""

    def __init__(self, connection_string: str):
        self.conn = psycopg2.connect(connection_string)
        self.cur = self.conn.cursor()
        self._create_tables()

    def _create_tables(self):
        """åˆ›å»ºè¯­æ³•æ ‘æ•°æ®è¡¨"""
        # è¯­æ³•æ ‘è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS syntax_trees (
                id SERIAL PRIMARY KEY,
                schema_name VARCHAR(200) NOT NULL,
                schema_type VARCHAR(100) NOT NULL,
                tree_structure JSONB NOT NULL,
                node_count INTEGER,
                depth INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(schema_name, schema_type)
            )
        """)

        # è¯­æ³•åˆ†æç»“æœè¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS syntax_analysis (
                id SERIAL PRIMARY KEY,
                schema_name VARCHAR(200) NOT NULL,
                analysis_type VARCHAR(100) NOT NULL,
                analysis_result JSONB NOT NULL,
                validation_status VARCHAR(50),
                errors JSONB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # è¯­ä¹‰æ¨¡å‹è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS semantic_models (
                id SERIAL PRIMARY KEY,
                schema_name VARCHAR(200) NOT NULL,
                domain_definitions JSONB NOT NULL,
                interpretation_functions JSONB NOT NULL,
                validation_status VARCHAR(50),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(schema_name)
            )
        """)

        # åˆ›å»ºç´¢å¼•
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_trees_schema_name
            ON syntax_trees(schema_name)
        """)
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_trees_tree_structure
            ON syntax_trees USING GIN(tree_structure)
        """)

        self.conn.commit()

    def store_syntax_tree(self, schema_name: str, schema_type: str,
                         tree: SyntaxTreeNode):
        """å­˜å‚¨è¯­æ³•æ ‘"""
        tree_dict = self._tree_to_dict(tree)
        node_count = self._count_nodes(tree)
        depth = self._calculate_depth(tree)

        self.cur.execute("""
            INSERT INTO syntax_trees
            (schema_name, schema_type, tree_structure, node_count, depth)
            VALUES (%s, %s, %s::jsonb, %s, %s)
            ON CONFLICT (schema_name, schema_type) DO UPDATE
            SET tree_structure = EXCLUDED.tree_structure,
                node_count = EXCLUDED.node_count,
                depth = EXCLUDED.depth,
                created_at = CURRENT_TIMESTAMP
        """, (schema_name, schema_type, json.dumps(tree_dict),
              node_count, depth))
        self.conn.commit()

    def store_syntax_analysis(self, schema_name: str, analysis_type: str,
                             analysis_result: Dict, validation_status: str,
                             errors: List[str] = None):
        """å­˜å‚¨è¯­æ³•åˆ†æç»“æœ"""
        self.cur.execute("""
            INSERT INTO syntax_analysis
            (schema_name, analysis_type, analysis_result,
             validation_status, errors)
            VALUES (%s, %s, %s::jsonb, %s, %s::jsonb)
        """, (schema_name, analysis_type, json.dumps(analysis_result),
              validation_status, json.dumps(errors) if errors else None))
        self.conn.commit()

    def store_semantic_model(self, schema_name: str,
                            domain_definitions: Dict,
                            interpretation_functions: Dict,
                            validation_status: str = 'valid'):
        """å­˜å‚¨è¯­ä¹‰æ¨¡å‹"""
        self.cur.execute("""
            INSERT INTO semantic_models
            (schema_name, domain_definitions, interpretation_functions,
             validation_status)
            VALUES (%s, %s::jsonb, %s::jsonb, %s)
            ON CONFLICT (schema_name) DO UPDATE
            SET domain_definitions = EXCLUDED.domain_definitions,
                interpretation_functions = EXCLUDED.interpretation_functions,
                validation_status = EXCLUDED.validation_status
        """, (schema_name, json.dumps(domain_definitions),
              json.dumps(interpretation_functions), validation_status))
        self.conn.commit()

    def get_syntax_tree(self, schema_name: str,
                       schema_type: str = None) -> Optional[Dict]:
        """è·å–è¯­æ³•æ ‘"""
        query = "SELECT * FROM syntax_trees WHERE schema_name = %s"
        params = [schema_name]

        if schema_type:
            query += " AND schema_type = %s"
            params.append(schema_type)

        self.cur.execute(query, params)
        row = self.cur.fetchone()
        if row:
            return {
                'id': row[0],
                'schema_name': row[1],
                'schema_type': row[2],
                'tree_structure': row[3],
                'node_count': row[4],
                'depth': row[5],
                'created_at': row[6]
            }
        return None

    def search_similar_trees(self, tree_structure: Dict,
                            similarity_threshold: float = 0.8) -> List[Dict]:
        """æŸ¥æ‰¾ç›¸ä¼¼çš„è¯­æ³•æ ‘ï¼ˆä½¿ç”¨JSONBç›¸ä¼¼åº¦æŸ¥è¯¢ï¼‰"""
        # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„ç›¸ä¼¼åº¦è®¡ç®—
        # å®é™…å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„å›¾ç›¸ä¼¼åº¦ç®—æ³•
        self.cur.execute("""
            SELECT
                schema_name,
                schema_type,
                tree_structure,
                node_count,
                depth
            FROM syntax_trees
            WHERE tree_structure @> %s::jsonb
               OR %s::jsonb @> tree_structure
            LIMIT 10
        """, (json.dumps(tree_structure), json.dumps(tree_structure)))

        results = []
        for row in self.cur.fetchall():
            results.append({
                'schema_name': row[0],
                'schema_type': row[1],
                'tree_structure': row[2],
                'node_count': row[3],
                'depth': row[4]
            })
        return results

    def _tree_to_dict(self, tree: SyntaxTreeNode) -> Dict:
        """å°†è¯­æ³•æ ‘è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'node_type': tree.node_type,
            'value': str(tree.value) if tree.value else None,
            'position': tree.position,
            'children': [self._tree_to_dict(child) for child in tree.children]
        }

    def _count_nodes(self, tree: SyntaxTreeNode) -> int:
        """è®¡ç®—èŠ‚ç‚¹æ•°é‡"""
        count = 1
        for child in tree.children:
            count += self._count_nodes(child)
        return count

    def _calculate_depth(self, tree: SyntaxTreeNode) -> int:
        """è®¡ç®—æ ‘æ·±åº¦"""
        if not tree.children:
            return 1
        return 1 + max(self._calculate_depth(child)
                      for child in tree.children)

    def close(self):
        """å…³é—­è¿æ¥"""
        self.cur.close()
        self.conn.close()
```

### 5.2 è¯­æ³•åˆ†ææŸ¥è¯¢

**é«˜çº§åˆ†ææŸ¥è¯¢**ï¼š

```python
class SyntaxAnalysisQuery:
    """è¯­æ³•åˆ†ææŸ¥è¯¢å™¨"""

    def __init__(self, storage: SyntaxTreeStorage):
        self.storage = storage

    def analyze_tree_statistics(self) -> Dict:
        """åˆ†æè¯­æ³•æ ‘ç»Ÿè®¡ä¿¡æ¯"""
        self.storage.cur.execute("""
            SELECT
                schema_type,
                COUNT(*) as tree_count,
                AVG(node_count) as avg_nodes,
                AVG(depth) as avg_depth,
                MAX(node_count) as max_nodes,
                MAX(depth) as max_depth
            FROM syntax_trees
            GROUP BY schema_type
        """)

        stats = {}
        for row in self.storage.cur.fetchall():
            stats[row[0]] = {
                'tree_count': row[1],
                'avg_nodes': float(row[2]) if row[2] else 0,
                'avg_depth': float(row[3]) if row[3] else 0,
                'max_nodes': row[4],
                'max_depth': row[5]
            }
        return stats

    def find_validation_errors(self) -> List[Dict]:
        """æŸ¥æ‰¾éªŒè¯é”™è¯¯"""
        self.storage.cur.execute("""
            SELECT
                schema_name,
                analysis_type,
                validation_status,
                errors
            FROM syntax_analysis
            WHERE validation_status != 'valid'
            ORDER BY created_at DESC
            LIMIT 50
        """)

        errors = []
        for row in self.storage.cur.fetchall():
            errors.append({
                'schema_name': row[0],
                'analysis_type': row[1],
                'validation_status': row[2],
                'errors': row[3]
            })
        return errors
```

---

## 6. å‚è€ƒæ–‡çŒ®

### 6.1 æŠ€æœ¯æ–‡æ¡£

- å½¢å¼è¯­è¨€ç†è®ºåœ¨ç¨‹åºè½¬æ¢ä¸­çš„åº”ç”¨
- PostgreSQL JSONBæ–‡æ¡£
- è¯­æ³•åˆ†ææœ€ä½³å®è·µ

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `05_Case_Studies.md` - å®è·µæ¡ˆä¾‹

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21ï¼ˆæ‰©å±•è¯­æ³•æ ‘å’Œè¯­ä¹‰æ¨¡å‹å­˜å‚¨åŠŸèƒ½ï¼Œæ–°å¢PostgreSQLå­˜å‚¨æ–¹æ¡ˆï¼‰
