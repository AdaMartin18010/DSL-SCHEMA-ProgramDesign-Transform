#!/usr/bin/env python3
"""
Model Relationship Analyzer
===========================

æ¨¡å‹å…³è”åˆ†æå™¨ï¼Œç”¨äºï¼š
- å‘ç°æ¨¡å‹é—´çš„å…³ç³»
- è®¡ç®—å…³è”å¼ºåº¦
- éªŒè¯å±‚æ¬¡æ˜ å°„
- ç”Ÿæˆå…³è”å›¾è°±

Version: 2.2.0
"""

import json
import re
from collections import defaultdict
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple
import numpy as np


@dataclass
class ModelEntity:
    """æ¨¡å‹å®ä½“"""
    id: str
    name: str
    type: str  # concept, standard, tool, schema
    attributes: Dict = field(default_factory=dict)
    source_file: Optional[str] = None


@dataclass
class Relationship:
    """æ¨¡å‹å…³ç³»"""
    source: str
    target: str
    rel_type: str  # specialization, composition, reference, etc.
    strength: float  # 0-1
    confidence: float  # 0-1
    evidence: List[str] = field(default_factory=list)


@dataclass
class HierarchyLevel:
    """å±‚æ¬¡çº§åˆ«"""
    level: int
    name: str
    description: str
    entities: List[ModelEntity] = field(default_factory=list)


class ModelRelationshipAnalyzer:
    """æ¨¡å‹å…³è”åˆ†æå™¨"""
    
    RELATIONSHIP_TYPES = {
        "specialization": {"symbol": "âŠ‘", "transitive": True, "symmetric": False},
        "composition": {"symbol": "â—¦", "transitive": True, "symmetric": False},
        "reference": {"symbol": "â†’áµ£", "transitive": False, "symmetric": False},
        "association": {"symbol": "~", "transitive": False, "symmetric": True},
        "mapping": {"symbol": "â†’", "transitive": True, "symmetric": False},
        "equivalence": {"symbol": "â‰¡", "transitive": True, "symmetric": True}
    }
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.themes_dir = self.project_root / "themes"
        self.entities: Dict[str, ModelEntity] = {}
        self.relationships: List[Relationship] = []
        self.hierarchy: Dict[int, HierarchyLevel] = {}
    
    def analyze_all_themes(self) -> Dict:
        """åˆ†ææ‰€æœ‰ä¸»é¢˜çš„å…³è”"""
        print("ğŸ” åˆ†æä¸»é¢˜æ¨¡å‹å…³è”...")
        
        # 1. æå–æ‰€æœ‰å®ä½“
        self._extract_entities()
        
        # 2. å‘ç°å…³ç³»
        self._discover_relationships()
        
        # 3. æ„å»ºå±‚æ¬¡ç»“æ„
        self._build_hierarchy()
        
        # 4. ç”ŸæˆæŠ¥å‘Š
        return self._generate_analysis_report()
    
    def _extract_entities(self):
        """ä»ä¸»é¢˜ä¸­æå–å®ä½“"""
        if not self.themes_dir.exists():
            return
        
        for theme_dir in self.themes_dir.iterdir():
            if not theme_dir.is_dir() or not theme_dir.name[0].isdigit():
                continue
            
            theme_name = theme_dir.name
            
            # æå–æ¦‚å¿µ
            concepts_dir = theme_dir / "Concepts"
            if concepts_dir.exists():
                for md_file in concepts_dir.glob("*.md"):
                    entity = ModelEntity(
                        id=f"{theme_name}_concept_{md_file.stem}",
                        name=md_file.stem,
                        type="concept",
                        source_file=str(md_file.relative_to(self.project_root))
                    )
                    self.entities[entity.id] = entity
            
            # æå–æ ‡å‡†
            standards_dir = theme_dir / "Standards"
            if standards_dir.exists():
                for md_file in standards_dir.glob("*.md"):
                    entity = ModelEntity(
                        id=f"{theme_name}_std_{md_file.stem}",
                        name=md_file.stem,
                        type="standard",
                        source_file=str(md_file.relative_to(self.project_root))
                    )
                    self.entities[entity.id] = entity
            
            # æå–å·¥å…·
            tools_dir = theme_dir / "Tools"
            if tools_dir.exists():
                for py_file in tools_dir.glob("*.py"):
                    if py_file.name.startswith("__"):
                        continue
                    entity = ModelEntity(
                        id=f"{theme_name}_tool_{py_file.stem}",
                        name=py_file.stem,
                        type="tool",
                        source_file=str(py_file.relative_to(self.project_root))
                    )
                    self.entities[entity.id] = entity
        
        print(f"  âœ“ æå–äº† {len(self.entities)} ä¸ªå®ä½“")
    
    def _discover_relationships(self):
        """å‘ç°å®ä½“é—´çš„å…³ç³»"""
        entities_list = list(self.entities.values())
        
        for i, e1 in enumerate(entities_list):
            for e2 in entities_list[i+1:]:
                # è®¡ç®—ç›¸ä¼¼åº¦
                similarity = self._calculate_similarity(e1, e2)
                
                if similarity > 0.5:
                    rel_type = self._determine_relationship_type(e1, e2)
                    
                    rel = Relationship(
                        source=e1.id,
                        target=e2.id,
                        rel_type=rel_type,
                        strength=similarity,
                        confidence=min(1.0, similarity * 1.2),
                        evidence=self._find_evidence(e1, e2)
                    )
                    self.relationships.append(rel)
        
        print(f"  âœ“ å‘ç°äº† {len(self.relationships)} ä¸ªå…³ç³»")
    
    def _calculate_similarity(self, e1: ModelEntity, e2: ModelEntity) -> float:
        """è®¡ç®—ä¸¤ä¸ªå®ä½“çš„ç›¸ä¼¼åº¦"""
        scores = []
        
        # 1. åç§°ç›¸ä¼¼åº¦
        name_sim = self._string_similarity(e1.name.lower(), e2.name.lower())
        scores.append(name_sim * 0.4)
        
        # 2. ç±»å‹ç›¸åŒåŠ åˆ†
        if e1.type == e2.type:
            scores.append(0.2)
        
        # 3. æ–‡ä»¶è·¯å¾„ç›¸ä¼¼åº¦
        if e1.source_file and e2.source_file:
            path_sim = self._path_similarity(e1.source_file, e2.source_file)
            scores.append(path_sim * 0.2)
        
        # 4. å…³é”®è¯é‡å 
        keywords1 = set(self._extract_keywords(e1.name))
        keywords2 = set(self._extract_keywords(e2.name))
        if keywords1 and keywords2:
            overlap = len(keywords1 & keywords2) / max(len(keywords1), len(keywords2))
            scores.append(overlap * 0.2)
        
        return sum(scores)
    
    def _string_similarity(self, s1: str, s2: str) -> float:
        """è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ (Jaccard)"""
        if not s1 or not s2:
            return 0.0
        
        # ç”Ÿæˆn-gram
        def ngrams(s, n=2):
            return set(s[i:i+n] for i in range(len(s)-n+1))
        
        g1 = ngrams(s1)
        g2 = ngrams(s2)
        
        intersection = len(g1 & g2)
        union = len(g1 | g2)
        
        return intersection / union if union > 0 else 0.0
    
    def _path_similarity(self, p1: str, p2: str) -> float:
        """è®¡ç®—è·¯å¾„ç›¸ä¼¼åº¦"""
        parts1 = set(Path(p1).parts)
        parts2 = set(Path(p2).parts)
        
        intersection = len(parts1 & parts2)
        union = len(parts1 | parts2)
        
        return intersection / union if union > 0 else 0.0
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–
        words = re.findall(r'[A-Z][a-z]+|[a-z]+', text)
        return [w.lower() for w in words if len(w) > 2]
    
    def _determine_relationship_type(self, e1: ModelEntity, e2: ModelEntity) -> str:
        """ç¡®å®šå…³ç³»ç±»å‹"""
        # åŸºäºå‘½åæ¨¡å¼åˆ¤æ–­
        if e1.name in e2.name or e2.name in e1.name:
            return "specialization"
        
        # åŸºäºæ–‡ä»¶ä½ç½®åˆ¤æ–­
        if e1.source_file and e2.source_file:
            p1 = Path(e1.source_file).parent
            p2 = Path(e2.source_file).parent
            if p1 == p2:
                return "composition"
        
        return "association"
    
    def _find_evidence(self, e1: ModelEntity, e2: ModelEntity) -> List[str]:
        """æŸ¥æ‰¾å…³ç³»è¯æ®"""
        evidence = []
        
        # æ£€æŸ¥æ–‡ä»¶å†…å®¹ä¸­çš„å¼•ç”¨
        if e1.source_file:
            try:
                content = (self.project_root / e1.source_file).read_text(
                    encoding='utf-8', errors='ignore'
                )
                if e2.name.lower() in content.lower():
                    evidence.append(f"{e1.name} å¼•ç”¨äº† {e2.name}")
            except:
                pass
        
        return evidence
    
    def _build_hierarchy(self):
        """æ„å»ºå±‚æ¬¡ç»“æ„"""
        self.hierarchy = {
            1: HierarchyLevel(1, "Foundation", "åŸºç¡€æ•°å­¦å±‚"),
            2: HierarchyLevel(2, "Meta-Model", "å…ƒæ¨¡å‹å±‚"),
            3: HierarchyLevel(3, "Data Model", "æ•°æ®æ¨¡å‹å±‚"),
            4: HierarchyLevel(4, "Service Model", "æœåŠ¡æ¨¡å‹å±‚"),
            5: HierarchyLevel(5, "Application", "åº”ç”¨æ¨¡å‹å±‚")
        }
        
        # å°†å®ä½“åˆ†é…åˆ°å±‚æ¬¡
        for entity in self.entities.values():
            level = self._assign_hierarchy_level(entity)
            self.hierarchy[level].entities.append(entity)
    
    def _assign_hierarchy_level(self, entity: ModelEntity) -> int:
        """åˆ†é…å±‚æ¬¡çº§åˆ«"""
        # åŸºäºå®ä½“ç±»å‹å’Œè·¯å¾„åˆ¤æ–­
        path_lower = entity.source_file.lower() if entity.source_file else ""
        
        if "concept" in path_lower or "theory" in path_lower:
            return 2
        elif "api" in path_lower or "service" in path_lower:
            return 4
        elif "tool" in path_lower:
            return 3
        elif "application" in path_lower or "case" in path_lower:
            return 5
        else:
            return 3
    
    def _generate_analysis_report(self) -> Dict:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = {
            "summary": {
                "total_entities": len(self.entities),
                "total_relationships": len(self.relationships),
                "relationship_types": defaultdict(int),
                "avg_relationship_strength": 0.0
            },
            "hierarchy": {},
            "relationships": [],
            "entity_clusters": []
        }
        
        # ç»Ÿè®¡å…³ç³»ç±»å‹
        strengths = []
        for rel in self.relationships:
            report["summary"]["relationship_types"][rel.rel_type] += 1
            strengths.append(rel.strength)
        
        if strengths:
            report["summary"]["avg_relationship_strength"] = sum(strengths) / len(strengths)
        
        # å±‚æ¬¡ç»Ÿè®¡
        for level, hl in self.hierarchy.items():
            report["hierarchy"][f"L{level}"] = {
                "name": hl.name,
                "entity_count": len(hl.entities)
            }
        
        # å…³ç³»è¯¦æƒ…
        for rel in self.relationships:
            report["relationships"].append({
                "source": self.entities[rel.source].name if rel.source in self.entities else rel.source,
                "target": self.entities[rel.target].name if rel.target in self.entities else rel.target,
                "type": rel.rel_type,
                "symbol": self.RELATIONSHIP_TYPES.get(rel.rel_type, {}).get("symbol", "~"),
                "strength": round(rel.strength, 3),
                "confidence": round(rel.confidence, 3)
            })
        
        # èšç±»
        report["entity_clusters"] = self._cluster_entities()
        
        return report
    
    def _cluster_entities(self) -> List[Dict]:
        """å¯¹å®ä½“è¿›è¡Œèšç±»"""
        # ç®€å•çš„åŸºäºä¸»é¢˜çš„èšç±»
        clusters = defaultdict(list)
        
        for entity in self.entities.values():
            theme = entity.id.split("_")[0]
            clusters[theme].append(entity.name)
        
        return [
            {"theme": theme, "entities": entities}
            for theme, entities in sorted(clusters.items())
        ]
    
    def export_to_graph_json(self, filepath: str):
        """å¯¼å‡ºä¸ºå›¾JSON (ç”¨äºD3.js)"""
        graph = {
            "nodes": [],
            "links": []
        }
        
        # æ·»åŠ èŠ‚ç‚¹
        for entity_id, entity in self.entities.items():
            graph["nodes"].append({
                "id": entity_id,
                "name": entity.name,
                "type": entity.type,
                "group": self._assign_hierarchy_level(entity)
            })
        
        # æ·»åŠ è¾¹
        for rel in self.relationships:
            graph["links"].append({
                "source": rel.source,
                "target": rel.target,
                "type": rel.rel_type,
                "value": rel.strength
            })
        
        Path(filepath).write_text(
            json.dumps(graph, indent=2, ensure_ascii=False),
            encoding='utf-8'
        )
        
        return graph
    
    def export_to_mermaid(self) -> str:
        """å¯¼å‡ºä¸ºMermaidå›¾"""
        lines = ["graph TB"]
        
        # æŒ‰å±‚æ¬¡åˆ†ç»„
        for level, hl in sorted(self.hierarchy.items()):
            if hl.entities:
                lines.append(f"    subgraph L{level} [{hl.name}]")
                for entity in hl.entities:
                    lines.append(f"        {entity.id}[{entity.name}]")
                lines.append("    end")
        
        # æ·»åŠ å…³ç³»
        for rel in self.relationships:
            symbol = self.RELATIONSHIP_TYPES.get(rel.rel_type, {}).get("symbol", "--")
            lines.append(f"    {rel.source} -->|{symbol}| {rel.target}")
        
        return "\n".join(lines)
    
    def find_mapping_path(self, source_id: str, target_id: str) -> Optional[List[str]]:
        """æŸ¥æ‰¾ä¸¤ä¸ªå®ä½“é—´çš„æ˜ å°„è·¯å¾„"""
        # BFSæŸ¥æ‰¾è·¯å¾„
        if source_id not in self.entities or target_id not in self.entities:
            return None
        
        visited = {source_id}
        queue = [(source_id, [source_id])]
        
        while queue:
            current, path = queue.pop(0)
            
            if current == target_id:
                return path
            
            for rel in self.relationships:
                if rel.source == current and rel.target not in visited:
                    visited.add(rel.target)
                    queue.append((rel.target, path + [rel.target]))
                elif rel.target == current and rel.source not in visited:
                    visited.add(rel.source)
                    queue.append((rel.source, path + [rel.source]))
        
        return None


def main():
    """ä¸»å‡½æ•°"""
    analyzer = ModelRelationshipAnalyzer()
    report = analyzer.analyze_all_themes()
    
    print("\nğŸ“Š å…³è”åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    print(f"å®ä½“æ€»æ•°: {report['summary']['total_entities']}")
    print(f"å…³ç³»æ€»æ•°: {report['summary']['total_relationships']}")
    print(f"å¹³å‡å…³ç³»å¼ºåº¦: {report['summary']['avg_relationship_strength']:.3f}")
    
    print("\nğŸ“ å±‚æ¬¡åˆ†å¸ƒ:")
    for level, info in sorted(report['hierarchy'].items()):
        print(f"  L{level} {info['name']}: {info['entity_count']} å®ä½“")
    
    print("\nğŸ”— å…³ç³»ç±»å‹åˆ†å¸ƒ:")
    for rel_type, count in report['summary']['relationship_types'].items():
        print(f"  {rel_type}: {count}")
    
    # å¯¼å‡º
    analyzer.export_to_graph_json("model_relationship_graph.json")
    mermaid = analyzer.export_to_mermaid()
    Path("model_relationship.mmd").write_text(mermaid, encoding='utf-8')
    
    print("\nâœ… å·²å¯¼å‡º:")
    print("  - model_relationship_graph.json")
    print("  - model_relationship.mmd")


if __name__ == "__main__":
    main()
