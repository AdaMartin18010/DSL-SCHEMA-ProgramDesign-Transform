# BPMN Schemaè½¬æ¢ä½“ç³»

## ğŸ“‘ ç›®å½•

- [BPMN Schemaè½¬æ¢ä½“ç³»](#bpmn-schemaè½¬æ¢ä½“ç³»)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. è½¬æ¢ä½“ç³»æ¦‚è¿°](#1-è½¬æ¢ä½“ç³»æ¦‚è¿°)
  - [2. BPMNåˆ°BPELè½¬æ¢](#2-bpmnåˆ°bpelè½¬æ¢)
  - [3. BPMNåˆ°XPDLè½¬æ¢](#3-bpmnåˆ°xpdlè½¬æ¢)
  - [4. è½¬æ¢å·¥å…·](#4-è½¬æ¢å·¥å…·)
  - [5. è½¬æ¢éªŒè¯](#5-è½¬æ¢éªŒè¯)
  - [6. BPMNæ•°æ®å­˜å‚¨ä¸åˆ†æ](#6-bpmnæ•°æ®å­˜å‚¨ä¸åˆ†æ)
    - [6.1 PostgreSQL BPMNæ•°æ®å­˜å‚¨](#61-postgresql-bpmnæ•°æ®å­˜å‚¨)
    - [6.2 BPMNæ•°æ®åˆ†ææŸ¥è¯¢](#62-bpmnæ•°æ®åˆ†ææŸ¥è¯¢)

---

## 1. è½¬æ¢ä½“ç³»æ¦‚è¿°

BPMN Schemaè½¬æ¢ä½“ç³»æ”¯æŒBPMNã€BPELã€
XPDLä¹‹é—´çš„è½¬æ¢ï¼Œä»¥åŠæµç¨‹æ‰§è¡Œæ•°æ®å­˜å‚¨ã€‚

### 1.1 è½¬æ¢ç›®æ ‡

1. **BPMNåˆ°BPELè½¬æ¢**ï¼šä¸šåŠ¡æµç¨‹æ¨¡å‹åˆ°å¯æ‰§è¡Œæµç¨‹
2. **BPMNåˆ°XPDLè½¬æ¢**ï¼šBPMNåˆ°å·¥ä½œæµå®šä¹‰è¯­è¨€
3. **æµç¨‹åˆ°æ•°æ®åº“è½¬æ¢**ï¼šBPMNæµç¨‹åˆ°PostgreSQLå­˜å‚¨

---

## 2. BPMNåˆ°BPELè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- BPMNæµç¨‹ â†’ BPELæµç¨‹
- BPMNä»»åŠ¡ â†’ BPELæ´»åŠ¨
- BPMNç½‘å…³ â†’ BPELæ§åˆ¶æµ
- BPMNäº‹ä»¶ â†’ BPELäº‹ä»¶å¤„ç†

**è½¬æ¢ç¤ºä¾‹**ï¼š

```python
def convert_bpmn_to_bpel(bpmn_process: BPMNProcess) -> BPELProcess:
    """å°†BPMNæµç¨‹è½¬æ¢ä¸ºBPELæµç¨‹"""
    bpel = BPELProcess()

    # è½¬æ¢æµç¨‹åŸºæœ¬ä¿¡æ¯
    bpel.name = bpmn_process.name
    bpel.target_namespace = bpmn_process.namespace

    # è½¬æ¢æµç¨‹å˜é‡
    for var in bpmn_process.variables:
        bpel.variables.append(convert_variable(var))

    # è½¬æ¢æµç¨‹å…ƒç´ 
    bpel.sequence = convert_flow_elements(bpmn_process.elements)

    return bpel

def convert_flow_elements(elements: List[FlowElement]) -> Sequence:
    """è½¬æ¢æµç¨‹å…ƒç´ ä¸ºBPELåºåˆ—"""
    sequence = Sequence()

    for element in elements:
        if isinstance(element, Task):
            sequence.activities.append(convert_task(element))
        elif isinstance(element, Gateway):
            sequence.activities.append(convert_gateway(element))
        elif isinstance(element, Event):
            sequence.activities.append(convert_event(element))

    return sequence
```

---

## 3. BPMNåˆ°XPDLè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- BPMNæµç¨‹ â†’ XPDLå·¥ä½œæµ
- BPMNä»»åŠ¡ â†’ XPDLæ´»åŠ¨
- BPMNç½‘å…³ â†’ XPDLè·¯ç”±
- BPMNäº‹ä»¶ â†’ XPDLäº‹ä»¶

**è½¬æ¢ç¤ºä¾‹**ï¼š

```python
def convert_bpmn_to_xpdl(bpmn_process: BPMNProcess) -> XPDLWorkflow:
    """å°†BPMNæµç¨‹è½¬æ¢ä¸ºXPDLå·¥ä½œæµ"""
    xpdl = XPDLWorkflow()

    # è½¬æ¢å·¥ä½œæµåŸºæœ¬ä¿¡æ¯
    xpdl.workflow_process.id = bpmn_process.id
    xpdl.workflow_process.name = bpmn_process.name

    # è½¬æ¢æ´»åŠ¨
    for element in bpmn_process.elements:
        if isinstance(element, Task):
            activity = XPDLActivity()
            activity.id = element.id
            activity.name = element.name
            activity.activity_type = convert_task_type(element.type)
            xpdl.workflow_process.activities.append(activity)

    # è½¬æ¢è½¬ç§»
    for flow in bpmn_process.sequence_flows:
        transition = XPDLTransition()
        transition.id = flow.id
        transition.from_activity = flow.source_ref
        transition.to_activity = flow.target_ref
        xpdl.workflow_process.transitions.append(transition)

    return xpdl
```

---

## 4. è½¬æ¢å·¥å…·

- **Camunda Modeler**ï¼šBPMNå»ºæ¨¡å’Œè½¬æ¢å·¥å…·
- **Activiti Designer**ï¼šBPMNè®¾è®¡å’Œè½¬æ¢å·¥å…·
- **jBPM**ï¼šä¸šåŠ¡æµç¨‹ç®¡ç†å¹³å°
- **è‡ªå®šä¹‰è½¬æ¢å™¨**ï¼šåŸºäºSchemaçš„è½¬æ¢å™¨

---

## 5. è½¬æ¢éªŒè¯

éªŒè¯è½¬æ¢çš„æµç¨‹å®Œæ•´æ€§ã€è¡Œä¸ºç­‰ä»·æ€§å’Œå¯æ‰§è¡Œæ€§ã€‚

---

## 6. BPMNæ•°æ®å­˜å‚¨ä¸åˆ†æ

### 6.1 PostgreSQL BPMNæ•°æ®å­˜å‚¨

**BPMNæ•°æ®å­˜å‚¨æ–¹æ¡ˆ**ï¼š

```python
import psycopg2
import json
from typing import Dict, List, Optional
from datetime import datetime

class BPMNStorage:
    """BPMNæ•°æ®å­˜å‚¨ç³»ç»Ÿ"""

    def __init__(self, connection_string: str):
        self.conn = psycopg2.connect(connection_string)
        self.cur = self.conn.cursor()
        self._create_tables()

    def _create_tables(self):
        """åˆ›å»ºBPMNæ•°æ®è¡¨"""
        # æµç¨‹å®šä¹‰è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS process_definitions (
                id SERIAL PRIMARY KEY,
                process_id VARCHAR(200) UNIQUE NOT NULL,
                process_name VARCHAR(200) NOT NULL,
                version VARCHAR(50),
                bpmn_xml TEXT NOT NULL,
                metadata JSONB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # æµç¨‹å®ä¾‹è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS process_instances (
                id BIGSERIAL PRIMARY KEY,
                instance_id VARCHAR(200) UNIQUE NOT NULL,
                process_id VARCHAR(200) NOT NULL,
                business_key VARCHAR(200),
                status VARCHAR(50) NOT NULL,
                start_time TIMESTAMP,
                end_time TIMESTAMP,
                variables JSONB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # ä»»åŠ¡å®ä¾‹è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS task_instances (
                id BIGSERIAL PRIMARY KEY,
                task_id VARCHAR(200) UNIQUE NOT NULL,
                instance_id VARCHAR(200) NOT NULL,
                task_name VARCHAR(200) NOT NULL,
                task_type VARCHAR(50) NOT NULL,
                assignee VARCHAR(200),
                candidate_users JSONB,
                candidate_groups JSONB,
                status VARCHAR(50) NOT NULL,
                due_date TIMESTAMP,
                priority INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                completed_at TIMESTAMP
            )
        """)

        # æµç¨‹æ‰§è¡Œå†å²è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS execution_history (
                id BIGSERIAL PRIMARY KEY,
                instance_id VARCHAR(200) NOT NULL,
                element_id VARCHAR(200) NOT NULL,
                element_type VARCHAR(50) NOT NULL,
                action VARCHAR(50) NOT NULL,
                timestamp TIMESTAMP NOT NULL,
                duration_ms BIGINT,
                variables JSONB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # æµç¨‹ç»Ÿè®¡è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS process_statistics (
                id SERIAL PRIMARY KEY,
                process_id VARCHAR(200) NOT NULL,
                statistic_type VARCHAR(50) NOT NULL,
                time_window TIMESTAMP NOT NULL,
                statistics JSONB NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(process_id, statistic_type, time_window)
            )
        """)

        # åˆ›å»ºç´¢å¼•
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_process_instances_status
            ON process_instances(status, created_at DESC)
        """)
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_task_instances_assignee
            ON task_instances(assignee, status)
        """)
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_execution_history_instance
            ON execution_history(instance_id, timestamp DESC)
        """)

        self.conn.commit()

    def store_process_definition(self, process_id: str, process_name: str,
                                 bpmn_xml: str, version: str = "1.0",
                                 metadata: Dict = None):
        """å­˜å‚¨æµç¨‹å®šä¹‰"""
        self.cur.execute("""
            INSERT INTO process_definitions
            (process_id, process_name, version, bpmn_xml, metadata)
            VALUES (%s, %s, %s, %s, %s::jsonb)
            ON CONFLICT (process_id) DO UPDATE
            SET process_name = EXCLUDED.process_name,
                version = EXCLUDED.version,
                bpmn_xml = EXCLUDED.bpmn_xml,
                metadata = EXCLUDED.metadata,
                updated_at = CURRENT_TIMESTAMP
        """, (process_id, process_name, version, bpmn_xml,
              json.dumps(metadata or {})))
        self.conn.commit()

    def calculate_process_statistics(self, process_id: str,
                                    time_window: datetime):
        """è®¡ç®—æµç¨‹ç»Ÿè®¡ä¿¡æ¯"""
        self.cur.execute("""
            SELECT
                COUNT(*) as total_instances,
                COUNT(CASE WHEN status = 'COMPLETED' THEN 1 END) as completed,
                COUNT(CASE WHEN status = 'RUNNING' THEN 1 END) as running,
                COUNT(CASE WHEN status = 'SUSPENDED' THEN 1 END) as suspended,
                AVG(EXTRACT(EPOCH FROM (end_time - start_time))) as avg_duration,
                MIN(EXTRACT(EPOCH FROM (end_time - start_time))) as min_duration,
                MAX(EXTRACT(EPOCH FROM (end_time - start_time))) as max_duration
            FROM process_instances
            WHERE process_id = %s AND created_at >= %s
        """, (process_id, time_window))

        stats = dict(zip([desc[0] for desc in self.cur.description],
                         self.cur.fetchone()))

        # å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
        self.cur.execute("""
            INSERT INTO process_statistics
            (process_id, statistic_type, time_window, statistics)
            VALUES (%s, %s, %s, %s::jsonb)
            ON CONFLICT (process_id, statistic_type, time_window)
            DO UPDATE SET statistics = EXCLUDED.statistics
        """, (process_id, "performance", time_window, json.dumps(stats)))
        self.conn.commit()

        return stats
```

### 6.2 BPMNæ•°æ®åˆ†ææŸ¥è¯¢

**æŸ¥è¯¢ç¤ºä¾‹**ï¼š

```python
# æŸ¥è¯¢æµç¨‹å®ä¾‹
storage.cur.execute("""
    SELECT instance_id, status, start_time, end_time
    FROM process_instances
    WHERE process_id = %s AND created_at >= %s
    ORDER BY created_at DESC
""", (process_id, start_time))

# æŸ¥è¯¢ä»»åŠ¡åˆ†é…ç»Ÿè®¡
storage.cur.execute("""
    SELECT assignee, COUNT(*) as task_count
    FROM task_instances
    WHERE status = 'COMPLETED' AND completed_at >= %s
    GROUP BY assignee
    ORDER BY task_count DESC
""", (start_time,))
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `05_Case_Studies.md` - å®è·µæ¡ˆä¾‹

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
