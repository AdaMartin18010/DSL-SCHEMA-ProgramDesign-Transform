# BPEL Schemaè½¬æ¢ä½“ç³»

## ğŸ“‘ ç›®å½•

- [BPEL Schemaè½¬æ¢ä½“ç³»](#bpel-schemaè½¬æ¢ä½“ç³»)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. è½¬æ¢ä½“ç³»æ¦‚è¿°](#1-è½¬æ¢ä½“ç³»æ¦‚è¿°)
    - [1.1 è½¬æ¢ç›®æ ‡](#11-è½¬æ¢ç›®æ ‡)
  - [2. BPMNåˆ°BPELè½¬æ¢](#2-bpmnåˆ°bpelè½¬æ¢)
  - [3. BPELåˆ°WSDLç”Ÿæˆ](#3-bpelåˆ°wsdlç”Ÿæˆ)
  - [4. è½¬æ¢å·¥å…·](#4-è½¬æ¢å·¥å…·)
  - [5. è½¬æ¢éªŒè¯](#5-è½¬æ¢éªŒè¯)
  - [6. BPELæ•°æ®å­˜å‚¨ä¸åˆ†æ](#6-bpelæ•°æ®å­˜å‚¨ä¸åˆ†æ)
    - [6.1 PostgreSQL BPELæ•°æ®å­˜å‚¨](#61-postgresql-bpelæ•°æ®å­˜å‚¨)
    - [6.2 BPELæ•°æ®åˆ†ææŸ¥è¯¢](#62-bpelæ•°æ®åˆ†ææŸ¥è¯¢)

---

## 1. è½¬æ¢ä½“ç³»æ¦‚è¿°

BPEL Schemaè½¬æ¢ä½“ç³»æ”¯æŒBPMNåˆ°BPELè½¬æ¢ã€
BPELåˆ°WSDLç”Ÿæˆï¼Œä»¥åŠæµç¨‹æ‰§è¡Œæ•°æ®å­˜å‚¨ã€‚

### 1.1 è½¬æ¢ç›®æ ‡

1. **BPMNåˆ°BPELè½¬æ¢**ï¼šä¸šåŠ¡æµç¨‹æ¨¡å‹åˆ°å¯æ‰§è¡Œæµç¨‹
2. **BPELåˆ°WSDLç”Ÿæˆ**ï¼šBPELæµç¨‹åˆ°WebæœåŠ¡æè¿°
3. **æµç¨‹åˆ°æ•°æ®åº“è½¬æ¢**ï¼šBPELæµç¨‹åˆ°PostgreSQLå­˜å‚¨

---

## 2. BPMNåˆ°BPELè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- BPMNæµç¨‹ â†’ BPELæµç¨‹
- BPMNä»»åŠ¡ â†’ BPELæ´»åŠ¨
- BPMNç½‘å…³ â†’ BPELæ§åˆ¶æµ
- BPMNäº‹ä»¶ â†’ BPELäº‹ä»¶å¤„ç†

**è½¬æ¢ç¤ºä¾‹**ï¼š

```python
def convert_bpmn_to_bpel(bpmn_process: BPMNProcess) -> BPELProcess:
    """å°†BPMNæµç¨‹è½¬æ¢ä¸ºBPELæµç¨‹"""
    bpel = BPELProcess()

    # è½¬æ¢æµç¨‹åŸºæœ¬ä¿¡æ¯
    bpel.name = bpmn_process.name
    bpel.target_namespace = bpmn_process.namespace

    # è½¬æ¢åˆä½œä¼™ä¼´é“¾æ¥
    for participant in bpmn_process.participants:
        partner_link = PartnerLink()
        partner_link.name = participant.id
        partner_link.partner_link_type = f"{participant.id}Type"
        bpel.partner_links.append(partner_link)

    # è½¬æ¢æµç¨‹å˜é‡
    for var in bpmn_process.variables:
        bpel_var = Variable()
        bpel_var.name = var.name
        bpel_var.message_type = var.type
        bpel.variables.append(bpel_var)

    # è½¬æ¢æµç¨‹æ´»åŠ¨
    bpel.activities = convert_flow_elements(bpmn_process.elements)

    return bpel

def convert_flow_elements(elements: List[FlowElement]) -> Activity:
    """è½¬æ¢æµç¨‹å…ƒç´ ä¸ºBPELæ´»åŠ¨"""
    if len(elements) == 1:
        return convert_single_element(elements[0])

    # å¤šä¸ªå…ƒç´ è½¬æ¢ä¸ºåºåˆ—
    sequence = Sequence()
    for element in elements:
        sequence.activities.append(convert_single_element(element))
    return sequence

def convert_single_element(element: FlowElement) -> Activity:
    """è½¬æ¢å•ä¸ªæµç¨‹å…ƒç´ """
    if isinstance(element, UserTask):
        # ç”¨æˆ·ä»»åŠ¡è½¬æ¢ä¸ºæ¥æ”¶å’Œå›å¤
        receive = Receive()
        receive.partner_link = element.assignee
        receive.operation = f"{element.id}Operation"
        receive.variable = f"{element.id}Input"

        reply = Reply()
        reply.partner_link = element.assignee
        reply.operation = f"{element.id}Operation"
        reply.variable = f"{element.id}Output"

        sequence = Sequence()
        sequence.activities.append(receive)
        sequence.activities.append(reply)
        return sequence

    elif isinstance(element, ServiceTask):
        # æœåŠ¡ä»»åŠ¡è½¬æ¢ä¸ºè°ƒç”¨
        invoke = Invoke()
        invoke.partner_link = element.implementation
        invoke.operation = element.operation_ref
        invoke.input_variable = f"{element.id}Input"
        invoke.output_variable = f"{element.id}Output"
        return invoke

    elif isinstance(element, ExclusiveGateway):
        # æ’ä»–ç½‘å…³è½¬æ¢ä¸ºé€‰æ‹©
        if_activity = If()
        if_activity.condition = element.sequence_flows[0].condition_expression
        if_activity.then = convert_flow_elements([element.sequence_flows[0].target_ref])
        if len(element.sequence_flows) > 1:
            if_activity.else_activity = convert_flow_elements([element.sequence_flows[1].target_ref])
        return if_activity

    elif isinstance(element, ParallelGateway):
        # å¹¶è¡Œç½‘å…³è½¬æ¢ä¸ºæµ
        flow = Flow()
        for seq_flow in element.outgoing_flows:
            flow.activities.append(convert_flow_elements([seq_flow.target_ref]))
        return flow

    return Empty()
```

---

## 3. BPELåˆ°WSDLç”Ÿæˆ

**ç”Ÿæˆè§„åˆ™**ï¼š

- BPELæµç¨‹ â†’ WSDLå®šä¹‰
- BPELåˆä½œä¼™ä¼´é“¾æ¥ â†’ WSDLç«¯å£ç±»å‹
- BPELæ“ä½œ â†’ WSDLæ“ä½œ

**ç”Ÿæˆç¤ºä¾‹**ï¼š

```python
def generate_wsdl_from_bpel(bpel_process: BPELProcess) -> WSDLDefinition:
    """ä»BPELæµç¨‹ç”ŸæˆWSDLå®šä¹‰"""
    wsdl = WSDLDefinition()
    wsdl.target_namespace = bpel_process.target_namespace

    # ç”Ÿæˆç«¯å£ç±»å‹
    for partner_link in bpel_process.partner_links:
        port_type = PortType()
        port_type.name = f"{partner_link.name}PortType"

        # æŸ¥æ‰¾ç›¸å…³çš„æ¥æ”¶å’Œå›å¤æ´»åŠ¨
        for activity in find_activities(bpel_process.activities):
            if isinstance(activity, Receive) and activity.partner_link == partner_link.name:
                operation = Operation()
                operation.name = activity.operation
                operation.input = Message()
                operation.input.message = activity.variable
                port_type.operations.append(operation)

            elif isinstance(activity, Reply) and activity.partner_link == partner_link.name:
                # æŸ¥æ‰¾å¯¹åº”çš„æ“ä½œå¹¶æ·»åŠ è¾“å‡º
                for op in port_type.operations:
                    if op.name == activity.operation:
                        op.output = Message()
                        op.output.message = activity.variable

        wsdl.port_types.append(port_type)

    return wsdl
```

---

## 4. è½¬æ¢å·¥å…·

- **Apache ODE**ï¼šBPELæ‰§è¡Œå¼•æ“å’Œè½¬æ¢å·¥å…·
- **ActiveVOS**ï¼šBPELè®¾è®¡å’Œè½¬æ¢å·¥å…·
- **Oracle BPEL Process Manager**ï¼šOracle BPELå¹³å°
- **è‡ªå®šä¹‰è½¬æ¢å™¨**ï¼šåŸºäºSchemaçš„è½¬æ¢å™¨

---

## 5. è½¬æ¢éªŒè¯

éªŒè¯è½¬æ¢çš„æµç¨‹å®Œæ•´æ€§ã€è¡Œä¸ºç­‰ä»·æ€§å’Œå¯æ‰§è¡Œæ€§ã€‚

---

## 6. BPELæ•°æ®å­˜å‚¨ä¸åˆ†æ

### 6.1 PostgreSQL BPELæ•°æ®å­˜å‚¨

**BPELæ•°æ®å­˜å‚¨æ–¹æ¡ˆ**ï¼š

```python
import psycopg2
import json
from typing import Dict, List, Optional
from datetime import datetime

class BPELStorage:
    """BPELæ•°æ®å­˜å‚¨ç³»ç»Ÿ"""

    def __init__(self, connection_string: str):
        self.conn = psycopg2.connect(connection_string)
        self.cur = self.conn.cursor()
        self._create_tables()

    def _create_tables(self):
        """åˆ›å»ºBPELæ•°æ®è¡¨"""
        # æµç¨‹å®šä¹‰è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS bpel_process_definitions (
                id SERIAL PRIMARY KEY,
                process_id VARCHAR(200) UNIQUE NOT NULL,
                process_name VARCHAR(200) NOT NULL,
                target_namespace VARCHAR(500),
                bpel_xml TEXT NOT NULL,
                metadata JSONB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # æµç¨‹å®ä¾‹è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS bpel_process_instances (
                id BIGSERIAL PRIMARY KEY,
                instance_id VARCHAR(200) UNIQUE NOT NULL,
                process_id VARCHAR(200) NOT NULL,
                status VARCHAR(50) NOT NULL,
                start_time TIMESTAMP,
                end_time TIMESTAMP,
                variables JSONB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # æ´»åŠ¨æ‰§è¡Œå†å²è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS bpel_activity_execution (
                id BIGSERIAL PRIMARY KEY,
                instance_id VARCHAR(200) NOT NULL,
                activity_id VARCHAR(200) NOT NULL,
                activity_type VARCHAR(50) NOT NULL,
                status VARCHAR(50) NOT NULL,
                start_time TIMESTAMP,
                end_time TIMESTAMP,
                input_data JSONB,
                output_data JSONB,
                fault_data JSONB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # æœåŠ¡è°ƒç”¨è®°å½•è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS bpel_service_calls (
                id BIGSERIAL PRIMARY KEY,
                instance_id VARCHAR(200) NOT NULL,
                activity_id VARCHAR(200) NOT NULL,
                partner_link VARCHAR(200) NOT NULL,
                operation VARCHAR(200) NOT NULL,
                call_type VARCHAR(50) NOT NULL,
                request_data JSONB,
                response_data JSONB,
                duration_ms BIGINT,
                status VARCHAR(50),
                error_message TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # æµç¨‹ç»Ÿè®¡è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS bpel_process_statistics (
                id SERIAL PRIMARY KEY,
                process_id VARCHAR(200) NOT NULL,
                statistic_type VARCHAR(50) NOT NULL,
                time_window TIMESTAMP NOT NULL,
                statistics JSONB NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(process_id, statistic_type, time_window)
            )
        """)

        # åˆ›å»ºç´¢å¼•
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_bpel_instances_status
            ON bpel_process_instances(status, created_at DESC)
        """)
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_bpel_activity_instance
            ON bpel_activity_execution(instance_id, start_time DESC)
        """)
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_bpel_service_calls_partner
            ON bpel_service_calls(partner_link, operation, created_at DESC)
        """)

        self.conn.commit()

    def store_process_definition(self, process_id: str, process_name: str,
                                 bpel_xml: str, target_namespace: str = None,
                                 metadata: Dict = None):
        """å­˜å‚¨æµç¨‹å®šä¹‰"""
        self.cur.execute("""
            INSERT INTO bpel_process_definitions
            (process_id, process_name, target_namespace, bpel_xml, metadata)
            VALUES (%s, %s, %s, %s, %s::jsonb)
            ON CONFLICT (process_id) DO UPDATE
            SET process_name = EXCLUDED.process_name,
                target_namespace = EXCLUDED.target_namespace,
                bpel_xml = EXCLUDED.bpel_xml,
                metadata = EXCLUDED.metadata,
                updated_at = CURRENT_TIMESTAMP
        """, (process_id, process_name, target_namespace, bpel_xml,
              json.dumps(metadata or {})))
        self.conn.commit()

    def record_service_call(self, instance_id: str, activity_id: str,
                           partner_link: str, operation: str,
                           call_type: str, request_data: Dict,
                           response_data: Dict = None, duration_ms: int = None,
                           status: str = "SUCCESS", error_message: str = None):
        """è®°å½•æœåŠ¡è°ƒç”¨"""
        self.cur.execute("""
            INSERT INTO bpel_service_calls
            (instance_id, activity_id, partner_link, operation, call_type,
             request_data, response_data, duration_ms, status, error_message)
            VALUES (%s, %s, %s, %s, %s, %s::jsonb, %s::jsonb, %s, %s, %s)
        """, (instance_id, activity_id, partner_link, operation, call_type,
              json.dumps(request_data), json.dumps(response_data or {}),
              duration_ms, status, error_message))
        self.conn.commit()

    def calculate_process_statistics(self, process_id: str,
                                    time_window: datetime):
        """è®¡ç®—æµç¨‹ç»Ÿè®¡ä¿¡æ¯"""
        self.cur.execute("""
            SELECT
                COUNT(*) as total_instances,
                COUNT(CASE WHEN status = 'COMPLETED' THEN 1 END) as completed,
                COUNT(CASE WHEN status = 'RUNNING' THEN 1 END) as running,
                COUNT(CASE WHEN status = 'FAULTED' THEN 1 END) as faulted,
                AVG(EXTRACT(EPOCH FROM (end_time - start_time))) as avg_duration,
                MIN(EXTRACT(EPOCH FROM (end_time - start_time))) as min_duration,
                MAX(EXTRACT(EPOCH FROM (end_time - start_time))) as max_duration
            FROM bpel_process_instances
            WHERE process_id = %s AND created_at >= %s
        """, (process_id, time_window))

        stats = dict(zip([desc[0] for desc in self.cur.description],
                         self.cur.fetchone()))

        # æœåŠ¡è°ƒç”¨ç»Ÿè®¡
        self.cur.execute("""
            SELECT
                partner_link,
                operation,
                COUNT(*) as call_count,
                AVG(duration_ms) as avg_duration_ms,
                COUNT(CASE WHEN status = 'SUCCESS' THEN 1 END) as success_count,
                COUNT(CASE WHEN status = 'FAILED' THEN 1 END) as failed_count
            FROM bpel_service_calls
            WHERE instance_id IN (
                SELECT instance_id FROM bpel_process_instances
                WHERE process_id = %s AND created_at >= %s
            )
            GROUP BY partner_link, operation
        """, (process_id, time_window))

        service_stats = []
        for row in self.cur.fetchall():
            service_stats.append({
                'partner_link': row[0],
                'operation': row[1],
                'call_count': row[2],
                'avg_duration_ms': row[3],
                'success_count': row[4],
                'failed_count': row[5]
            })

        stats['service_calls'] = service_stats

        # å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
        self.cur.execute("""
            INSERT INTO bpel_process_statistics
            (process_id, statistic_type, time_window, statistics)
            VALUES (%s, %s, %s, %s::jsonb)
            ON CONFLICT (process_id, statistic_type, time_window)
            DO UPDATE SET statistics = EXCLUDED.statistics
        """, (process_id, "performance", time_window, json.dumps(stats)))
        self.conn.commit()

        return stats
```

### 6.2 BPELæ•°æ®åˆ†ææŸ¥è¯¢

**æŸ¥è¯¢ç¤ºä¾‹**ï¼š

```python
# æŸ¥è¯¢æµç¨‹å®ä¾‹
storage.cur.execute("""
    SELECT instance_id, status, start_time, end_time
    FROM bpel_process_instances
    WHERE process_id = %s AND created_at >= %s
    ORDER BY created_at DESC
""", (process_id, start_time))

# æŸ¥è¯¢æœåŠ¡è°ƒç”¨ç»Ÿè®¡
storage.cur.execute("""
    SELECT partner_link, operation, COUNT(*) as call_count,
           AVG(duration_ms) as avg_duration
    FROM bpel_service_calls
    WHERE created_at >= %s
    GROUP BY partner_link, operation
    ORDER BY call_count DESC
""", (start_time,))
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `05_Case_Studies.md` - å®è·µæ¡ˆä¾‹

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
