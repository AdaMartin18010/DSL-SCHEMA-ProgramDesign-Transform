# å¯è§‚æµ‹æ€§å®è·µæ¡ˆä¾‹

## ğŸ“‘ ç›®å½•

- [å¯è§‚æµ‹æ€§å®è·µæ¡ˆä¾‹](#å¯è§‚æµ‹æ€§å®è·µæ¡ˆä¾‹)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¡ˆä¾‹æ¦‚è¿°](#1-æ¡ˆä¾‹æ¦‚è¿°)
  - [2. æ¡ˆä¾‹1ï¼šä¼ä¸šçº§å¯è§‚æµ‹æ€§å¹³å°å»ºè®¾](#2-æ¡ˆä¾‹1ä¼ä¸šçº§å¯è§‚æµ‹æ€§å¹³å°å»ºè®¾)
    - [2.1 ä¼ä¸šèƒŒæ™¯](#21-ä¼ä¸šèƒŒæ™¯)
    - [2.2 ä¸šåŠ¡ç—›ç‚¹](#22-ä¸šåŠ¡ç—›ç‚¹)
    - [2.3 ä¸šåŠ¡ç›®æ ‡](#23-ä¸šåŠ¡ç›®æ ‡)
    - [2.4 æŠ€æœ¯æŒ‘æˆ˜](#24-æŠ€æœ¯æŒ‘æˆ˜)
    - [2.5 è§£å†³æ–¹æ¡ˆ](#25-è§£å†³æ–¹æ¡ˆ)
    - [2.6 å®Œæ•´ä»£ç å®ç°](#26-å®Œæ•´ä»£ç å®ç°)
    - [2.7 æ•ˆæœè¯„ä¼°](#27-æ•ˆæœè¯„ä¼°)
  - [3. æ¡ˆä¾‹æ€»ç»“](#3-æ¡ˆä¾‹æ€»ç»“)
  - [4. å‚è€ƒæ–‡çŒ®](#4-å‚è€ƒæ–‡çŒ®)

---

## 1. æ¡ˆä¾‹æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›å¯è§‚æµ‹æ€§ï¼ˆObservabilityï¼‰åœ¨å®é™…ä¼ä¸šåº”ç”¨ä¸­çš„å®è·µæ¡ˆä¾‹ï¼Œæ¶µç›–æ—¥å¿—ã€æŒ‡æ ‡ã€è¿½è¸ªä¸‰å¤§æ”¯æŸ±çš„ç»Ÿä¸€å¹³å°å»ºè®¾ã€‚

**å‚è€ƒä¼ä¸šæ¡ˆä¾‹**ï¼š

- **Netflix**ï¼šå¤§è§„æ¨¡åˆ†å¸ƒå¼ç³»ç»Ÿå¯è§‚æµ‹æ€§
- **Uber**ï¼šå¾®æœåŠ¡å¯è§‚æµ‹æ€§å®è·µ
- **Shopify**ï¼šäº‘åŸç”Ÿå¯è§‚æµ‹æ€§å¹³å°

---

## 2. æ¡ˆä¾‹1ï¼šä¼ä¸šçº§å¯è§‚æµ‹æ€§å¹³å°å»ºè®¾

### 2.1 ä¼ä¸šèƒŒæ™¯

**ä¼ä¸šåç§°**ï¼šæŸé‡‘èç§‘æŠ€å…¬å¸ï¼ˆFinTech Proï¼‰

**ä¼ä¸šè§„æ¨¡**ï¼š
- å‘˜å·¥äººæ•°ï¼š6000+
- ç ”å‘å›¢é˜Ÿï¼š2000äºº
- å¾®æœåŠ¡æ•°é‡ï¼š600+
- Kubernetesé›†ç¾¤ï¼š15ä¸ª
- æ—¥å¤„ç†äº¤æ˜“é‡ï¼š10äº¿+
- æ—¥å¿—é‡ï¼š50TB/å¤©

**æŠ€æœ¯æ ˆ**ï¼š
- å®¹å™¨ç¼–æ’ï¼šKubernetes
- ç¼–ç¨‹è¯­è¨€ï¼šJava, Go, Python, Node.js
- æ¶ˆæ¯é˜Ÿåˆ—ï¼šKafka
- æ•°æ®åº“ï¼šPostgreSQL, MongoDB, Redis
- åŸºç¡€è®¾æ–½ï¼šæ··åˆäº‘

### 2.2 ä¸šåŠ¡ç—›ç‚¹

1. **ç›‘æ§æ•°æ®å­¤å²›**ï¼šæ—¥å¿—ã€æŒ‡æ ‡ã€è¿½è¸ªæ•°æ®åˆ†æ•£åœ¨ä¸åŒç³»ç»Ÿï¼Œæ— æ³•å…³è”åˆ†æ
2. **æ•…éšœå®šä½æ…¢**ï¼šå¹³å‡æ•…éšœå®šä½æ—¶é—´ï¼ˆMTTRï¼‰è¶…è¿‡2å°æ—¶
3. **å‘Šè­¦é£æš´**ï¼šç¼ºä¹æ™ºèƒ½å‘Šè­¦ï¼Œå‘Šè­¦è¿‡å¤šå¯¼è‡´å›¢é˜Ÿç–²åŠ³
4. **å­˜å‚¨æˆæœ¬é«˜**ï¼šæ—¥å¿—å’ŒæŒ‡æ ‡å­˜å‚¨æˆæœ¬é«˜æ˜‚
5. **æ•°æ®æŸ¥è¯¢æ…¢**ï¼šå¤§è§„æ¨¡æ•°æ®æŸ¥è¯¢å“åº”æ…¢ï¼Œå½±å“æ’éšœæ•ˆç‡

### 2.3 ä¸šåŠ¡ç›®æ ‡

1. **ç»Ÿä¸€å¯è§‚æµ‹æ€§å¹³å°**ï¼šæ•´åˆæ—¥å¿—ã€æŒ‡æ ‡ã€è¿½è¸ªä¸‰å¤§æ”¯æŸ±
2. **é™ä½MTTR**ï¼šå°†æ•…éšœå®šä½æ—¶é—´ä»2å°æ—¶é™ä½åˆ°15åˆ†é’Ÿ
3. **æ™ºèƒ½å‘Šè­¦**ï¼šå®ç°å‘Šè­¦é™å™ªï¼Œå‡å°‘90%æ— æ•ˆå‘Šè­¦
4. **é™ä½å­˜å‚¨æˆæœ¬**ï¼šé€šè¿‡æ•°æ®å‹ç¼©å’Œé‡‡æ ·é™ä½50%å­˜å‚¨æˆæœ¬
5. **å®æ—¶æŸ¥è¯¢**ï¼šå®ç°ç§’çº§å¤§è§„æ¨¡æ•°æ®æŸ¥è¯¢å“åº”

### 2.4 æŠ€æœ¯æŒ‘æˆ˜

1. **æ•°æ®é‡å·¨å¤§**ï¼šæ¯å¤©50TBæ—¥å¿—æ•°æ®ï¼Œéœ€è¦é«˜æ•ˆé‡‡é›†å’Œå­˜å‚¨
2. **å¤šè¯­è¨€æ”¯æŒ**ï¼šéœ€è¦æ”¯æŒJavaã€Goã€Pythonç­‰å¤šç§è¯­è¨€çš„SDK
3. **è·¨é›†ç¾¤é‡‡é›†**ï¼š15ä¸ªé›†ç¾¤çš„æ•°æ®éœ€è¦ç»Ÿä¸€é‡‡é›†
4. **æˆæœ¬æ§åˆ¶**ï¼šåœ¨æ»¡è¶³éœ€æ±‚çš„åŒæ—¶æ§åˆ¶æˆæœ¬
5. **é«˜å¯ç”¨æ€§**ï¼šå¯è§‚æµ‹æ€§å¹³å°æœ¬èº«éœ€è¦é«˜å¯ç”¨

### 2.5 è§£å†³æ–¹æ¡ˆ

**æ¶æ„è®¾è®¡**ï¼š

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Observability Platform Architecture                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                     Data Collection Layer                     â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  OpenTelemetryâ”‚  â”‚ Prometheus  â”‚  â”‚    Fluent Bit       â”‚   â”‚  â”‚
â”‚  â”‚  â”‚   Collector â”‚  â”‚   Server    â”‚  â”‚   (Log Collector)   â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                     Message Queue (Kafka)                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                     Storage Layer                             â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  ClickHouse â”‚  â”‚  Victoria   â”‚  â”‚    MinIO/S3         â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  (Logs)     â”‚  â”‚  Metrics    â”‚  â”‚    (Long-term)      â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚  â”‚
â”‚  â”‚  â”‚   Jaeger    â”‚  â”‚   Tempo     â”‚                              â”‚  â”‚
â”‚  â”‚  â”‚  (Traces)   â”‚  â”‚  (Traces)   â”‚                              â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                     Visualization Layer                       â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚   Grafana   â”‚  â”‚  AlertManagerâ”‚  â”‚    Custom UI        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚                     â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ ¸å¿ƒç»„ä»¶**ï¼š

1. **OpenTelemetry Collector**ï¼šç»Ÿä¸€æ•°æ®é‡‡é›†
2. **Kafka**ï¼šæ•°æ®ç¼“å†²å’Œè§£è€¦
3. **ClickHouse**ï¼šé«˜æ€§èƒ½æ—¥å¿—å­˜å‚¨å’ŒæŸ¥è¯¢
4. **VictoriaMetrics**ï¼šé«˜æ€§èƒ½æŒ‡æ ‡å­˜å‚¨
5. **Jaeger/Tempo**ï¼šåˆ†å¸ƒå¼è¿½è¸ª
6. **Grafana**ï¼šç»Ÿä¸€å¯è§†åŒ–
7. **AlertManager**ï¼šå‘Šè­¦ç®¡ç†

### 2.6 å®Œæ•´ä»£ç å®ç°

**å¯è§‚æµ‹æ€§å¹³å°ç®¡ç†Pythonå·¥å…·**ï¼š

```python
#!/usr/bin/env python3
"""
ä¼ä¸šçº§å¯è§‚æµ‹æ€§å¹³å°ç®¡ç†å·¥å…·
æ”¯æŒæ—¥å¿—é‡‡é›†ã€æŒ‡æ ‡æ”¶é›†ã€é“¾è·¯è¿½è¸ªã€å‘Šè­¦ç®¡ç†ç­‰åŠŸèƒ½
"""

import json
import time
import logging
import requests
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
import hashlib
import zlib


class LogLevel(Enum):
    """æ—¥å¿—çº§åˆ«"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


class MetricType(Enum):
    """æŒ‡æ ‡ç±»å‹"""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    SUMMARY = "summary"


@dataclass
class LogEntry:
    """æ—¥å¿—æ¡ç›®"""
    timestamp: datetime
    service: str
    level: LogLevel
    message: str
    trace_id: Optional[str] = None
    span_id: Optional[str] = None
    attributes: Optional[Dict] = None


@dataclass
class MetricPoint:
    """æŒ‡æ ‡æ•°æ®ç‚¹"""
    name: str
    value: float
    timestamp: datetime
    labels: Dict[str, str]
    metric_type: MetricType


@dataclass
class TraceSpan:
    """è¿½è¸ªSpan"""
    trace_id: str
    span_id: str
    parent_span_id: Optional[str]
    service: str
    operation: str
    start_time: datetime
    end_time: datetime
    tags: Dict[str, str]
    logs: List[Dict]


class ObservabilityCollector:
    """å¯è§‚æµ‹æ€§æ•°æ®é‡‡é›†å™¨"""

    def __init__(self, config: Dict):
        """
        åˆå§‹åŒ–é‡‡é›†å™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.logger = self._setup_logger()
        self.batch_size = config.get('batch_size', 100)
        self.flush_interval = config.get('flush_interval', 5)
        
        # æ‰¹å¤„ç†ç¼“å†²åŒº
        self.log_buffer: List[LogEntry] = []
        self.metric_buffer: List[MetricPoint] = []
        self.trace_buffer: List[TraceSpan] = []
        
        # é‡‡æ ·é…ç½®
        self.log_sample_rate = config.get('log_sample_rate', 1.0)
        self.trace_sample_rate = config.get('trace_sample_rate', 0.1)

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger('ObservabilityCollector')
        logger.setLevel(logging.INFO)
        
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
        
        return logger

    def _should_sample(self, rate: float) -> bool:
        """æ ¹æ®é‡‡æ ·ç‡å†³å®šæ˜¯å¦é‡‡æ ·"""
        import random
        return random.random() < rate

    def collect_log(
        self,
        service: str,
        level: LogLevel,
        message: str,
        trace_id: Optional[str] = None,
        span_id: Optional[str] = None,
        attributes: Optional[Dict] = None
    ):
        """
        é‡‡é›†æ—¥å¿—
        
        Args:
            service: æœåŠ¡åç§°
            level: æ—¥å¿—çº§åˆ«
            message: æ—¥å¿—æ¶ˆæ¯
            trace_id: è¿½è¸ªID
            span_id: Span ID
            attributes: é™„åŠ å±æ€§
        """
        # é‡‡æ ·æ£€æŸ¥
        if not self._should_sample(self.log_sample_rate):
            return
        
        log_entry = LogEntry(
            timestamp=datetime.now(),
            service=service,
            level=level,
            message=message,
            trace_id=trace_id,
            span_id=span_id,
            attributes=attributes or {}
        )
        
        self.log_buffer.append(log_entry)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°
        if len(self.log_buffer) >= self.batch_size:
            self._flush_logs()

    def collect_metric(
        self,
        name: str,
        value: float,
        labels: Dict[str, str],
        metric_type: MetricType = MetricType.GAUGE
    ):
        """
        é‡‡é›†æŒ‡æ ‡
        
        Args:
            name: æŒ‡æ ‡åç§°
            value: æŒ‡æ ‡å€¼
            labels: æ ‡ç­¾
            metric_type: æŒ‡æ ‡ç±»å‹
        """
        metric_point = MetricPoint(
            name=name,
            value=value,
            timestamp=datetime.now(),
            labels=labels,
            metric_type=metric_type
        )
        
        self.metric_buffer.append(metric_point)
        
        if len(self.metric_buffer) >= self.batch_size:
            self._flush_metrics()

    def collect_trace(self, span: TraceSpan):
        """
        é‡‡é›†è¿½è¸ªæ•°æ®
        
        Args:
            span: Trace Span
        """
        # é‡‡æ ·æ£€æŸ¥
        if not self._should_sample(self.trace_sample_rate):
            return
        
        self.trace_buffer.append(span)
        
        if len(self.trace_buffer) >= self.batch_size:
            self._flush_traces()

    def _compress_data(self, data: str) -> bytes:
        """å‹ç¼©æ•°æ®"""
        return zlib.compress(data.encode('utf-8'))

    def _flush_logs(self):
        """åˆ·æ–°æ—¥å¿—ç¼“å†²åŒº"""
        if not self.log_buffer:
            return
        
        self.logger.debug(f"åˆ·æ–° {len(self.log_buffer)} æ¡æ—¥å¿—")
        
        # è½¬æ¢ä¸ºJSON
        logs_data = [
            {
                'timestamp': log.timestamp.isoformat(),
                'service': log.service,
                'level': log.level.value,
                'message': log.message,
                'trace_id': log.trace_id,
                'span_id': log.span_id,
                'attributes': log.attributes
            }
            for log in self.log_buffer
        ]
        
        # å‘é€åˆ°å­˜å‚¨
        self._send_to_storage('logs', logs_data)
        
        # æ¸…ç©ºç¼“å†²åŒº
        self.log_buffer = []

    def _flush_metrics(self):
        """åˆ·æ–°æŒ‡æ ‡ç¼“å†²åŒº"""
        if not self.metric_buffer:
            return
        
        self.logger.debug(f"åˆ·æ–° {len(self.metric_buffer)} ä¸ªæŒ‡æ ‡")
        
        # è½¬æ¢ä¸ºPrometheusæ ¼å¼
        metrics_data = []
        for metric in self.metric_buffer:
            labels_str = ','.join([f'{k}="{v}"' for k, v in metric.labels.items()])
            metrics_data.append({
                'name': metric.name,
                'value': metric.value,
                'timestamp': metric.timestamp.timestamp(),
                'labels': labels_str,
                'type': metric.metric_type.value
            })
        
        self._send_to_storage('metrics', metrics_data)
        self.metric_buffer = []

    def _flush_traces(self):
        """åˆ·æ–°è¿½è¸ªç¼“å†²åŒº"""
        if not self.trace_buffer:
            return
        
        self.logger.debug(f"åˆ·æ–° {len(self.trace_buffer)} ä¸ªè¿½è¸ªSpan")
        
        # è½¬æ¢ä¸ºJaegeræ ¼å¼
        traces_data = [
            {
                'trace_id': span.trace_id,
                'span_id': span.span_id,
                'parent_span_id': span.parent_span_id,
                'service': span.service,
                'operation': span.operation,
                'start_time': span.start_time.isoformat(),
                'duration_ms': (span.end_time - span.start_time).total_seconds() * 1000,
                'tags': span.tags,
                'logs': span.logs
            }
            for span in self.trace_buffer
        ]
        
        self._send_to_storage('traces', traces_data)
        self.trace_buffer = []

    def _send_to_storage(self, data_type: str, data: List[Dict]):
        """å‘é€æ•°æ®åˆ°å­˜å‚¨"""
        # è¿™é‡Œå®ç°å®é™…çš„å‘é€é€»è¾‘
        # å¯ä»¥å‘é€åˆ°Kafkaã€ClickHouseç­‰
        pass

    def flush_all(self):
        """åˆ·æ–°æ‰€æœ‰ç¼“å†²åŒº"""
        self._flush_logs()
        self._flush_metrics()
        self._flush_traces()


class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""

    def __init__(self, config: Dict):
        """
        åˆå§‹åŒ–å‘Šè­¦ç®¡ç†å™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.alert_rules: List[Dict] = []
        self.alert_history: List[Dict] = []
        self.silence_windows: Dict[str, datetime] = {}

    def add_alert_rule(
        self,
        name: str,
        condition: str,
        duration: int,
        severity: str,
        labels: Dict[str, str],
        annotations: Dict[str, str]
    ):
        """
        æ·»åŠ å‘Šè­¦è§„åˆ™
        
        Args:
            name: è§„åˆ™åç§°
            condition: å‘Šè­¦æ¡ä»¶ï¼ˆPromQLè¡¨è¾¾å¼ï¼‰
            duration: æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            severity: ä¸¥é‡çº§åˆ«
            labels: æ ‡ç­¾
            annotations: æ³¨é‡Š
        """
        rule = {
            'name': name,
            'condition': condition,
            'duration': duration,
            'severity': severity,
            'labels': labels,
            'annotations': annotations,
            'created_at': datetime.now().isoformat()
        }
        
        self.alert_rules.append(rule)

    def evaluate_alerts(self, metrics_data: Dict) -> List[Dict]:
        """
        è¯„ä¼°å‘Šè­¦è§„åˆ™
        
        Args:
            metrics_data: æŒ‡æ ‡æ•°æ®
            
        Returns:
            è§¦å‘çš„å‘Šè­¦åˆ—è¡¨
        """
        triggered_alerts = []
        
        for rule in self.alert_rules:
            # ç®€å•çš„å‘Šè­¦è¯„ä¼°é€»è¾‘
            # å®é™…åº”è¯¥ä½¿ç”¨PromQLå¼•æ“
            if self._evaluate_condition(rule['condition'], metrics_data):
                alert = {
                    'name': rule['name'],
                    'severity': rule['severity'],
                    'labels': rule['labels'],
                    'annotations': rule['annotations'],
                    'fired_at': datetime.now().isoformat()
                }
                triggered_alerts.append(alert)
        
        return triggered_alerts

    def _evaluate_condition(self, condition: str, data: Dict) -> bool:
        """è¯„ä¼°å‘Šè­¦æ¡ä»¶"""
        # ç®€åŒ–çš„æ¡ä»¶è¯„ä¼°
        # å®é™…åº”è¯¥ä½¿ç”¨å®Œæ•´çš„PromQLè§£æ
        return False

    def group_alerts(self, alerts: List[Dict]) -> Dict[str, List[Dict]]:
        """
        å‘Šè­¦åˆ†ç»„
        
        Args:
            alerts: å‘Šè­¦åˆ—è¡¨
            
        Returns:
            åˆ†ç»„åçš„å‘Šè­¦
        """
        groups = {}
        
        for alert in alerts:
            # æŒ‰æœåŠ¡åˆ†ç»„
            service = alert.get('labels', {}).get('service', 'unknown')
            
            if service not in groups:
                groups[service] = []
            
            groups[service].append(alert)
        
        return groups

    def inhibit_alerts(self, alerts: List[Dict]) -> List[Dict]:
        """
        å‘Šè­¦æŠ‘åˆ¶
        
        Args:
            alerts: å‘Šè­¦åˆ—è¡¨
            
        Returns:
            æŠ‘åˆ¶åçš„å‘Šè­¦åˆ—è¡¨
        """
        # ç®€å•çš„æŠ‘åˆ¶é€»è¾‘ï¼šé«˜çº§åˆ«å‘Šè­¦æŠ‘åˆ¶ä½çº§åˆ«
        filtered = []
        critical_services = set()
        
        for alert in alerts:
            if alert['severity'] == 'critical':
                service = alert.get('labels', {}).get('service')
                if service:
                    critical_services.add(service)
                filtered.append(alert)
            elif alert['severity'] == 'warning':
                service = alert.get('labels', {}).get('service')
                # å¦‚æœè¯¥æœåŠ¡æœ‰criticalå‘Šè­¦ï¼ŒæŠ‘åˆ¶warning
                if service not in critical_services:
                    filtered.append(alert)
        
        return filtered

    def send_notifications(self, alerts: List[Dict]):
        """
        å‘é€å‘Šè­¦é€šçŸ¥
        
        Args:
            alerts: å‘Šè­¦åˆ—è¡¨
        """
        for alert in alerts:
            # æ£€æŸ¥æ˜¯å¦åœ¨é™é»˜æœŸ
            alert_key = f"{alert['name']}:{alert.get('labels', {}).get('service', '')}"
            
            if alert_key in self.silence_windows:
                if datetime.now() < self.silence_windows[alert_key]:
                    continue
            
            # æ ¹æ®ä¸¥é‡çº§åˆ«é€‰æ‹©é€šçŸ¥æ¸ é“
            severity = alert['severity']
            
            if severity == 'critical':
                self._send_pagerduty(alert)
                self._send_slack(alert)
            elif severity == 'warning':
                self._send_slack(alert)
            else:
                self._send_email(alert)
            
            # è®°å½•å‘Šè­¦å†å²
            self.alert_history.append(alert)

    def _send_slack(self, alert: Dict):
        """å‘é€Slacké€šçŸ¥"""
        webhook_url = self.config.get('slack_webhook_url')
        if not webhook_url:
            return
        
        message = {
            'text': f"Alert: {alert['name']}",
            'attachments': [{
                'color': 'danger' if alert['severity'] == 'critical' else 'warning',
                'fields': [
                    {'title': 'Severity', 'value': alert['severity'], 'short': True},
                    {'title': 'Service', 'value': alert.get('labels', {}).get('service', 'unknown'), 'short': True},
                    {'title': 'Description', 'value': alert.get('annotations', {}).get('summary', ''), 'short': False}
                ]
            }]
        }
        
        try:
            requests.post(webhook_url, json=message, timeout=10)
        except Exception as e:
            logging.error(f"å‘é€Slacké€šçŸ¥å¤±è´¥: {e}")

    def _send_pagerduty(self, alert: Dict):
        """å‘é€PagerDutyé€šçŸ¥"""
        # PagerDutyé›†æˆå®ç°
        pass

    def _send_email(self, alert: Dict):
        """å‘é€é‚®ä»¶é€šçŸ¥"""
        # é‚®ä»¶å‘é€å®ç°
        pass


class LogAnalyzer:
    """æ—¥å¿—åˆ†æå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æ—¥å¿—åˆ†æå™¨"""
        self.patterns = {}

    def parse_log(self, log_line: str) -> Optional[Dict]:
        """
        è§£ææ—¥å¿—è¡Œ
        
        Args:
            log_line: æ—¥å¿—è¡Œ
            
        Returns:
            è§£æåçš„æ—¥å¿—å­—å…¸
        """
        import re
        
        # å¸¸è§çš„æ—¥å¿—æ ¼å¼è§£æ
        patterns = [
            # Nginxæ ¼å¼
            r'(?P<ip>\S+) - - \[(?P<time>[^\]]+)\] "(?P<method>\S+) (?P<path>\S+) (?P<protocol>\S+)" (?P<status>\d+) (?P<bytes>\d+)',
            # JSONæ ¼å¼
            r'(?P<json>\{.*\})',
            # é€šç”¨æ ¼å¼
            r'(?P<timestamp>\d{4}-\d{2}-\d{2}[\sT]\d{2}:\d{2}:\d{2})\s+(?P<level>\w+)\s+(?P<message>.*)'
        ]
        
        for pattern in patterns:
            match = re.match(pattern, log_line)
            if match:
                return match.groupdict()
        
        return None

    def extract_error_patterns(self, logs: List[str]) -> Dict[str, int]:
        """
        æå–é”™è¯¯æ¨¡å¼
        
        Args:
            logs: æ—¥å¿—åˆ—è¡¨
            
        Returns:
            é”™è¯¯æ¨¡å¼ç»Ÿè®¡
        """
        error_patterns = {}
        
        for log in logs:
            if 'ERROR' in log or 'error' in log.lower():
                # æå–é”™è¯¯æ¶ˆæ¯çš„æ ¸å¿ƒéƒ¨åˆ†
                # ç§»é™¤æ—¶é—´æˆ³ã€IDç­‰å˜é‡éƒ¨åˆ†
                normalized = self._normalize_error(log)
                error_patterns[normalized] = error_patterns.get(normalized, 0) + 1
        
        return error_patterns

    def _normalize_error(self, error_msg: str) -> str:
        """è§„èŒƒåŒ–é”™è¯¯æ¶ˆæ¯"""
        import re
        
        # ç§»é™¤æ—¶é—´æˆ³
        msg = re.sub(r'\d{4}-\d{2}-\d{2}[\sT]\d{2}:\d{2}:\d{2}', '<TIMESTAMP>', error_msg)
        # ç§»é™¤UUID
        msg = re.sub(r'[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}', '<UUID>', msg, flags=re.I)
        # ç§»é™¤æ•°å­—ID
        msg = re.sub(r'\b\d+\b', '<ID>', msg)
        
        return msg

    def correlate_logs_with_traces(
        self,
        logs: List[LogEntry],
        traces: List[TraceSpan]
    ) -> Dict[str, List[LogEntry]]:
        """
        å…³è”æ—¥å¿—å’Œè¿½è¸ª
        
        Args:
            logs: æ—¥å¿—åˆ—è¡¨
            traces: è¿½è¸ªåˆ—è¡¨
            
        Returns:
            å…³è”ç»“æœ
        """
        correlated = {}
        
        # åˆ›å»ºtrace_idç´¢å¼•
        trace_index = {span.trace_id: span for span in traces}
        
        for log in logs:
            if log.trace_id and log.trace_id in trace_index:
                if log.trace_id not in correlated:
                    correlated[log.trace_id] = []
                correlated[log.trace_id].append(log)
        
        return correlated


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–é‡‡é›†å™¨
    collector_config = {
        'batch_size': 100,
        'flush_interval': 5,
        'log_sample_rate': 1.0,
        'trace_sample_rate': 0.1
    }
    
    collector = ObservabilityCollector(collector_config)
    
    # é‡‡é›†æ—¥å¿—
    collector.collect_log(
        service="payment-service",
        level=LogLevel.INFO,
        message="Payment processed successfully",
        trace_id="abc123",
        attributes={'amount': 100, 'currency': 'USD'}
    )
    
    # é‡‡é›†æŒ‡æ ‡
    collector.collect_metric(
        name="http_requests_total",
        value=1,
        labels={'method': 'GET', 'status': '200', 'path': '/api/payments'},
        metric_type=MetricType.COUNTER
    )
    
    # é‡‡é›†è¿½è¸ª
    span = TraceSpan(
        trace_id="abc123",
        span_id="span001",
        parent_span_id=None,
        service="payment-service",
        operation="process_payment",
        start_time=datetime.now(),
        end_time=datetime.now(),
        tags={'method': 'POST'},
        logs=[]
    )
    collector.collect_trace(span)
    
    # åˆ·æ–°æ‰€æœ‰æ•°æ®
    collector.flush_all()
    
    # å‘Šè­¦ç®¡ç†
    alert_config = {
        'slack_webhook_url': 'https://hooks.slack.com/services/xxx'
    }
    
    alert_manager = AlertManager(alert_config)
    
    alert_manager.add_alert_rule(
        name="HighErrorRate",
        condition="rate(http_requests_total{status=~\"5..\"}[5m]) > 0.1",
        duration=300,
        severity="critical",
        labels={'service': 'payment-service'},
        annotations={'summary': 'High error rate detected'}
    )
    
    print("å¯è§‚æµ‹æ€§æ•°æ®é‡‡é›†å®Œæˆ")


if __name__ == '__main__':
    main()
```

### 2.7 æ•ˆæœè¯„ä¼°

**æ€§èƒ½æŒ‡æ ‡**ï¼š

| æŒ‡æ ‡ | æ”¹è¿›å‰ | æ”¹è¿›å | æå‡ |
|------|--------|--------|------|
| MTTR | 2å°æ—¶ | 12åˆ†é’Ÿ | 10x |
| æ—¥å¿—æŸ¥è¯¢é€Ÿåº¦ | 30ç§’ | 1ç§’ | 30x |
| å‘Šè­¦ä¿¡å™ªæ¯” | 10:1 | 1:1 | 10x |
| å­˜å‚¨æˆæœ¬ | 100% | 45% | 55%é™ä½ |
| æ•°æ®ä¿ç•™æœŸ | 7å¤© | 90å¤© | 12x |

**ROIåˆ†æ**ï¼š

1. **æˆæœ¬èŠ‚çº¦**ï¼š
   - æ•…éšœæ¢å¤æ—¶é—´ç¼©çŸ­ï¼šæ¯å¹´ 600ä¸‡å…ƒ
   - å­˜å‚¨æˆæœ¬é™ä½ï¼šæ¯å¹´ 200ä¸‡å…ƒ
   - è¿ç»´æ•ˆç‡æå‡ï¼šæ¯å¹´ 300ä¸‡å…ƒ

2. **æŠ•èµ„å›æŠ¥ç‡**ï¼š
   - æ€»æŠ•èµ„ï¼š500ä¸‡å…ƒ
   - å¹´åº¦æ”¶ç›Šï¼š1100ä¸‡å…ƒ
   - ROIï¼š220%

**ç»éªŒæ•™è®­**ï¼š

1. **ç»Ÿä¸€é‡‡é›†**ï¼šä½¿ç”¨OpenTelemetryç»Ÿä¸€é‡‡é›†ä¸‰ç§æ•°æ®
2. **é‡‡æ ·å¾ˆé‡è¦**ï¼šå…¨é‡é‡‡é›†æˆæœ¬è¿‡é«˜ï¼Œéœ€è¦åˆç†é‡‡æ ·
3. **å…³è”æ˜¯å…³é”®**ï¼šæ—¥å¿—ã€æŒ‡æ ‡ã€è¿½è¸ªéœ€è¦èƒ½ç›¸äº’å…³è”
4. **å‘Šè­¦é™å™ª**ï¼šæ™ºèƒ½å‘Šè­¦åˆ†ç»„å’ŒæŠ‘åˆ¶å¾ˆé‡è¦

---

## 3. æ¡ˆä¾‹æ€»ç»“

### æˆåŠŸå› ç´ 

1. **ä¸‰å¤§æ”¯æŸ±ç»Ÿä¸€**ï¼šæ—¥å¿—ã€æŒ‡æ ‡ã€è¿½è¸ªç»Ÿä¸€å¹³å°ç®¡ç†
2. **é«˜æ€§èƒ½å­˜å‚¨**ï¼šé€‰æ‹©é€‚åˆçš„å­˜å‚¨å¼•æ“ï¼ˆClickHouse, VictoriaMetricsï¼‰
3. **æ™ºèƒ½å‘Šè­¦**ï¼šå‘Šè­¦åˆ†ç»„ã€æŠ‘åˆ¶ã€æ™ºèƒ½è·¯ç”±
4. **æˆæœ¬ä¼˜åŒ–**ï¼šé‡‡æ ·ã€å‹ç¼©ã€å†·çƒ­åˆ†å±‚

### æœ€ä½³å®è·µ

1. **OpenTelemetryæ ‡å‡†åŒ–**ï¼šä½¿ç”¨OpenTelemetryç»Ÿä¸€é‡‡é›†
2. **åˆç†çš„é‡‡æ ·ç­–ç•¥**ï¼šå¹³è¡¡æˆæœ¬å’Œè¦†ç›–åº¦
3. **æ ‡ç­¾è§„èŒƒåŒ–**ï¼šç»Ÿä¸€çš„æ ‡ç­¾ä½“ç³»ä¾¿äºæŸ¥è¯¢
4. **æ•°æ®å…³è”**ï¼šç¡®ä¿ä¸‰ç§æ•°æ®å¯ä»¥ç›¸äº’å…³è”

---

## 4. å‚è€ƒæ–‡çŒ®

- [OpenTelemetryå®˜æ–¹æ–‡æ¡£](https://opentelemetry.io/docs/)
- [Google SREä¹¦ç± - å¯è§‚æµ‹æ€§ç« èŠ‚](https://sre.google/sre-book/table-of-contents/)
- [Prometheusæœ€ä½³å®è·µ](https://prometheus.io/docs/practices/)

---

**æ–‡æ¡£åˆ›å»ºæ—¶é—´**ï¼š2025-01-21  
**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**ç»´æŠ¤è€…**ï¼šDSL Schemaç ”ç©¶å›¢é˜Ÿ  
**æœ€åæ›´æ–°**ï¼š2025-01-21
