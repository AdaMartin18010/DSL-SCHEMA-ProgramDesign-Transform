# å½¢å¼åŒ–éªŒè¯

## ğŸ“‘ ç›®å½•

- [å½¢å¼åŒ–éªŒè¯](#å½¢å¼åŒ–éªŒè¯)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. å½¢å¼åŒ–æ–¹æ³•](#1-å½¢å¼åŒ–æ–¹æ³•)
    - [1.1 é›†åˆè®ºè¯æ˜](#11-é›†åˆè®ºè¯æ˜)
    - [1.2 ç±»å‹è®ºè¯æ˜](#12-ç±»å‹è®ºè¯æ˜)
  - [2. éªŒè¯å·¥å…·](#2-éªŒè¯å·¥å…·)
    - [2.1 Coq](#21-coq)
    - [2.2 Isabelle](#22-isabelle)
  - [3. éªŒè¯æ¡ˆä¾‹](#3-éªŒè¯æ¡ˆä¾‹)
    - [3.1 æ—¶é—´ç»´åº¦è½¬æ¢éªŒè¯](#31-æ—¶é—´ç»´åº¦è½¬æ¢éªŒè¯)
  - [6. æ•°æ®åº“å­˜å‚¨ä¸åˆ†æ](#6-æ•°æ®åº“å­˜å‚¨ä¸åˆ†æ)
    - [6.1 PostgreSQLæ•°æ®å­˜å‚¨](#61-postgresqlæ•°æ®å­˜å‚¨)
    - [6.2 æ•°æ®åˆ†ææŸ¥è¯¢ç¤ºä¾‹](#62-æ•°æ®åˆ†ææŸ¥è¯¢ç¤ºä¾‹)

---

## 1. å½¢å¼åŒ–æ–¹æ³•

### 1.1 é›†åˆè®ºè¯æ˜

**æ–¹æ³•**ï¼šä½¿ç”¨é›†åˆè®ºè¯æ˜è½¬æ¢çš„æ­£ç¡®æ€§ã€‚

**ç¤ºä¾‹**ï¼š

- å®šä¹‰ç»´åº¦é›†åˆ
- å®šä¹‰è½¬æ¢å‡½æ•°
- è¯æ˜è½¬æ¢å‡½æ•°çš„æ€§è´¨

### 1.2 ç±»å‹è®ºè¯æ˜

**æ–¹æ³•**ï¼šä½¿ç”¨ç±»å‹è®ºè¯æ˜ç±»å‹å®‰å…¨ã€‚

**ç¤ºä¾‹**ï¼š

- å®šä¹‰ç»´åº¦ç±»å‹
- å®šä¹‰è½¬æ¢å‡½æ•°ç±»å‹
- è¯æ˜ç±»å‹å®‰å…¨

---

## 2. éªŒè¯å·¥å…·

### 2.1 Coq

**åŠŸèƒ½**ï¼šå½¢å¼åŒ–è¯æ˜å·¥å…·ã€‚

**åº”ç”¨**ï¼šè¯æ˜è½¬æ¢å‡½æ•°çš„æ­£ç¡®æ€§ã€‚

### 2.2 Isabelle

**åŠŸèƒ½**ï¼šå½¢å¼åŒ–è¯æ˜å·¥å…·ã€‚

**åº”ç”¨**ï¼šè¯æ˜è½¬æ¢è§„åˆ™çš„æ­£ç¡®æ€§ã€‚

---

## 3. éªŒè¯æ¡ˆä¾‹

### 3.1 æ—¶é—´ç»´åº¦è½¬æ¢éªŒè¯

**éªŒè¯ç›®æ ‡**ï¼šæ—¶é—´ç»´åº¦è½¬æ¢çš„æ­£ç¡®æ€§ã€‚

**éªŒè¯æ–¹æ³•**ï¼š

- å®šä¹‰æ—¶é—´ç»´åº¦ç±»å‹
- å®šä¹‰è½¬æ¢å‡½æ•°
- è¯æ˜è½¬æ¢å‡½æ•°çš„æ€§è´¨

---

## 6. æ•°æ®åº“å­˜å‚¨ä¸åˆ†æ

### 6.1 PostgreSQLæ•°æ®å­˜å‚¨

**è¡¨ç»“æ„è®¾è®¡**ï¼š

```sql
-- å¤šç»´æ¨¡å‹è½¬æ¢è¡¨
CREATE TABLE multidimensional_model_conversions (
    id SERIAL PRIMARY KEY,
    model_name VARCHAR(200) UNIQUE NOT NULL,
    source_dimensions JSONB NOT NULL,
    target_dimensions JSONB NOT NULL,
    conversion_proof JSONB,
    verification_status VARCHAR(20) DEFAULT 'PENDING',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç»´åº¦è½¬æ¢è®°å½•è¡¨
CREATE TABLE dimension_conversion_records (
    id SERIAL PRIMARY KEY,
    conversion_id INTEGER REFERENCES multidimensional_model_conversions(id),
    dimension_name VARCHAR(100) NOT NULL,
    source_value JSONB,
    target_value JSONB,
    conversion_method VARCHAR(50),
    verification_result JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_conversions_verification_status ON multidimensional_model_conversions(verification_status);
CREATE INDEX idx_dimension_records_conversion_id ON dimension_conversion_records(conversion_id);
```

**Pythonå­˜å‚¨å®ç°**ï¼š

```python
import psycopg2
import json
from typing import Dict, Any, Optional
import logging

logger = logging.getLogger(__name__)

class MultidimensionalModelStorage:
    """å¤šç»´æ¨¡å‹è½¬æ¢æ•°æ®å­˜å‚¨ç±»"""

    def __init__(self, db_config: Dict[str, Any]):
        self.conn = psycopg2.connect(**db_config)
        self.cur = self.conn.cursor()
        self._create_tables()

    def _create_tables(self):
        """åˆ›å»ºè¡¨ç»“æ„"""
        # å¤šç»´æ¨¡å‹è½¬æ¢è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS multidimensional_model_conversions (
                id SERIAL PRIMARY KEY,
                model_name VARCHAR(200) UNIQUE NOT NULL,
                source_dimensions JSONB NOT NULL,
                target_dimensions JSONB NOT NULL,
                conversion_proof JSONB,
                verification_status VARCHAR(20) DEFAULT 'PENDING',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # ç»´åº¦è½¬æ¢è®°å½•è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS dimension_conversion_records (
                id SERIAL PRIMARY KEY,
                conversion_id INTEGER REFERENCES multidimensional_model_conversions(id),
                dimension_name VARCHAR(100) NOT NULL,
                source_value JSONB,
                target_value JSONB,
                conversion_method VARCHAR(50),
                verification_result JSONB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # åˆ›å»ºç´¢å¼•
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_conversions_verification_status
            ON multidimensional_model_conversions(verification_status)
        """)
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_dimension_records_conversion_id
            ON dimension_conversion_records(conversion_id)
        """)
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_conversions_created_at
            ON multidimensional_model_conversions(created_at DESC)
        """)

        self.conn.commit()

    def store_conversion(self, model_name: str, source_dimensions: Dict,
                        target_dimensions: Dict, conversion_proof: Optional[Dict] = None,
                        verification_status: str = 'PENDING') -> int:
        """å­˜å‚¨å¤šç»´æ¨¡å‹è½¬æ¢"""
        try:
            self.cur.execute("""
                INSERT INTO multidimensional_model_conversions
                (model_name, source_dimensions, target_dimensions,
                 conversion_proof, verification_status)
                VALUES (%s, %s::jsonb, %s::jsonb, %s::jsonb, %s)
                ON CONFLICT (model_name) DO UPDATE
                SET source_dimensions = EXCLUDED.source_dimensions,
                    target_dimensions = EXCLUDED.target_dimensions,
                    conversion_proof = EXCLUDED.conversion_proof,
                    verification_status = EXCLUDED.verification_status,
                    updated_at = CURRENT_TIMESTAMP
                RETURNING id
            """, (model_name, json.dumps(source_dimensions),
                  json.dumps(target_dimensions),
                  json.dumps(conversion_proof) if conversion_proof else None,
                  verification_status))
            conversion_id = self.cur.fetchone()[0]
            self.conn.commit()
            logger.info(f"Stored conversion: {model_name} (ID: {conversion_id})")
            return conversion_id
        except Exception as e:
            logger.error(f"Failed to store conversion: {e}")
            self.conn.rollback()
            raise

    def store_dimension_record(self, conversion_id: int, dimension_name: str,
                              source_value: Dict, target_value: Dict,
                              conversion_method: str, verification_result: Optional[Dict] = None) -> int:
        """å­˜å‚¨ç»´åº¦è½¬æ¢è®°å½•"""
        try:
            self.cur.execute("""
                INSERT INTO dimension_conversion_records
                (conversion_id, dimension_name, source_value, target_value,
                 conversion_method, verification_result)
                VALUES (%s, %s, %s::jsonb, %s::jsonb, %s, %s::jsonb)
                RETURNING id
            """, (conversion_id, dimension_name, json.dumps(source_value),
                  json.dumps(target_value), conversion_method,
                  json.dumps(verification_result) if verification_result else None))
            record_id = self.cur.fetchone()[0]
            self.conn.commit()
            logger.info(f"Stored dimension record: {record_id}")
            return record_id
        except Exception as e:
            logger.error(f"Failed to store dimension record: {e}")
            self.conn.rollback()
            raise

    def get_verification_statistics(self) -> Dict:
        """è·å–éªŒè¯ç»Ÿè®¡ä¿¡æ¯"""
        try:
            self.cur.execute("""
                SELECT
                    verification_status,
                    COUNT(*) as count,
                    COUNT(CASE WHEN conversion_proof IS NOT NULL THEN 1 END) as with_proof_count
                FROM multidimensional_model_conversions
                GROUP BY verification_status
                ORDER BY count DESC
            """)
            results = []
            for row in self.cur.fetchall():
                results.append({
                    'verification_status': row[0],
                    'count': row[1],
                    'with_proof_count': row[2]
                })
            return {'by_status': results}
        except Exception as e:
            logger.error(f"Failed to get verification statistics: {e}")
            raise

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.cur.close()
        self.conn.close()
```

### 6.2 æ•°æ®åˆ†ææŸ¥è¯¢ç¤ºä¾‹

**æŸ¥è¯¢éªŒè¯çŠ¶æ€ç»Ÿè®¡**ï¼š

```python
# æŸ¥è¯¢éªŒè¯çŠ¶æ€åˆ†å¸ƒ
storage.cur.execute("""
    SELECT verification_status, COUNT(*) as count
    FROM multidimensional_model_conversions
    GROUP BY verification_status
    ORDER BY count DESC
""")
```

**æŸ¥è¯¢ç»´åº¦è½¬æ¢ç»Ÿè®¡**ï¼š

```python
# æŸ¥è¯¢ç»´åº¦è½¬æ¢ç»Ÿè®¡
storage.cur.execute("""
    SELECT
        dimension_name,
        COUNT(*) as conversion_count,
        COUNT(DISTINCT conversion_id) as model_count,
        COUNT(CASE WHEN verification_result->>'verified' = 'true' THEN 1 END) as verified_count
    FROM dimension_conversion_records
    GROUP BY dimension_name
    ORDER BY conversion_count DESC
""")
```

**æŸ¥è¯¢è½¬æ¢æ–¹æ³•åˆ†å¸ƒ**ï¼š

```python
# æŸ¥è¯¢è½¬æ¢æ–¹æ³•åˆ†å¸ƒ
storage.cur.execute("""
    SELECT
        conversion_method,
        COUNT(*) as usage_count,
        COUNT(DISTINCT conversion_id) as model_count
    FROM dimension_conversion_records
    WHERE conversion_method IS NOT NULL
    GROUP BY conversion_method
    ORDER BY usage_count DESC
""")
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å¤šç»´æ¨¡å‹ç†è®º
- `03_Standards.md` - è½¬æ¢è®ºè¯
- `05_Case_Studies.md` - å®è·µæ¡ˆä¾‹

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
