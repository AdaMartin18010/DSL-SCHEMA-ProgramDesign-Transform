# æ•°æ®åˆ†æSchemaè½¬æ¢ä½“ç³»

## ğŸ“‘ ç›®å½•

- [æ•°æ®åˆ†æSchemaè½¬æ¢ä½“ç³»](#æ•°æ®åˆ†æschemaè½¬æ¢ä½“ç³»)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. è½¬æ¢ä½“ç³»æ¦‚è¿°](#1-è½¬æ¢ä½“ç³»æ¦‚è¿°)
    - [1.1 è½¬æ¢ç›®æ ‡](#11-è½¬æ¢ç›®æ ‡)
  - [2. æ•°æ®åˆ†æåˆ°æ•°æ®ä»“åº“è½¬æ¢](#2-æ•°æ®åˆ†æåˆ°æ•°æ®ä»“åº“è½¬æ¢)
  - [3. æ•°æ®åˆ†æåˆ°BIè½¬æ¢](#3-æ•°æ®åˆ†æåˆ°biè½¬æ¢)
  - [4. è½¬æ¢å·¥å…·](#4-è½¬æ¢å·¥å…·)
  - [5. æ•°æ®åˆ†ææ•°æ®å­˜å‚¨](#5-æ•°æ®åˆ†ææ•°æ®å­˜å‚¨)
    - [5.1 PostgreSQLæ•°æ®åˆ†ææ•°æ®å­˜å‚¨](#51-postgresqlæ•°æ®åˆ†ææ•°æ®å­˜å‚¨)
    - [5.2 æ•°æ®åˆ†ææŸ¥è¯¢](#52-æ•°æ®åˆ†ææŸ¥è¯¢)

---

## 1. è½¬æ¢ä½“ç³»æ¦‚è¿°

æ•°æ®åˆ†æSchemaè½¬æ¢ä½“ç³»æ”¯æŒæ•°æ®åˆ†ææ•°æ®åˆ°æ•°æ®ä»“åº“ã€BIæ ¼å¼è½¬æ¢ï¼Œ
ä»¥åŠæ•°æ®åˆ†ææ•°æ®å­˜å‚¨ã€‚

### 1.1 è½¬æ¢ç›®æ ‡

1. **æ•°æ®åˆ†æåˆ°æ•°æ®ä»“åº“è½¬æ¢**ï¼šæ•°æ®åˆ†ææ•°æ®åˆ°æ•°æ®ä»“åº“æ ¼å¼
2. **æ•°æ®åˆ†æåˆ°BIè½¬æ¢**ï¼šæ•°æ®åˆ†ææ•°æ®åˆ°BIæ ¼å¼
3. **æ•°æ®åˆ†æåˆ°æ•°æ®åº“è½¬æ¢**ï¼šæ•°æ®åˆ†ææ•°æ®åˆ°PostgreSQLå­˜å‚¨

---

## 2. æ•°æ®åˆ†æåˆ°æ•°æ®ä»“åº“è½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- åˆ†æç»“æœ â†’ æ•°æ®ä»“åº“äº‹å®è¡¨
- åˆ†æç»´åº¦ â†’ æ•°æ®ä»“åº“ç»´åº¦è¡¨
- åˆ†ææŒ‡æ ‡ â†’ æ•°æ®ä»“åº“åº¦é‡å€¼

**è½¬æ¢ç¤ºä¾‹**ï¼š

```python
def convert_analytics_to_data_warehouse(analytics_data: DataAnalyticsSchema) -> DataWarehouseSchema:
    """å°†æ•°æ®åˆ†ææ•°æ®è½¬æ¢ä¸ºæ•°æ®ä»“åº“æ ¼å¼"""
    dw_schema = DataWarehouseSchema()

    # è½¬æ¢æ˜Ÿå‹æ¨¡å¼
    star_schema = StarSchema()

    # åˆ›å»ºäº‹å®è¡¨
    fact_table = FactTable()
    fact_table.fact_table_name = "sales_fact"
    fact_table.measures = [
        {"name": "sales_amount", "type": "Decimal"},
        {"name": "quantity", "type": "Integer"}
    ]
    fact_table.grain = "Daily Sales by Product and Customer"
    star_schema.fact_tables.append(fact_table)

    # åˆ›å»ºç»´åº¦è¡¨
    dimension_table = DimensionTable()
    dimension_table.dimension_name = "product_dimension"
    dimension_table.dimension_attributes = [
        "product_id", "product_name", "product_category", "product_price"
    ]
    star_schema.dimension_tables.append(dimension_table)

    dw_schema.star_schema = star_schema

    return dw_schema
```

---

## 3. æ•°æ®åˆ†æåˆ°BIè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- åˆ†æç»“æœ â†’ BIæŠ¥è¡¨æ•°æ®
- åˆ†æå›¾è¡¨ â†’ BIä»ªè¡¨æ¿ç»„ä»¶
- åˆ†ææŒ‡æ ‡ â†’ BI KPI

**è½¬æ¢ç¤ºä¾‹**ï¼š

```python
def convert_analytics_to_bi(analytics_data: DataAnalyticsSchema) -> BusinessIntelligenceSchema:
    """å°†æ•°æ®åˆ†ææ•°æ®è½¬æ¢ä¸ºBIæ ¼å¼"""
    bi_schema = BusinessIntelligenceSchema()

    # è½¬æ¢æŠ¥è¡¨
    report = Report()
    report.report_name = "Sales Analysis Report"
    report.report_format = "PDF"
    report.report_content = generate_report_content(analytics_data)
    bi_schema.reports.append(report)

    # è½¬æ¢ä»ªè¡¨æ¿
    dashboard = Dashboard()
    dashboard.dashboard_name = "Sales Dashboard"

    # è½¬æ¢å›¾è¡¨ç»„ä»¶
    for chart in analytics_data.data_visualization.chart_types:
        component = DashboardComponent()
        component.component_type = "Chart"
        component.component_config = chart.chart_config
        dashboard.dashboard_components.append(component)

    bi_schema.dashboards.append(dashboard)

    return bi_schema
```

---

## 4. è½¬æ¢å·¥å…·

### 4.1 æ•°æ®åˆ†æå·¥å…·

- **Pythonæ•°æ®åˆ†æ**ï¼šPandasã€NumPyã€Scikit-learn
- **Ræ•°æ®åˆ†æ**ï¼šRè¯­è¨€æ•°æ®åˆ†æåŒ…
- **Sparkæ•°æ®åˆ†æ**ï¼šApache Sparkæ•°æ®åˆ†æ

---

## 5. æ•°æ®åˆ†ææ•°æ®å­˜å‚¨

### 5.1 PostgreSQLæ•°æ®åˆ†ææ•°æ®å­˜å‚¨

**è¡¨ç»“æ„è®¾è®¡**ï¼š

```sql
-- æ•°æ®æºè¡¨
CREATE TABLE data_sources (
    source_id VARCHAR(50) PRIMARY KEY,
    source_type VARCHAR(50) NOT NULL,
    source_connection TEXT NOT NULL,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ•°æ®è´¨é‡æŒ‡æ ‡è¡¨
CREATE TABLE data_quality_metrics (
    metric_id VARCHAR(50) PRIMARY KEY,
    metric_name VARCHAR(200) NOT NULL,
    metric_type VARCHAR(50) NOT NULL,
    metric_value DECIMAL(5, 2) NOT NULL,
    threshold DECIMAL(5, 2) NOT NULL,
    is_passed BOOLEAN GENERATED ALWAYS AS (metric_value >= threshold) STORED,
    check_date DATE NOT NULL
);

-- åˆ†æç»“æœè¡¨
CREATE TABLE analysis_results (
    result_id VARCHAR(50) PRIMARY KEY,
    analysis_id VARCHAR(50) NOT NULL,
    analysis_type VARCHAR(50) NOT NULL,
    result_data JSONB NOT NULL,
    result_date DATE NOT NULL
);

-- æœºå™¨å­¦ä¹ æ¨¡å‹è¡¨
CREATE TABLE ml_models (
    model_id VARCHAR(50) PRIMARY KEY,
    model_type VARCHAR(50) NOT NULL,
    algorithm VARCHAR(100) NOT NULL,
    model_accuracy DECIMAL(5, 2) NOT NULL,
    training_date DATE NOT NULL,
    model_version VARCHAR(50) NOT NULL
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_data_quality_metrics_date ON data_quality_metrics(check_date);
CREATE INDEX idx_analysis_results_analysis ON analysis_results(analysis_id);
CREATE INDEX idx_ml_models_type ON ml_models(model_type);
```

**æ•°æ®æ’å…¥ç¤ºä¾‹**ï¼š

```python
def store_analytics_data(analytics_data: DataAnalyticsSchema, conn):
    """å­˜å‚¨æ•°æ®åˆ†ææ•°æ®åˆ°PostgreSQL"""
    cursor = conn.cursor()

    # æ’å…¥æ•°æ®æº
    for source in analytics_data.data_collection.data_sources:
        cursor.execute("""
            INSERT INTO data_sources
            (source_id, source_type, source_connection, is_active)
            VALUES (%s, %s, %s, %s)
        """, (source.source_id, source.source_type,
              source.source_connection, source.is_active))

    # æ’å…¥æ•°æ®è´¨é‡æŒ‡æ ‡
    for metric in analytics_data.data_collection.data_quality.quality_metrics:
        cursor.execute("""
            INSERT INTO data_quality_metrics
            (metric_id, metric_name, metric_type, metric_value, threshold, check_date)
            VALUES (%s, %s, %s, %s, %s, %s)
        """, (metric.metric_id, metric.metric_name, metric.metric_type,
              metric.metric_value, metric.threshold, "2025-01-21"))

    # æ’å…¥æœºå™¨å­¦ä¹ æ¨¡å‹
    for model in analytics_data.data_analysis.machine_learning.models:
        cursor.execute("""
            INSERT INTO ml_models
            (model_id, model_type, algorithm, model_accuracy, training_date, model_version)
            VALUES (%s, %s, %s, %s, %s, %s)
        """, (model.model_id, model.model_type, model.algorithm,
              model.model_accuracy, "2025-01-21", "v1.0"))

    conn.commit()
```

### 5.2 æ•°æ®åˆ†ææŸ¥è¯¢

**æŸ¥è¯¢ç¤ºä¾‹**ï¼š

```python
def analyze_analytics_data(conn, period_start, period_end):
    """åˆ†ææ•°æ®åˆ†ææ•°æ®"""
    cursor = conn.cursor()

    # æŸ¥è¯¢æ•°æ®è´¨é‡è¶‹åŠ¿
    cursor.execute("""
        SELECT
            check_date,
            AVG(metric_value) as avg_quality_score,
            COUNT(CASE WHEN is_passed THEN 1 END) as passed_metrics,
            COUNT(*) as total_metrics
        FROM data_quality_metrics
        WHERE check_date BETWEEN %s AND %s
        GROUP BY check_date
        ORDER BY check_date
    """, (period_start, period_end))

    quality_trends = cursor.fetchall()

    # æŸ¥è¯¢æ¨¡å‹å‡†ç¡®ç‡
    cursor.execute("""
        SELECT
            model_type,
            AVG(model_accuracy) as avg_accuracy,
            COUNT(*) as model_count
        FROM ml_models
        WHERE training_date BETWEEN %s AND %s
        GROUP BY model_type
        ORDER BY avg_accuracy DESC
    """, (period_start, period_end))

    model_performance = cursor.fetchall()

    return {
        "quality_trends": quality_trends,
        "model_performance": model_performance
    }
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `05_Case_Studies.md` - å®è·µæ¡ˆä¾‹

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
