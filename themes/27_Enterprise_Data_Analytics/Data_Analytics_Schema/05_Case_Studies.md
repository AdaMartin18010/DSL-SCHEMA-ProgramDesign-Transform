# æ•°æ®åˆ†æSchemaå®è·µæ¡ˆä¾‹

## ğŸ“‘ ç›®å½•

- [æ•°æ®åˆ†æSchemaå®è·µæ¡ˆä¾‹](#æ•°æ®åˆ†æschemaå®è·µæ¡ˆä¾‹)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¡ˆä¾‹æ¦‚è¿°](#1-æ¡ˆä¾‹æ¦‚è¿°)
  - [2. æ¡ˆä¾‹1ï¼šä¼ä¸šé”€å”®æ•°æ®åˆ†æç³»ç»Ÿ](#2-æ¡ˆä¾‹1ä¼ä¸šé”€å”®æ•°æ®åˆ†æç³»ç»Ÿ)
    - [2.1 ä¸šåŠ¡èƒŒæ™¯](#21-ä¸šåŠ¡èƒŒæ™¯)
    - [2.2 æŠ€æœ¯æŒ‘æˆ˜](#22-æŠ€æœ¯æŒ‘æˆ˜)
    - [2.3 è§£å†³æ–¹æ¡ˆ](#23-è§£å†³æ–¹æ¡ˆ)
    - [2.4 å®Œæ•´ä»£ç å®ç°](#24-å®Œæ•´ä»£ç å®ç°)
    - [2.5 æ•ˆæœè¯„ä¼°](#25-æ•ˆæœè¯„ä¼°)
  - [3. æ¡ˆä¾‹2ï¼šå®¢æˆ·è¡Œä¸ºåˆ†æ](#3-æ¡ˆä¾‹2å®¢æˆ·è¡Œä¸ºåˆ†æ)
    - [3.1 åœºæ™¯æè¿°](#31-åœºæ™¯æè¿°)
    - [3.2 Schemaå®šä¹‰](#32-schemaå®šä¹‰)
  - [4. æ¡ˆä¾‹3ï¼šé¢„æµ‹åˆ†æ](#4-æ¡ˆä¾‹3é¢„æµ‹åˆ†æ)
    - [4.1 åœºæ™¯æè¿°](#41-åœºæ™¯æè¿°)
    - [4.2 Schemaå®šä¹‰](#42-schemaå®šä¹‰)
  - [5. æ¡ˆä¾‹4ï¼šæ•°æ®åˆ†æåˆ°æ•°æ®ä»“åº“è½¬æ¢](#5-æ¡ˆä¾‹4æ•°æ®åˆ†æåˆ°æ•°æ®ä»“åº“è½¬æ¢)
    - [5.1 åœºæ™¯æè¿°](#51-åœºæ™¯æè¿°)
    - [5.2 å®ç°ä»£ç ](#52-å®ç°ä»£ç )
  - [6. æ¡ˆä¾‹5ï¼šæ•°æ®åˆ†ææ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿ](#6-æ¡ˆä¾‹5æ•°æ®åˆ†ææ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿ)
    - [6.1 åœºæ™¯æè¿°](#61-åœºæ™¯æè¿°)
    - [6.2 å®ç°ä»£ç ](#62-å®ç°ä»£ç )

---

## 1. æ¡ˆä¾‹æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›æ•°æ®åˆ†æSchemaåœ¨å®é™…ä¼ä¸šåº”ç”¨ä¸­çš„å®è·µæ¡ˆä¾‹ï¼Œæ¶µç›–é”€å”®æ•°æ®åˆ†æã€å®¢æˆ·è¡Œä¸ºåˆ†æã€é¢„æµ‹åˆ†æç­‰çœŸå®åœºæ™¯ã€‚

**æ¡ˆä¾‹ç±»å‹**ï¼š

1. **ä¼ä¸šé”€å”®æ•°æ®åˆ†æç³»ç»Ÿ**ï¼šé”€å”®è¶‹åŠ¿å’Œé¢„æµ‹åˆ†æ
2. **å®¢æˆ·è¡Œä¸ºåˆ†æç³»ç»Ÿ**ï¼šå®¢æˆ·è¡Œä¸ºåˆ†æ
3. **é¢„æµ‹åˆ†æç³»ç»Ÿ**ï¼šé”€å”®å’Œä¸šåŠ¡é¢„æµ‹
4. **æ•°æ®åˆ†æåˆ°æ•°æ®ä»“åº“è½¬æ¢å·¥å…·**ï¼šåˆ†ææ•°æ®åˆ°æ•°æ®ä»“åº“è½¬æ¢
5. **æ•°æ®åˆ†ææ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿ**ï¼šåˆ†ææ•°æ®åˆ†æå’Œç›‘æ§

**å‚è€ƒä¼ä¸šæ¡ˆä¾‹**ï¼š

- **æ•°æ®åˆ†ææœ€ä½³å®è·µ**ï¼šKDnuggetsæ•°æ®åˆ†ææŒ‡å—
- **é¢„æµ‹åˆ†æ**ï¼šAnalytics Vidhyaé¢„æµ‹åˆ†ææŒ‡å—

---

## 2. æ¡ˆä¾‹1ï¼šä¼ä¸šé”€å”®æ•°æ®åˆ†æç³»ç»Ÿ

### 2.1 ä¸šåŠ¡èƒŒæ™¯

**ä¼ä¸šèƒŒæ™¯**ï¼š
æŸé›¶å”®å…¬å¸éœ€è¦æ„å»ºé”€å”®æ•°æ®åˆ†æç³»ç»Ÿï¼Œåˆ†æé”€å”®è¶‹åŠ¿ã€é¢„æµ‹æœªæ¥é”€å”®ã€åˆ†æå®¢æˆ·è¡Œä¸ºï¼Œä¸ºä¸šåŠ¡å†³ç­–æä¾›æ•°æ®æ”¯æŒã€‚

**ä¸šåŠ¡ç—›ç‚¹**ï¼š

1. **æ•°æ®åˆ†æèƒ½åŠ›ä¸è¶³**ï¼šç¼ºä¹æ•°æ®åˆ†æèƒ½åŠ›
2. **é”€å”®é¢„æµ‹ä¸å‡†ç¡®**ï¼šé”€å”®é¢„æµ‹ä¸å‡†ç¡®
3. **å®¢æˆ·åˆ†æç¼ºå¤±**ï¼šç¼ºä¹å®¢æˆ·è¡Œä¸ºåˆ†æ
4. **æŠ¥è¡¨ç”Ÿæˆæ•ˆç‡ä½**ï¼šæŠ¥è¡¨ç”Ÿæˆæ•ˆç‡ä½

**ä¸šåŠ¡ç›®æ ‡**ï¼š

- å¢å¼ºæ•°æ®åˆ†æèƒ½åŠ›
- æé«˜é”€å”®é¢„æµ‹å‡†ç¡®æ€§
- åŠ å¼ºå®¢æˆ·è¡Œä¸ºåˆ†æ
- æé«˜æŠ¥è¡¨ç”Ÿæˆæ•ˆç‡

### 2.2 æŠ€æœ¯æŒ‘æˆ˜

1. **æ•°æ®æ”¶é›†**ï¼šä»å¤šä¸ªæ•°æ®æºæ”¶é›†æ•°æ®
2. **ç»Ÿè®¡åˆ†æ**ï¼šè¿›è¡Œç»Ÿè®¡åˆ†æ
3. **é¢„æµ‹åˆ†æ**ï¼šè¿›è¡Œé”€å”®é¢„æµ‹
4. **æŠ¥è¡¨ç”Ÿæˆ**ï¼šè‡ªåŠ¨ç”Ÿæˆåˆ†ææŠ¥è¡¨

### 2.3 è§£å†³æ–¹æ¡ˆ

**ä½¿ç”¨Schemaå®šä¹‰é”€å”®æ•°æ®åˆ†æç³»ç»Ÿ**ï¼š

### 2.4 å®Œæ•´ä»£ç å®ç°

**é”€å”®æ•°æ®åˆ†æSchemaï¼ˆå®Œæ•´ç¤ºä¾‹ï¼‰**ï¼š

```python
#!/usr/bin/env python3
"""
æ•°æ®åˆ†æSchemaå®ç°
"""

from typing import Dict, List, Optional
from datetime import date, datetime
from decimal import Decimal
from dataclasses import dataclass, field
from enum import Enum

class AnalysisType(str, Enum):
    """åˆ†æç±»å‹"""
    DESCRIPTIVE = "Descriptive"
    PREDICTIVE = "Predictive"
    PRESCRIPTIVE = "Prescriptive"

class ForecastType(str, Enum):
    """é¢„æµ‹ç±»å‹"""
    TIME_SERIES = "TimeSeries"
    REGRESSION = "Regression"
    MACHINE_LEARNING = "MachineLearning"

@dataclass
class DataSource:
    """æ•°æ®æº"""
    source_id: str
    source_type: str
    source_connection: str
    source_name: Optional[str] = None

@dataclass
class DataCollection:
    """æ•°æ®æ”¶é›†"""
    data_sources: List[DataSource] = field(default_factory=list)

    def add_data_source(self, source: DataSource):
        """æ·»åŠ æ•°æ®æº"""
        self.data_sources.append(source)

@dataclass
class Analysis:
    """åˆ†æ"""
    analysis_id: str
    analysis_type: AnalysisType
    analysis_method: str
    output_results: Dict[str, Decimal] = field(default_factory=dict)
    analysis_date: datetime = field(default_factory=datetime.now)

@dataclass
class StatisticalAnalysis:
    """ç»Ÿè®¡åˆ†æ"""
    analyses: List[Analysis] = field(default_factory=list)

    def add_analysis(self, analysis: Analysis):
        """æ·»åŠ åˆ†æ"""
        self.analyses.append(analysis)

@dataclass
class Forecast:
    """é¢„æµ‹"""
    forecast_id: str
    forecast_type: ForecastType
    forecast_period_start: date
    forecast_period_end: date
    forecast_values: Dict[str, Decimal] = field(default_factory=dict)
    confidence_interval: Optional[Dict[str, Decimal]] = None
    created_at: datetime = field(default_factory=datetime.now)

@dataclass
class PredictiveAnalysis:
    """é¢„æµ‹åˆ†æ"""
    forecasts: List[Forecast] = field(default_factory=list)

    def add_forecast(self, forecast: Forecast):
        """æ·»åŠ é¢„æµ‹"""
        self.forecasts.append(forecast)

@dataclass
class DataAnalysis:
    """æ•°æ®åˆ†æ"""
    statistical_analysis: StatisticalAnalysis = field(default_factory=StatisticalAnalysis)
    predictive_analysis: PredictiveAnalysis = field(default_factory=PredictiveAnalysis)

@dataclass
class SalesDataAnalysis:
    """é”€å”®æ•°æ®åˆ†æ"""
    data_collection: DataCollection
    data_analysis: DataAnalysis

    def add_data_source(self, source: DataSource):
        """æ·»åŠ æ•°æ®æº"""
        self.data_collection.add_data_source(source)

    def perform_trend_analysis(self, analysis_id: str) -> Analysis:
        """æ‰§è¡Œè¶‹åŠ¿åˆ†æ"""
        analysis = Analysis(
            analysis_id=analysis_id,
            analysis_type=AnalysisType.DESCRIPTIVE,
            analysis_method="Time Series Analysis"
        )
        # æ¨¡æ‹Ÿåˆ†æç»“æœ
        analysis.output_results = {
            'average_sales': Decimal('100000.00'),
            'growth_rate': Decimal('10.50'),
            'trend': Decimal('1.05')
        }
        self.data_analysis.statistical_analysis.add_analysis(analysis)
        return analysis

    def generate_forecast(self, forecast_id: str, period_start: date, period_end: date) -> Forecast:
        """ç”Ÿæˆé¢„æµ‹"""
        forecast = Forecast(
            forecast_id=forecast_id,
            forecast_type=ForecastType.TIME_SERIES,
            forecast_period_start=period_start,
            forecast_period_end=period_end
        )
        # æ¨¡æ‹Ÿé¢„æµ‹å€¼
        forecast.forecast_values = {
            'predicted_sales': Decimal('110000.00'),
            'predicted_growth': Decimal('10.00')
        }
        self.data_analysis.predictive_analysis.add_forecast(forecast)
        return forecast

    def get_analysis_summary(self) -> Dict:
        """è·å–åˆ†ææ‘˜è¦"""
        return {
            'data_sources_count': len(self.data_collection.data_sources),
            'statistical_analyses_count': len(self.data_analysis.statistical_analysis.analyses),
            'forecasts_count': len(self.data_analysis.predictive_analysis.forecasts),
            'latest_analysis': {
                'id': self.data_analysis.statistical_analysis.analyses[-1].analysis_id if self.data_analysis.statistical_analysis.analyses else None,
                'type': self.data_analysis.statistical_analysis.analyses[-1].analysis_type.value if self.data_analysis.statistical_analysis.analyses else None
            } if self.data_analysis.statistical_analysis.analyses else None
        }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # åˆ›å»ºé”€å”®æ•°æ®åˆ†æç³»ç»Ÿ
    sales_analysis = SalesDataAnalysis(
        data_collection=DataCollection(),
        data_analysis=DataAnalysis()
    )

    # æ·»åŠ æ•°æ®æº
    data_source = DataSource(
        source_id="DS-SALES",
        source_type="Database",
        source_connection="postgresql://sales_db"
    )
    sales_analysis.add_data_source(data_source)

    # æ‰§è¡Œè¶‹åŠ¿åˆ†æ
    trend_analysis = sales_analysis.perform_trend_analysis("ANALYSIS-SALES-TREND")
    print(f"è¶‹åŠ¿åˆ†æç»“æœ: {trend_analysis.output_results}")

    # ç”Ÿæˆé¢„æµ‹
    forecast = sales_analysis.generate_forecast(
        "FORECAST-SALES-2025",
        date(2025, 1, 1),
        date(2025, 12, 31)
    )
    print(f"é¢„æµ‹ç»“æœ: {forecast.forecast_values}")

    # è·å–åˆ†ææ‘˜è¦
    summary = sales_analysis.get_analysis_summary()
    print(f"åˆ†ææ‘˜è¦: {summary}")
```

### 2.5 æ•ˆæœè¯„ä¼°

**æ€§èƒ½æŒ‡æ ‡**ï¼š

| æŒ‡æ ‡ | æ”¹è¿›å‰ | æ”¹è¿›å | æå‡ |
|------|--------|--------|------|
| æ•°æ®åˆ†æèƒ½åŠ› | ä½ | é«˜ | æ˜¾è‘—æå‡ |
| é”€å”®é¢„æµ‹å‡†ç¡®æ€§ | 70% | 85% | 15%æå‡ |
| å®¢æˆ·åˆ†æå®Œæ•´æ€§ | 60% | 90% | 30%æå‡ |
| æŠ¥è¡¨ç”Ÿæˆæ•ˆç‡ | ä½ | é«˜ | æ˜¾è‘—æå‡ |

**ä¸šåŠ¡ä»·å€¼**ï¼š

1. **åˆ†æèƒ½åŠ›å¢å¼º**ï¼šå¢å¼ºæ•°æ®åˆ†æèƒ½åŠ›
2. **é¢„æµ‹å‡†ç¡®æ€§æé«˜**ï¼šæé«˜é”€å”®é¢„æµ‹å‡†ç¡®æ€§
3. **å®¢æˆ·åˆ†æåŠ å¼º**ï¼šåŠ å¼ºå®¢æˆ·è¡Œä¸ºåˆ†æ
4. **æŠ¥è¡¨æ•ˆç‡æé«˜**ï¼šæé«˜æŠ¥è¡¨ç”Ÿæˆæ•ˆç‡

**ç»éªŒæ•™è®­**ï¼š

1. æ•°æ®æ”¶é›†å¾ˆé‡è¦
2. åˆ†ææ–¹æ³•éœ€è¦åˆç†é€‰æ‹©
3. é¢„æµ‹æ¨¡å‹éœ€è¦æŒç»­ä¼˜åŒ–
4. æŠ¥è¡¨ç”Ÿæˆéœ€è¦è‡ªåŠ¨åŒ–

**å‚è€ƒæ¡ˆä¾‹**ï¼š

- [æ•°æ®åˆ†ææœ€ä½³å®è·µ](https://www.kdnuggets.com/)
- [é¢„æµ‹åˆ†ææŒ‡å—](https://www.analyticsvidhya.com/)

---

## 3. æ¡ˆä¾‹2ï¼šå®¢æˆ·è¡Œä¸ºåˆ†æ

### 3.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
ä¼ä¸šå®¢æˆ·è¡Œä¸ºåˆ†æï¼ŒåŒ…æ‹¬å®¢æˆ·ç»†åˆ†ã€å®¢æˆ·é¢„æµ‹ã€å®¢æˆ·ä»·å€¼åˆ†æã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- å®¢æˆ·ç»†åˆ†
- å®¢æˆ·è¡Œä¸ºé¢„æµ‹
- å®¢æˆ·ä»·å€¼åˆ†æ
- å®¢æˆ·æ¨è

### 3.2 Schemaå®šä¹‰

**å®¢æˆ·è¡Œä¸ºåˆ†æSchema**ï¼š

```dsl
schema CustomerBehaviorAnalysis {
  data_analysis: DataAnalysis {
    machine_learning: MachineLearning {
      models: List<MLModel> {
        model1: MLModel {
          model_id: String @value("MODEL-CUSTOMER-SEGMENT")
          model_type: Enum @value("Unsupervised")
          algorithm: String @value("K-Means Clustering")
          model_accuracy: Decimal @value(90.00)
        }
        model2: MLModel {
          model_id: String @value("MODEL-CUSTOMER-PREDICT")
          model_type: Enum @value("Supervised")
          algorithm: String @value("Random Forest")
          model_accuracy: Decimal @value(85.00)
        }
      }
      predictions: List<Prediction> {
        prediction1: Prediction {
          prediction_id: String @value("PRED-CUSTOMER-001")
          model_id: String @value("MODEL-CUSTOMER-PREDICT")
          predicted_value: Decimal @value(5000.00)
          confidence_score: Decimal @value(88.00)
        }
      }
    }
  }
} @standard("Machine Learning")
```

---

## 4. æ¡ˆä¾‹3ï¼šé¢„æµ‹åˆ†æ

### 4.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
ä¼ä¸šé¢„æµ‹åˆ†æï¼ŒåŒ…æ‹¬éœ€æ±‚é¢„æµ‹ã€é”€å”®é¢„æµ‹ã€é£é™©é¢„æµ‹ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- éœ€æ±‚é¢„æµ‹
- é”€å”®é¢„æµ‹
- é£é™©é¢„æµ‹
- é¢„æµ‹å‡†ç¡®æ€§è¯„ä¼°

### 4.2 Schemaå®šä¹‰

**é¢„æµ‹åˆ†æSchema**ï¼š

```dsl
schema PredictiveAnalysis {
  predictive_analysis: PredictiveAnalysis {
    forecasts: List<Forecast> {
      forecast1: Forecast {
        forecast_id: String @value("FORECAST-DEMAND-2025")
        forecast_type: Enum @value("TimeSeries")
        forecast_method: String @value("ARIMA")
        forecast_period: Date @value("2025-12-31")
        forecast_value: Decimal @value(1000000.00)
        confidence_level: Decimal @value(90.00)
      }
      forecast2: Forecast {
        forecast_id: String @value("FORECAST-SALES-2025")
        forecast_type: Enum @value("Regression")
        forecast_method: String @value("Linear Regression")
        forecast_period: Date @value("2025-12-31")
        forecast_value: Decimal @value(2000000.00)
        confidence_level: Decimal @value(85.00)
      }
    }
  }
} @standard("Predictive Analytics")
```

---

## 5. æ¡ˆä¾‹4ï¼šæ•°æ®åˆ†æåˆ°æ•°æ®ä»“åº“è½¬æ¢

### 5.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
å°†ä¼ä¸šæ•°æ®åˆ†æç»“æœè½¬æ¢ä¸ºæ•°æ®ä»“åº“æ ¼å¼ï¼Œç”¨äºæ•°æ®ä»“åº“å»ºè®¾ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- åˆ†æç»“æœè½¬æ¢ä¸ºäº‹å®è¡¨
- åˆ†æç»´åº¦è½¬æ¢ä¸ºç»´åº¦è¡¨
- åˆ†ææŒ‡æ ‡è½¬æ¢ä¸ºåº¦é‡å€¼

### 5.2 å®ç°ä»£ç 

```python
from data_analytics_schema import DataAnalyticsSchema
from data_warehouse_schema import DataWarehouseSchema, StarSchema, FactTable, DimensionTable

def convert_analytics_to_data_warehouse(analytics_data: DataAnalyticsSchema) -> DataWarehouseSchema:
    """å°†æ•°æ®åˆ†ææ•°æ®è½¬æ¢ä¸ºæ•°æ®ä»“åº“æ ¼å¼"""
    dw_schema = DataWarehouseSchema()

    # è½¬æ¢æ˜Ÿå‹æ¨¡å¼
    star_schema = StarSchema()

    # åˆ›å»ºé”€å”®äº‹å®è¡¨
    fact_table = FactTable()
    fact_table.fact_table_name = "sales_fact"
    fact_table.measures = [
        {"name": "sales_amount", "type": "Decimal"},
        {"name": "quantity", "type": "Integer"},
        {"name": "profit", "type": "Decimal"}
    ]
    fact_table.grain = "Daily Sales by Product and Customer"
    star_schema.fact_tables.append(fact_table)

    # åˆ›å»ºäº§å“ç»´åº¦è¡¨
    product_dimension = DimensionTable()
    product_dimension.dimension_name = "product_dimension"
    product_dimension.dimension_attributes = [
        "product_id", "product_name", "product_category", "product_price"
    ]
    star_schema.dimension_tables.append(product_dimension)

    # åˆ›å»ºå®¢æˆ·ç»´åº¦è¡¨
    customer_dimension = DimensionTable()
    customer_dimension.dimension_name = "customer_dimension"
    customer_dimension.dimension_attributes = [
        "customer_id", "customer_name", "customer_segment", "customer_region"
    ]
    star_schema.dimension_tables.append(customer_dimension)

    dw_schema.star_schema = star_schema

    return dw_schema

# ä½¿ç”¨ç¤ºä¾‹
analytics_data = DataAnalyticsSchema.load_from_database("2025-01")
dw_schema = convert_analytics_to_data_warehouse(analytics_data)
dw_schema.save_to_database()
```

---

## 6. æ¡ˆä¾‹5ï¼šæ•°æ®åˆ†ææ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿ

### 6.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
ä¼ä¸šæ•°æ®åˆ†ææ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿï¼Œæ”¯æŒæ•°æ®åˆ†ææ•°æ®å­˜å‚¨ã€æŸ¥è¯¢ã€åˆ†æå’ŒæŠ¥è¡¨ç”Ÿæˆã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- PostgreSQLæ•°æ®åº“å­˜å‚¨
- æ”¯æŒå¤æ‚æŸ¥è¯¢å’Œåˆ†æ
- æ”¯æŒæ•°æ®è´¨é‡ç›‘æ§
- æ”¯æŒæ¨¡å‹æ€§èƒ½åˆ†æ

### 6.2 å®ç°ä»£ç 

```python
import psycopg2
from data_analytics_schema import DataAnalyticsSchema, DataSource, MLModel

class AnalyticsDataStore:
    def __init__(self, db_config):
        self.conn = psycopg2.connect(**db_config)

    def store_analytics_data(self, analytics_data: DataAnalyticsSchema):
        """å­˜å‚¨æ•°æ®åˆ†ææ•°æ®"""
        cursor = self.conn.cursor()

        # æ’å…¥æ•°æ®æº
        for source in analytics_data.data_collection.data_sources:
            cursor.execute("""
                INSERT INTO data_sources
                (source_id, source_type, source_connection, is_active)
                VALUES (%s, %s, %s, %s)
            """, (source.source_id, source.source_type,
                  source.source_connection, source.is_active))

        # æ’å…¥æœºå™¨å­¦ä¹ æ¨¡å‹
        for model in analytics_data.data_analysis.machine_learning.models:
            cursor.execute("""
                INSERT INTO ml_models
                (model_id, model_type, algorithm, model_accuracy, training_date, model_version)
                VALUES (%s, %s, %s, %s, %s, %s)
            """, (model.model_id, model.model_type, model.algorithm,
                  model.model_accuracy, "2025-01-21", "v1.0"))

        self.conn.commit()

    def generate_analytics_report(self, period_start, period_end):
        """ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Š"""
        cursor = self.conn.cursor()

        # æŸ¥è¯¢æ•°æ®è´¨é‡è¶‹åŠ¿
        cursor.execute("""
            SELECT
                check_date,
                AVG(metric_value) as avg_quality_score,
                COUNT(CASE WHEN is_passed THEN 1 END) as passed_metrics,
                COUNT(*) as total_metrics
            FROM data_quality_metrics
            WHERE check_date BETWEEN %s AND %s
            GROUP BY check_date
            ORDER BY check_date
        """, (period_start, period_end))

        quality_trends = cursor.fetchall()

        # æŸ¥è¯¢æ¨¡å‹æ€§èƒ½
        cursor.execute("""
            SELECT
                model_type,
                AVG(model_accuracy) as avg_accuracy,
                COUNT(*) as model_count
            FROM ml_models
            WHERE training_date BETWEEN %s AND %s
            GROUP BY model_type
            ORDER BY avg_accuracy DESC
        """, (period_start, period_end))

        model_performance = cursor.fetchall()

        return {
            "quality_trends": quality_trends,
            "model_performance": model_performance
        }

# ä½¿ç”¨ç¤ºä¾‹
db_config = {
    "host": "localhost",
    "database": "data_analytics",
    "user": "analytics_user",
    "password": "password"
}

store = AnalyticsDataStore(db_config)

# ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Š
analytics_report = store.generate_analytics_report("2025-01-01", "2025-12-31")
print("æ•°æ®è´¨é‡è¶‹åŠ¿:")
for row in analytics_report["quality_trends"]:
    print(f"æ—¥æœŸ: {row[0]}, å¹³å‡è´¨é‡: {row[1]:.2f}, é€šè¿‡: {row[2]}/{row[3]}")

print("\næ¨¡å‹æ€§èƒ½:")
for row in analytics_report["model_performance"]:
    print(f"{row[0]}: å¹³å‡å‡†ç¡®ç‡={row[1]:.2f}%, æ¨¡å‹æ•°={row[2]}")
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `04_Transformation.md` - è½¬æ¢ä½“ç³»

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
