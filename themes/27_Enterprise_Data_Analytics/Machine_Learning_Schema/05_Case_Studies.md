# æœºå™¨å­¦ä¹ Schemaå®è·µæ¡ˆä¾‹

## ğŸ“‘ ç›®å½•

- [æœºå™¨å­¦ä¹ Schemaå®è·µæ¡ˆä¾‹](#æœºå™¨å­¦ä¹ schemaå®è·µæ¡ˆä¾‹)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¡ˆä¾‹æ¦‚è¿°](#1-æ¡ˆä¾‹æ¦‚è¿°)
  - [2. æ¡ˆä¾‹1ï¼šMLflowå®éªŒç®¡ç†](#2-æ¡ˆä¾‹1mlflowå®éªŒç®¡ç†)
    - [2.1 åœºæ™¯æè¿°](#21-åœºæ™¯æè¿°)
    - [2.2 Schemaå®šä¹‰](#22-schemaå®šä¹‰)
  - [3. æ¡ˆä¾‹2ï¼šæ¨¡å‹è®­ç»ƒä¸æ³¨å†Œ](#3-æ¡ˆä¾‹2æ¨¡å‹è®­ç»ƒä¸æ³¨å†Œ)
    - [3.1 åœºæ™¯æè¿°](#31-åœºæ™¯æè¿°)
    - [3.2 å®ç°ä»£ç ](#32-å®ç°ä»£ç )
  - [4. æ¡ˆä¾‹3ï¼šæ¨¡å‹æœåŠ¡ä¸ç›‘æ§](#4-æ¡ˆä¾‹3æ¨¡å‹æœåŠ¡ä¸ç›‘æ§)
    - [4.1 åœºæ™¯æè¿°](#41-åœºæ™¯æè¿°)
    - [4.2 å®ç°ä»£ç ](#42-å®ç°ä»£ç )
  - [5. æ¡ˆä¾‹4ï¼šæœºå™¨å­¦ä¹ åˆ°MLflowè½¬æ¢](#5-æ¡ˆä¾‹4æœºå™¨å­¦ä¹ åˆ°mlflowè½¬æ¢)
    - [5.1 åœºæ™¯æè¿°](#51-åœºæ™¯æè¿°)
    - [5.2 å®ç°ä»£ç ](#52-å®ç°ä»£ç )
  - [6. æ¡ˆä¾‹5ï¼šæœºå™¨å­¦ä¹ æ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿ](#6-æ¡ˆä¾‹5æœºå™¨å­¦ä¹ æ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿ)
    - [6.1 åœºæ™¯æè¿°](#61-åœºæ™¯æè¿°)
    - [6.2 å®ç°ä»£ç ](#62-å®ç°ä»£ç )

---

## 1. æ¡ˆä¾‹æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›æœºå™¨å­¦ä¹ Schemaåœ¨å®é™…åº”ç”¨ä¸­çš„å®è·µæ¡ˆä¾‹ã€‚

---

## 2. æ¡ˆä¾‹1ï¼šMLflowå®éªŒç®¡ç†

### 2.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
ä½¿ç”¨MLflowç®¡ç†æœºå™¨å­¦ä¹ å®éªŒï¼Œè·Ÿè¸ªå®éªŒå‚æ•°ã€æŒ‡æ ‡ã€ç»“æœã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- æ”¯æŒå®éªŒåˆ›å»ºå’Œç®¡ç†
- æ”¯æŒè¿è¡Œè·Ÿè¸ªå’Œæ¯”è¾ƒ
- æ”¯æŒå®éªŒé‡ç°

### 2.2 Schemaå®šä¹‰

**MLflowå®éªŒç®¡ç†Schema**ï¼š

```dsl
schema MLflowExperimentManagement {
  experiment: Experiment {
    experiment_id: String @value("EXP-20250001")
    experiment_name: String @value("CustomerChurnPrediction")
    experiment_description: String @value("å®¢æˆ·æµå¤±é¢„æµ‹å®éªŒ")
    experiment_tags: List<String> {
      "classification"
      "customer_analytics"
    }
  }

  run: Run {
    run_id: String @value("RUN-20250001")
    experiment_id: String @value("EXP-20250001")
    run_name: String @value("RandomForest_v1")
    run_status: Enum @value("Finished")
    parameters: Map<String, String> {
      "n_estimators": String @value("100")
      "max_depth": String @value("10")
      "learning_rate": String @value("0.01")
    }
    metrics: Map<String, Decimal> {
      "accuracy": Decimal @value(0.85)
      "precision": Decimal @value(0.82)
      "recall": Decimal @value(0.88)
    }
  }
}
```

---

## 3. æ¡ˆä¾‹2ï¼šæ¨¡å‹è®­ç»ƒä¸æ³¨å†Œ

### 3.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹å¹¶æ³¨å†Œåˆ°æ¨¡å‹æ³¨å†Œè¡¨ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- æ”¯æŒæ¨¡å‹è®­ç»ƒ
- æ”¯æŒæ¨¡å‹æ³¨å†Œ
- æ”¯æŒæ¨¡å‹ç‰ˆæœ¬ç®¡ç†

### 3.2 å®ç°ä»£ç 

```python
def train_and_register_model(ml_data: MachineLearningSchema) -> ModelVersion:
    """è®­ç»ƒå¹¶æ³¨å†Œæ¨¡å‹"""
    import mlflow

    training_def = ml_data.model_training.training_definitions[0]

    # åˆ›å»ºå®éªŒ
    experiment = mlflow.create_experiment(training_def.definition_name)

    with mlflow.start_run(experiment_id=experiment):
        # è®­ç»ƒæ¨¡å‹
        model = train_model(training_def)

        # è®°å½•å‚æ•°
        mlflow.log_params({
            "optimizer": training_def.training_config.optimizer,
            "learning_rate": training_def.training_config.learning_rate,
            "batch_size": training_def.training_config.batch_size,
            "epochs": training_def.training_config.epochs
        })

        # è¯„ä¼°æ¨¡å‹
        evaluation_metrics = evaluate_model(model, training_def.data_config.test_data_path)

        # è®°å½•æŒ‡æ ‡
        mlflow.log_metrics(evaluation_metrics)

        # æ³¨å†Œæ¨¡å‹
        mlflow.sklearn.log_model(
            model,
            "model",
            registered_model_name=training_def.definition_name
        )

        # è·å–æ¨¡å‹ç‰ˆæœ¬
        model_version = mlflow.get_model_version(
            name=training_def.definition_name,
            version=1
        )

        return model_version
```

---

## 4. æ¡ˆä¾‹3ï¼šæ¨¡å‹æœåŠ¡ä¸ç›‘æ§

### 4.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
éƒ¨ç½²æ¨¡å‹åˆ°ç”Ÿäº§ç¯å¢ƒå¹¶æä¾›APIæœåŠ¡ï¼Œç›‘æ§æ¨¡å‹æ€§èƒ½ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- æ”¯æŒæ¨¡å‹éƒ¨ç½²
- æ”¯æŒAPIæœåŠ¡
- æ”¯æŒæ€§èƒ½ç›‘æ§

### 4.2 å®ç°ä»£ç 

```python
def deploy_and_monitor_model(model_version: ModelVersion) -> ModelDeployment:
    """éƒ¨ç½²å¹¶ç›‘æ§æ¨¡å‹"""
    import mlflow

    # éƒ¨ç½²æ¨¡å‹
    deployment = ModelDeployment()
    deployment.deployment_id = f"DEPLOY-{model_version.version_id}"
    deployment.model_id = model_version.model_id
    deployment.version_id = model_version.version_id
    deployment.deployment_name = f"{model_version.model_name}_v{model_version.version_number}"
    deployment.deployment_environment = "Production"
    deployment.deployment_status = "Deploying"
    deployment.deployment_date = datetime.now()

    # ä½¿ç”¨MLflowéƒ¨ç½²æ¨¡å‹
    mlflow.deployments.create_deployment(
        name=deployment.deployment_name,
        model_uri=f"models:/{model_version.model_name}/{model_version.version_number}",
        target="production"
    )

    deployment.deployment_status = "Active"
    deployment.deployment_endpoint = f"https://api.example.com/models/{deployment.deployment_id}/predict"

    # åˆ›å»ºAPI
    api = ModelAPI()
    api.api_id = f"API-{deployment.deployment_id}"
    api.deployment_id = deployment.deployment_id
    api.api_endpoint = deployment.deployment_endpoint
    api.api_version = "v1"
    api.request_schema = {
        "type": "object",
        "properties": {
            "features": {
                "type": "array",
                "items": {"type": "number"}
            }
        }
    }
    api.response_schema = {
        "type": "object",
        "properties": {
            "prediction": {"type": "number"},
            "probability": {"type": "number"}
        }
    }

    deployment.model_apis = [api]

    # åˆ›å»ºç›‘æ§
    monitoring = ModelMonitoring()
    monitoring.monitoring_id = f"MON-{deployment.deployment_id}"
    monitoring.deployment_id = deployment.deployment_id

    # ç›‘æ§æŒ‡æ ‡
    monitoring.monitoring_metrics = [
        MonitoringMetric(
            metric_name="prediction_count",
            metric_type="Prediction_Count",
            metric_value=0,
            metric_timestamp=datetime.now()
        ),
        MonitoringMetric(
            metric_name="average_latency",
            metric_type="Latency",
            metric_value=0,
            metric_timestamp=datetime.now()
        )
    ]

    deployment.model_monitoring = [monitoring]

    return deployment

def monitor_model_performance(deployment_id: str, conn):
    """ç›‘æ§æ¨¡å‹æ€§èƒ½"""
    cursor = conn.cursor()

    # æŸ¥è¯¢é¢„æµ‹ç»Ÿè®¡
    cursor.execute("""
        SELECT
            COUNT(*) as prediction_count,
            AVG(latency_ms) as avg_latency,
            SUM(CASE WHEN error_occurred THEN 1 ELSE 0 END) * 100.0 / COUNT(*) as error_rate
        FROM model_predictions
        WHERE deployment_id = %s
        AND prediction_timestamp >= CURRENT_TIMESTAMP - INTERVAL '1 hour'
    """, (deployment_id,))

    performance_stats = cursor.fetchone()

    # æ›´æ–°ç›‘æ§æŒ‡æ ‡
    cursor.execute("""
        INSERT INTO model_monitoring_metrics
        (monitoring_id, metric_name, metric_type, metric_value, metric_timestamp)
        VALUES
        (%s, 'prediction_count', 'Prediction_Count', %s, CURRENT_TIMESTAMP),
        (%s, 'average_latency', 'Latency', %s, CURRENT_TIMESTAMP),
        (%s, 'error_rate', 'Error_Rate', %s, CURRENT_TIMESTAMP)
    """, (
        deployment_id, performance_stats[0],
        deployment_id, performance_stats[1],
        deployment_id, performance_stats[2]
    ))

    conn.commit()
```

---

## 5. æ¡ˆä¾‹4ï¼šæœºå™¨å­¦ä¹ åˆ°MLflowè½¬æ¢

### 5.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
å°†æœºå™¨å­¦ä¹ Schemaè½¬æ¢ä¸ºMLflowæ ¼å¼ï¼Œç”¨äºå®éªŒç®¡ç†ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- æ”¯æŒè‡ªåŠ¨è½¬æ¢åˆ°MLflow
- æ”¯æŒå®éªŒå’Œè¿è¡Œè·Ÿè¸ª
- æ”¯æŒæ¨¡å‹æ³¨å†Œ

### 5.2 å®ç°ä»£ç 

```python
def convert_ml_to_mlflow_complete(ml_data: MachineLearningSchema) -> MLflowExperiment:
    """å®Œæ•´è½¬æ¢æœºå™¨å­¦ä¹ Schemaåˆ°MLflow"""
    import mlflow

    experiment = ml_data.experiment_management.experiments[0]

    # åˆ›å»ºMLflowå®éªŒ
    mlflow_experiment = mlflow.create_experiment(experiment.experiment_name)

    # è½¬æ¢è¿è¡Œ
    for run in ml_data.experiment_management.runs:
        with mlflow.start_run(
            experiment_id=mlflow_experiment,
            run_name=run.run_name,
            nested=run.parent_run_id is not None
        ):
            # è®°å½•å‚æ•°
            if run.parameters:
                mlflow.log_params(run.parameters)

            # è®°å½•æŒ‡æ ‡
            if run.metrics:
                mlflow.log_metrics(run.metrics)

            # è®°å½•æ ‡ç­¾
            if run.tags:
                mlflow.set_tags(run.tags)

            # è®°å½•å·¥ä»¶
            for artifact in run.artifacts:
                if artifact.artifact_type == "Model":
                    mlflow.sklearn.log_model(
                        artifact.artifact_path,
                        "model",
                        registered_model_name=experiment.experiment_name
                    )
                else:
                    mlflow.log_artifact(artifact.artifact_path)

    return mlflow_experiment
```

---

## 6. æ¡ˆä¾‹5ï¼šæœºå™¨å­¦ä¹ æ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿ

### 6.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
æœºå™¨å­¦ä¹ æ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿï¼Œæ”¯æŒå…ƒæ•°æ®å­˜å‚¨ã€æŸ¥è¯¢ã€åˆ†æã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- æ”¯æŒæœºå™¨å­¦ä¹ å…ƒæ•°æ®å­˜å‚¨
- æ”¯æŒå…ƒæ•°æ®æŸ¥è¯¢å’Œåˆ†æ
- æ”¯æŒå®éªŒå’Œæ¨¡å‹æ€§èƒ½åˆ†æ

### 6.2 å®ç°ä»£ç 

```python
def store_ml_data(ml_data: MachineLearningSchema, conn):
    """å­˜å‚¨æœºå™¨å­¦ä¹ æ•°æ®åˆ°PostgreSQL"""
    cursor = conn.cursor()

    # å­˜å‚¨å®éªŒå…ƒæ•°æ®
    for experiment in ml_data.experiment_management.experiments:
        cursor.execute("""
            INSERT INTO experiment_metadata
            (experiment_id, experiment_name, experiment_description, created_by)
            VALUES (%s, %s, %s, %s)
            ON CONFLICT (experiment_id) DO UPDATE SET
            experiment_name = EXCLUDED.experiment_name,
            experiment_description = EXCLUDED.experiment_description,
            updated_at = CURRENT_TIMESTAMP
        """, (experiment.experiment_id, experiment.experiment_name,
              experiment.experiment_description, experiment.created_by))

    # å­˜å‚¨è¿è¡Œå…ƒæ•°æ®
    for run in ml_data.experiment_management.runs:
        cursor.execute("""
            INSERT INTO run_metadata
            (run_id, experiment_id, run_name, run_status, start_time, end_time, duration, parent_run_id)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (run_id) DO UPDATE SET
            run_status = EXCLUDED.run_status,
            end_time = EXCLUDED.end_time,
            duration = EXCLUDED.duration
        """, (run.run_id, run.experiment_id, run.run_name, run.run_status,
              run.start_time, run.end_time, run.duration, run.parent_run_id))

        # å­˜å‚¨è¿è¡Œå‚æ•°
        for param_name, param_value in run.parameters.items():
            cursor.execute("""
                INSERT INTO run_parameters
                (parameter_id, run_id, parameter_name, parameter_value)
                VALUES (%s, %s, %s, %s)
                ON CONFLICT (parameter_id) DO UPDATE SET
                parameter_value = EXCLUDED.parameter_value
            """, (f"PARAM-{run.run_id}-{param_name}", run.run_id, param_name, param_value))

        # å­˜å‚¨è¿è¡ŒæŒ‡æ ‡
        for metric_name, metric_value in run.metrics.items():
            cursor.execute("""
                INSERT INTO run_metrics
                (metric_id, run_id, metric_name, metric_value, metric_timestamp)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (metric_id) DO UPDATE SET
                metric_value = EXCLUDED.metric_value,
                metric_timestamp = EXCLUDED.metric_timestamp
            """, (f"METRIC-{run.run_id}-{metric_name}", run.run_id,
                  metric_name, metric_value, datetime.now()))

    # å­˜å‚¨æ¨¡å‹æ³¨å†Œ
    for model in ml_data.model_registry.registered_models:
        cursor.execute("""
            INSERT INTO model_registry
            (model_id, model_name, model_description, created_by)
            VALUES (%s, %s, %s, %s)
            ON CONFLICT (model_id) DO UPDATE SET
            model_name = EXCLUDED.model_name,
            model_description = EXCLUDED.model_description,
            updated_at = CURRENT_TIMESTAMP
        """, (model.model_id, model.model_name, model.model_description, model.created_by))

        # å­˜å‚¨æ¨¡å‹ç‰ˆæœ¬
        for version in ml_data.model_registry.model_versions:
            if version.model_id == model.model_id:
                cursor.execute("""
                    INSERT INTO model_versions
                    (version_id, model_id, version_number, version_stage, run_id, model_uri, model_format, created_by)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (version_id) DO UPDATE SET
                    version_stage = EXCLUDED.version_stage,
                    model_uri = EXCLUDED.model_uri
                """, (version.version_id, version.model_id, version.version_number,
                      version.version_stage, version.run_id, version.model_uri,
                      version.model_format, version.created_by))

    # å­˜å‚¨æ¨¡å‹éƒ¨ç½²
    for deployment in ml_data.model_serving.model_deployments:
        cursor.execute("""
            INSERT INTO model_deployments
            (deployment_id, model_id, version_id, deployment_name, deployment_environment,
             deployment_status, deployment_date, deployment_endpoint)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (deployment_id) DO UPDATE SET
            deployment_status = EXCLUDED.deployment_status,
            deployment_endpoint = EXCLUDED.deployment_endpoint
        """, (deployment.deployment_id, deployment.model_id, deployment.version_id,
              deployment.deployment_name, deployment.deployment_environment,
              deployment.deployment_status, deployment.deployment_date,
              deployment.deployment_endpoint))

    conn.commit()

def generate_ml_report(conn):
    """ç”Ÿæˆæœºå™¨å­¦ä¹ æŠ¥è¡¨"""
    cursor = conn.cursor()

    # æŸ¥è¯¢å®éªŒæ±‡æ€»
    cursor.execute("""
        SELECT
            em.experiment_name,
            COUNT(rm.run_id) as run_count,
            SUM(CASE WHEN rm.run_status = 'Finished' THEN 1 ELSE 0 END) as completed_runs
        FROM experiment_metadata em
        LEFT JOIN run_metadata rm ON em.experiment_id = rm.experiment_id
        GROUP BY em.experiment_id, em.experiment_name
        ORDER BY em.experiment_name
    """)

    experiment_report = cursor.fetchall()

    # æŸ¥è¯¢æ¨¡å‹éƒ¨ç½²æŠ¥è¡¨
    cursor.execute("""
        SELECT
            mr.model_name,
            mv.version_number,
            md.deployment_environment,
            md.deployment_status
        FROM model_registry mr
        JOIN model_versions mv ON mr.model_id = mv.model_id
        JOIN model_deployments md ON mv.version_id = md.version_id
        ORDER BY md.deployment_date DESC
    """)

    deployment_report = cursor.fetchall()

    return {
        "experiment_report": experiment_report,
        "deployment_report": deployment_report
    }
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `04_Transformation.md` - è½¬æ¢ä½“ç³»

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
