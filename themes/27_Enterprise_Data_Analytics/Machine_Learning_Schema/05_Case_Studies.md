# æœºå™¨å­¦ä¹ Schemaå®è·µæ¡ˆä¾‹

## ğŸ“‘ ç›®å½•

- [æœºå™¨å­¦ä¹ Schemaå®è·µæ¡ˆä¾‹](#æœºå™¨å­¦ä¹ schemaå®è·µæ¡ˆä¾‹)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¡ˆä¾‹æ¦‚è¿°](#1-æ¡ˆä¾‹æ¦‚è¿°)
  - [2. æ¡ˆä¾‹1ï¼šä¼ä¸šMLflowæœºå™¨å­¦ä¹ å®éªŒç®¡ç†ç³»ç»Ÿ](#2-æ¡ˆä¾‹1ä¼ä¸šmlflowæœºå™¨å­¦ä¹ å®éªŒç®¡ç†ç³»ç»Ÿ)
    - [2.1 ä¸šåŠ¡èƒŒæ™¯](#21-ä¸šåŠ¡èƒŒæ™¯)
    - [2.2 æŠ€æœ¯æŒ‘æˆ˜](#22-æŠ€æœ¯æŒ‘æˆ˜)
    - [2.3 è§£å†³æ–¹æ¡ˆ](#23-è§£å†³æ–¹æ¡ˆ)
    - [2.4 å®Œæ•´ä»£ç å®ç°](#24-å®Œæ•´ä»£ç å®ç°)
    - [2.5 æ•ˆæœè¯„ä¼°](#25-æ•ˆæœè¯„ä¼°)
  - [3. æ¡ˆä¾‹2ï¼šæ¨¡å‹è®­ç»ƒä¸æ³¨å†Œ](#3-æ¡ˆä¾‹2æ¨¡å‹è®­ç»ƒä¸æ³¨å†Œ)
    - [3.1 åœºæ™¯æè¿°](#31-åœºæ™¯æè¿°)
    - [3.2 å®ç°ä»£ç ](#32-å®ç°ä»£ç )
  - [4. æ¡ˆä¾‹3ï¼šæ¨¡å‹æœåŠ¡ä¸ç›‘æ§](#4-æ¡ˆä¾‹3æ¨¡å‹æœåŠ¡ä¸ç›‘æ§)
    - [4.1 åœºæ™¯æè¿°](#41-åœºæ™¯æè¿°)
    - [4.2 å®ç°ä»£ç ](#42-å®ç°ä»£ç )
  - [5. æ¡ˆä¾‹4ï¼šæœºå™¨å­¦ä¹ åˆ°MLflowè½¬æ¢](#5-æ¡ˆä¾‹4æœºå™¨å­¦ä¹ åˆ°mlflowè½¬æ¢)
    - [5.1 åœºæ™¯æè¿°](#51-åœºæ™¯æè¿°)
    - [5.2 å®ç°ä»£ç ](#52-å®ç°ä»£ç )
  - [6. æ¡ˆä¾‹5ï¼šæœºå™¨å­¦ä¹ æ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿ](#6-æ¡ˆä¾‹5æœºå™¨å­¦ä¹ æ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿ)
    - [6.1 åœºæ™¯æè¿°](#61-åœºæ™¯æè¿°)
    - [6.2 å®ç°ä»£ç ](#62-å®ç°ä»£ç )

---

## 1. æ¡ˆä¾‹æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›æœºå™¨å­¦ä¹ Schemaåœ¨å®é™…ä¼ä¸šåº”ç”¨ä¸­çš„å®è·µæ¡ˆä¾‹ï¼Œæ¶µç›–MLflowå®éªŒç®¡ç†ã€æ¨¡å‹è®­ç»ƒä¸æ³¨å†Œã€æ¨¡å‹æœåŠ¡ä¸ç›‘æ§ç­‰çœŸå®åœºæ™¯ã€‚

**æ¡ˆä¾‹ç±»å‹**ï¼š

1. **ä¼ä¸šMLflowæœºå™¨å­¦ä¹ å®éªŒç®¡ç†ç³»ç»Ÿ**ï¼šå®éªŒè·Ÿè¸ªå’Œç®¡ç†
2. **æ¨¡å‹è®­ç»ƒä¸æ³¨å†Œç³»ç»Ÿ**ï¼šæ¨¡å‹è®­ç»ƒå’Œç‰ˆæœ¬ç®¡ç†
3. **æ¨¡å‹æœåŠ¡ä¸ç›‘æ§ç³»ç»Ÿ**ï¼šæ¨¡å‹éƒ¨ç½²å’Œç›‘æ§
4. **æœºå™¨å­¦ä¹ åˆ°MLflowè½¬æ¢å·¥å…·**ï¼šML Schemaåˆ°MLflowè½¬æ¢
5. **æœºå™¨å­¦ä¹ æ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿ**ï¼šMLæ•°æ®åˆ†æå’Œç›‘æ§

**å‚è€ƒä¼ä¸šæ¡ˆä¾‹**ï¼š

- **MLflowå®˜æ–¹**ï¼šMLflowå®éªŒç®¡ç†æœ€ä½³å®è·µ
- **æœºå™¨å­¦ä¹ Ops**ï¼šMLOpsæœ€ä½³å®è·µ

---

## 2. æ¡ˆä¾‹1ï¼šä¼ä¸šMLflowæœºå™¨å­¦ä¹ å®éªŒç®¡ç†ç³»ç»Ÿ

### 2.1 ä¸šåŠ¡èƒŒæ™¯

**ä¼ä¸šèƒŒæ™¯**ï¼š
æŸç”µå•†å…¬å¸éœ€è¦æ„å»ºæœºå™¨å­¦ä¹ å®éªŒç®¡ç†ç³»ç»Ÿï¼Œä½¿ç”¨MLflowè·Ÿè¸ªå’Œç®¡ç†æœºå™¨å­¦ä¹ å®éªŒï¼Œæé«˜æ¨¡å‹å¼€å‘æ•ˆç‡å’Œå¯é‡ç°æ€§ã€‚

**ä¸šåŠ¡ç—›ç‚¹**ï¼š

1. **å®éªŒç®¡ç†æ··ä¹±**ï¼šå®éªŒå‚æ•°ã€ç»“æœéš¾ä»¥è¿½è¸ª
2. **å®éªŒé‡ç°å›°éš¾**ï¼šæ— æ³•é‡ç°å†å²å®éªŒ
3. **æ¨¡å‹ç‰ˆæœ¬ç®¡ç†ç¼ºå¤±**ï¼šç¼ºä¹æ¨¡å‹ç‰ˆæœ¬ç®¡ç†
4. **å®éªŒæ¯”è¾ƒå›°éš¾**ï¼šéš¾ä»¥æ¯”è¾ƒä¸åŒå®éªŒæ•ˆæœ

**ä¸šåŠ¡ç›®æ ‡**ï¼š

- ç»Ÿä¸€å®éªŒç®¡ç†
- æ”¯æŒå®éªŒé‡ç°
- è§„èŒƒæ¨¡å‹ç‰ˆæœ¬ç®¡ç†
- æ”¯æŒå®éªŒæ¯”è¾ƒ

### 2.2 æŠ€æœ¯æŒ‘æˆ˜

1. **å®éªŒè·Ÿè¸ª**ï¼šè·Ÿè¸ªå®éªŒå‚æ•°ã€æŒ‡æ ‡ã€ç»“æœ
2. **æ¨¡å‹æ³¨å†Œ**ï¼šæ³¨å†Œå’Œç®¡ç†æ¨¡å‹ç‰ˆæœ¬
3. **å®éªŒé‡ç°**ï¼šç¡®ä¿å®éªŒå¯é‡ç°
4. **æ¨¡å‹æœåŠ¡**ï¼šæ¨¡å‹éƒ¨ç½²å’ŒæœåŠ¡åŒ–

### 2.3 è§£å†³æ–¹æ¡ˆ

**ä½¿ç”¨Schemaå®šä¹‰MLflowå®éªŒç®¡ç†ç³»ç»Ÿ**ï¼š

### 2.4 å®Œæ•´ä»£ç å®ç°

**MLflowå®éªŒç®¡ç†Schemaï¼ˆå®Œæ•´ç¤ºä¾‹ï¼‰**ï¼š

```python
#!/usr/bin/env python3
"""
æœºå™¨å­¦ä¹ å®éªŒç®¡ç†Schemaå®ç°
"""

from typing import Dict, List, Optional
from datetime import datetime
from decimal import Decimal
from dataclasses import dataclass, field
from enum import Enum

class RunStatus(str, Enum):
    """è¿è¡ŒçŠ¶æ€"""
    RUNNING = "Running"
    FINISHED = "Finished"
    FAILED = "Failed"
    KILLED = "Killed"

@dataclass
class Experiment:
    """å®éªŒ"""
    experiment_id: str
    experiment_name: str
    experiment_description: Optional[str] = None
    experiment_tags: List[str] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.now)
    created_by: str = ""

    def add_tag(self, tag: str):
        """æ·»åŠ æ ‡ç­¾"""
        if tag not in self.experiment_tags:
            self.experiment_tags.append(tag)

@dataclass
class Run:
    """è¿è¡Œ"""
    run_id: str
    experiment_id: str
    run_name: str
    run_status: RunStatus = RunStatus.RUNNING
    parameters: Dict[str, str] = field(default_factory=dict)
    metrics: Dict[str, Decimal] = field(default_factory=dict)
    tags: Dict[str, str] = field(default_factory=dict)
    artifacts: List[str] = field(default_factory=list)
    start_time: datetime = field(default_factory=datetime.now)
    end_time: Optional[datetime] = None

    def add_parameter(self, key: str, value: str):
        """æ·»åŠ å‚æ•°"""
        self.parameters[key] = value

    def add_metric(self, key: str, value: Decimal):
        """æ·»åŠ æŒ‡æ ‡"""
        self.metrics[key] = value

    def finish(self, status: RunStatus = RunStatus.FINISHED):
        """å®Œæˆè¿è¡Œ"""
        self.run_status = status
        self.end_time = datetime.now()

@dataclass
class ModelVersion:
    """æ¨¡å‹ç‰ˆæœ¬"""
    version_id: str
    model_name: str
    run_id: str
    version: int
    stage: str = "None"  # None, Staging, Production, Archived
    description: Optional[str] = None
    created_at: datetime = field(default_factory=datetime.now)
    created_by: str = ""

    def promote_to_staging(self):
        """æå‡åˆ°Staging"""
        self.stage = "Staging"

    def promote_to_production(self):
        """æå‡åˆ°Production"""
        self.stage = "Production"

    def archive(self):
        """å½’æ¡£"""
        self.stage = "Archived"

@dataclass
class MLflowExperimentManagement:
    """MLflowå®éªŒç®¡ç†"""
    experiments: Dict[str, Experiment] = field(default_factory=dict)
    runs: Dict[str, Run] = field(default_factory=dict)
    model_versions: Dict[str, ModelVersion] = field(default_factory=dict)

    def create_experiment(self, experiment_name: str, description: Optional[str] = None) -> Experiment:
        """åˆ›å»ºå®éªŒ"""
        experiment_id = f"EXP-{datetime.now().strftime('%Y%m%d%H%M%S')}"
        experiment = Experiment(
            experiment_id=experiment_id,
            experiment_name=experiment_name,
            experiment_description=description
        )
        self.experiments[experiment_id] = experiment
        return experiment

    def create_run(self, experiment_id: str, run_name: str) -> Run:
        """åˆ›å»ºè¿è¡Œ"""
        if experiment_id not in self.experiments:
            raise ValueError(f"Experiment {experiment_id} not found")

        run_id = f"RUN-{datetime.now().strftime('%Y%m%d%H%M%S')}"
        run = Run(
            run_id=run_id,
            experiment_id=experiment_id,
            run_name=run_name
        )
        self.runs[run_id] = run
        return run

    def register_model(self, model_name: str, run_id: str, description: Optional[str] = None) -> ModelVersion:
        """æ³¨å†Œæ¨¡å‹"""
        if run_id not in self.runs:
            raise ValueError(f"Run {run_id} not found")

        # è·å–ä¸‹ä¸€ä¸ªç‰ˆæœ¬å·
        existing_versions = [v for v in self.model_versions.values() if v.model_name == model_name]
        next_version = max([v.version for v in existing_versions], default=0) + 1

        version_id = f"MODEL-{model_name}-v{next_version}"
        model_version = ModelVersion(
            version_id=version_id,
            model_name=model_name,
            run_id=run_id,
            version=next_version,
            description=description
        )
        self.model_versions[version_id] = model_version
        return model_version

    def compare_runs(self, run_ids: List[str]) -> Dict:
        """æ¯”è¾ƒè¿è¡Œ"""
        comparison = {
            'runs': [],
            'metrics_comparison': {},
            'parameters_comparison': {}
        }

        for run_id in run_ids:
            if run_id not in self.runs:
                continue

            run = self.runs[run_id]
            comparison['runs'].append({
                'run_id': run_id,
                'run_name': run.run_name,
                'status': run.run_status.value,
                'metrics': {k: float(v) for k, v in run.metrics.items()},
                'parameters': run.parameters
            })

            # æ¯”è¾ƒæŒ‡æ ‡
            for metric_name, metric_value in run.metrics.items():
                if metric_name not in comparison['metrics_comparison']:
                    comparison['metrics_comparison'][metric_name] = []
                comparison['metrics_comparison'][metric_name].append({
                    'run_id': run_id,
                    'value': float(metric_value)
                })

        return comparison

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # åˆ›å»ºMLflowå®éªŒç®¡ç†
    mlflow_mgmt = MLflowExperimentManagement()

    # åˆ›å»ºå®éªŒ
    experiment = mlflow_mgmt.create_experiment(
        experiment_name="CustomerChurnPrediction",
        description="å®¢æˆ·æµå¤±é¢„æµ‹å®éªŒ"
    )
    experiment.add_tag("classification")
    experiment.add_tag("customer_analytics")

    # åˆ›å»ºè¿è¡Œ
    run = mlflow_mgmt.create_run(experiment.experiment_id, "RandomForest_v1")
    run.add_parameter("n_estimators", "100")
    run.add_parameter("max_depth", "10")
    run.add_parameter("learning_rate", "0.01")
    run.add_metric("accuracy", Decimal('0.85'))
    run.add_metric("precision", Decimal('0.82'))
    run.add_metric("recall", Decimal('0.88'))
    run.finish(RunStatus.FINISHED)

    # æ³¨å†Œæ¨¡å‹
    model_version = mlflow_mgmt.register_model(
        model_name="CustomerChurnModel",
        run_id=run.run_id,
        description="å®¢æˆ·æµå¤±é¢„æµ‹æ¨¡å‹v1"
    )
    model_version.promote_to_staging()

    print(f"å®éªŒ: {experiment.experiment_name}")
    print(f"è¿è¡Œ: {run.run_name}, çŠ¶æ€: {run.run_status.value}")
    print(f"æ¨¡å‹ç‰ˆæœ¬: {model_version.model_name} v{model_version.version}, é˜¶æ®µ: {model_version.stage}")
```

### 2.5 æ•ˆæœè¯„ä¼°

**æ€§èƒ½æŒ‡æ ‡**ï¼š

| æŒ‡æ ‡ | æ”¹è¿›å‰ | æ”¹è¿›å | æå‡ |
|------|--------|--------|------|
| å®éªŒç®¡ç†æ•ˆç‡ | ä½ | é«˜ | æ˜¾è‘—æå‡ |
| å®éªŒé‡ç°æ€§ | 60% | 100% | 40%æå‡ |
| æ¨¡å‹ç‰ˆæœ¬ç®¡ç† | æ—  | å®Œæ•´ | 100% |
| å®éªŒæ¯”è¾ƒæ•ˆç‡ | ä½ | é«˜ | æ˜¾è‘—æå‡ |

**ä¸šåŠ¡ä»·å€¼**ï¼š

1. **å®éªŒç®¡ç†ç»Ÿä¸€**ï¼šç»Ÿä¸€å®éªŒç®¡ç†æµç¨‹
2. **å®éªŒå¯é‡ç°**ï¼šç¡®ä¿å®éªŒå¯é‡ç°
3. **æ¨¡å‹ç‰ˆæœ¬ç®¡ç†**ï¼šè§„èŒƒæ¨¡å‹ç‰ˆæœ¬ç®¡ç†
4. **å®éªŒæ¯”è¾ƒæ”¯æŒ**ï¼šæ”¯æŒå®éªŒæ•ˆæœæ¯”è¾ƒ

**ç»éªŒæ•™è®­**ï¼š

1. å®éªŒè·Ÿè¸ªå¾ˆé‡è¦
2. æ¨¡å‹ç‰ˆæœ¬ç®¡ç†éœ€è¦è§„èŒƒ
3. å®éªŒé‡ç°éœ€è¦å®Œæ•´è®°å½•
4. æ¨¡å‹æœåŠ¡éœ€è¦æ ‡å‡†åŒ–

**å‚è€ƒæ¡ˆä¾‹**ï¼š

- [MLflowå®˜æ–¹æ–‡æ¡£](https://mlflow.org/)
- [æœºå™¨å­¦ä¹ å®éªŒç®¡ç†æœ€ä½³å®è·µ](https://mlflow.org/docs/latest/index.html)

---

## 3. æ¡ˆä¾‹2ï¼šæ¨¡å‹è®­ç»ƒä¸æ³¨å†Œ

### 3.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹å¹¶æ³¨å†Œåˆ°æ¨¡å‹æ³¨å†Œè¡¨ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- æ”¯æŒæ¨¡å‹è®­ç»ƒ
- æ”¯æŒæ¨¡å‹æ³¨å†Œ
- æ”¯æŒæ¨¡å‹ç‰ˆæœ¬ç®¡ç†

### 3.2 å®ç°ä»£ç 

```python
def train_and_register_model(ml_data: MachineLearningSchema) -> ModelVersion:
    """è®­ç»ƒå¹¶æ³¨å†Œæ¨¡å‹"""
    import mlflow

    training_def = ml_data.model_training.training_definitions[0]

    # åˆ›å»ºå®éªŒ
    experiment = mlflow.create_experiment(training_def.definition_name)

    with mlflow.start_run(experiment_id=experiment):
        # è®­ç»ƒæ¨¡å‹
        model = train_model(training_def)

        # è®°å½•å‚æ•°
        mlflow.log_params({
            "optimizer": training_def.training_config.optimizer,
            "learning_rate": training_def.training_config.learning_rate,
            "batch_size": training_def.training_config.batch_size,
            "epochs": training_def.training_config.epochs
        })

        # è¯„ä¼°æ¨¡å‹
        evaluation_metrics = evaluate_model(model, training_def.data_config.test_data_path)

        # è®°å½•æŒ‡æ ‡
        mlflow.log_metrics(evaluation_metrics)

        # æ³¨å†Œæ¨¡å‹
        mlflow.sklearn.log_model(
            model,
            "model",
            registered_model_name=training_def.definition_name
        )

        # è·å–æ¨¡å‹ç‰ˆæœ¬
        model_version = mlflow.get_model_version(
            name=training_def.definition_name,
            version=1
        )

        return model_version
```

---

## 4. æ¡ˆä¾‹3ï¼šæ¨¡å‹æœåŠ¡ä¸ç›‘æ§

### 4.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
éƒ¨ç½²æ¨¡å‹åˆ°ç”Ÿäº§ç¯å¢ƒå¹¶æä¾›APIæœåŠ¡ï¼Œç›‘æ§æ¨¡å‹æ€§èƒ½ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- æ”¯æŒæ¨¡å‹éƒ¨ç½²
- æ”¯æŒAPIæœåŠ¡
- æ”¯æŒæ€§èƒ½ç›‘æ§

### 4.2 å®ç°ä»£ç 

```python
def deploy_and_monitor_model(model_version: ModelVersion) -> ModelDeployment:
    """éƒ¨ç½²å¹¶ç›‘æ§æ¨¡å‹"""
    import mlflow

    # éƒ¨ç½²æ¨¡å‹
    deployment = ModelDeployment()
    deployment.deployment_id = f"DEPLOY-{model_version.version_id}"
    deployment.model_id = model_version.model_id
    deployment.version_id = model_version.version_id
    deployment.deployment_name = f"{model_version.model_name}_v{model_version.version_number}"
    deployment.deployment_environment = "Production"
    deployment.deployment_status = "Deploying"
    deployment.deployment_date = datetime.now()

    # ä½¿ç”¨MLflowéƒ¨ç½²æ¨¡å‹
    mlflow.deployments.create_deployment(
        name=deployment.deployment_name,
        model_uri=f"models:/{model_version.model_name}/{model_version.version_number}",
        target="production"
    )

    deployment.deployment_status = "Active"
    deployment.deployment_endpoint = f"https://api.example.com/models/{deployment.deployment_id}/predict"

    # åˆ›å»ºAPI
    api = ModelAPI()
    api.api_id = f"API-{deployment.deployment_id}"
    api.deployment_id = deployment.deployment_id
    api.api_endpoint = deployment.deployment_endpoint
    api.api_version = "v1"
    api.request_schema = {
        "type": "object",
        "properties": {
            "features": {
                "type": "array",
                "items": {"type": "number"}
            }
        }
    }
    api.response_schema = {
        "type": "object",
        "properties": {
            "prediction": {"type": "number"},
            "probability": {"type": "number"}
        }
    }

    deployment.model_apis = [api]

    # åˆ›å»ºç›‘æ§
    monitoring = ModelMonitoring()
    monitoring.monitoring_id = f"MON-{deployment.deployment_id}"
    monitoring.deployment_id = deployment.deployment_id

    # ç›‘æ§æŒ‡æ ‡
    monitoring.monitoring_metrics = [
        MonitoringMetric(
            metric_name="prediction_count",
            metric_type="Prediction_Count",
            metric_value=0,
            metric_timestamp=datetime.now()
        ),
        MonitoringMetric(
            metric_name="average_latency",
            metric_type="Latency",
            metric_value=0,
            metric_timestamp=datetime.now()
        )
    ]

    deployment.model_monitoring = [monitoring]

    return deployment

def monitor_model_performance(deployment_id: str, conn):
    """ç›‘æ§æ¨¡å‹æ€§èƒ½"""
    cursor = conn.cursor()

    # æŸ¥è¯¢é¢„æµ‹ç»Ÿè®¡
    cursor.execute("""
        SELECT
            COUNT(*) as prediction_count,
            AVG(latency_ms) as avg_latency,
            SUM(CASE WHEN error_occurred THEN 1 ELSE 0 END) * 100.0 / COUNT(*) as error_rate
        FROM model_predictions
        WHERE deployment_id = %s
        AND prediction_timestamp >= CURRENT_TIMESTAMP - INTERVAL '1 hour'
    """, (deployment_id,))

    performance_stats = cursor.fetchone()

    # æ›´æ–°ç›‘æ§æŒ‡æ ‡
    cursor.execute("""
        INSERT INTO model_monitoring_metrics
        (monitoring_id, metric_name, metric_type, metric_value, metric_timestamp)
        VALUES
        (%s, 'prediction_count', 'Prediction_Count', %s, CURRENT_TIMESTAMP),
        (%s, 'average_latency', 'Latency', %s, CURRENT_TIMESTAMP),
        (%s, 'error_rate', 'Error_Rate', %s, CURRENT_TIMESTAMP)
    """, (
        deployment_id, performance_stats[0],
        deployment_id, performance_stats[1],
        deployment_id, performance_stats[2]
    ))

    conn.commit()
```

---

## 5. æ¡ˆä¾‹4ï¼šæœºå™¨å­¦ä¹ åˆ°MLflowè½¬æ¢

### 5.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
å°†æœºå™¨å­¦ä¹ Schemaè½¬æ¢ä¸ºMLflowæ ¼å¼ï¼Œç”¨äºå®éªŒç®¡ç†ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- æ”¯æŒè‡ªåŠ¨è½¬æ¢åˆ°MLflow
- æ”¯æŒå®éªŒå’Œè¿è¡Œè·Ÿè¸ª
- æ”¯æŒæ¨¡å‹æ³¨å†Œ

### 5.2 å®ç°ä»£ç 

```python
def convert_ml_to_mlflow_complete(ml_data: MachineLearningSchema) -> MLflowExperiment:
    """å®Œæ•´è½¬æ¢æœºå™¨å­¦ä¹ Schemaåˆ°MLflow"""
    import mlflow

    experiment = ml_data.experiment_management.experiments[0]

    # åˆ›å»ºMLflowå®éªŒ
    mlflow_experiment = mlflow.create_experiment(experiment.experiment_name)

    # è½¬æ¢è¿è¡Œ
    for run in ml_data.experiment_management.runs:
        with mlflow.start_run(
            experiment_id=mlflow_experiment,
            run_name=run.run_name,
            nested=run.parent_run_id is not None
        ):
            # è®°å½•å‚æ•°
            if run.parameters:
                mlflow.log_params(run.parameters)

            # è®°å½•æŒ‡æ ‡
            if run.metrics:
                mlflow.log_metrics(run.metrics)

            # è®°å½•æ ‡ç­¾
            if run.tags:
                mlflow.set_tags(run.tags)

            # è®°å½•å·¥ä»¶
            for artifact in run.artifacts:
                if artifact.artifact_type == "Model":
                    mlflow.sklearn.log_model(
                        artifact.artifact_path,
                        "model",
                        registered_model_name=experiment.experiment_name
                    )
                else:
                    mlflow.log_artifact(artifact.artifact_path)

    return mlflow_experiment
```

---

## 6. æ¡ˆä¾‹5ï¼šæœºå™¨å­¦ä¹ æ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿ

### 6.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
æœºå™¨å­¦ä¹ æ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿï¼Œæ”¯æŒå…ƒæ•°æ®å­˜å‚¨ã€æŸ¥è¯¢ã€åˆ†æã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- æ”¯æŒæœºå™¨å­¦ä¹ å…ƒæ•°æ®å­˜å‚¨
- æ”¯æŒå…ƒæ•°æ®æŸ¥è¯¢å’Œåˆ†æ
- æ”¯æŒå®éªŒå’Œæ¨¡å‹æ€§èƒ½åˆ†æ

### 6.2 å®ç°ä»£ç 

```python
def store_ml_data(ml_data: MachineLearningSchema, conn):
    """å­˜å‚¨æœºå™¨å­¦ä¹ æ•°æ®åˆ°PostgreSQL"""
    cursor = conn.cursor()

    # å­˜å‚¨å®éªŒå…ƒæ•°æ®
    for experiment in ml_data.experiment_management.experiments:
        cursor.execute("""
            INSERT INTO experiment_metadata
            (experiment_id, experiment_name, experiment_description, created_by)
            VALUES (%s, %s, %s, %s)
            ON CONFLICT (experiment_id) DO UPDATE SET
            experiment_name = EXCLUDED.experiment_name,
            experiment_description = EXCLUDED.experiment_description,
            updated_at = CURRENT_TIMESTAMP
        """, (experiment.experiment_id, experiment.experiment_name,
              experiment.experiment_description, experiment.created_by))

    # å­˜å‚¨è¿è¡Œå…ƒæ•°æ®
    for run in ml_data.experiment_management.runs:
        cursor.execute("""
            INSERT INTO run_metadata
            (run_id, experiment_id, run_name, run_status, start_time, end_time, duration, parent_run_id)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (run_id) DO UPDATE SET
            run_status = EXCLUDED.run_status,
            end_time = EXCLUDED.end_time,
            duration = EXCLUDED.duration
        """, (run.run_id, run.experiment_id, run.run_name, run.run_status,
              run.start_time, run.end_time, run.duration, run.parent_run_id))

        # å­˜å‚¨è¿è¡Œå‚æ•°
        for param_name, param_value in run.parameters.items():
            cursor.execute("""
                INSERT INTO run_parameters
                (parameter_id, run_id, parameter_name, parameter_value)
                VALUES (%s, %s, %s, %s)
                ON CONFLICT (parameter_id) DO UPDATE SET
                parameter_value = EXCLUDED.parameter_value
            """, (f"PARAM-{run.run_id}-{param_name}", run.run_id, param_name, param_value))

        # å­˜å‚¨è¿è¡ŒæŒ‡æ ‡
        for metric_name, metric_value in run.metrics.items():
            cursor.execute("""
                INSERT INTO run_metrics
                (metric_id, run_id, metric_name, metric_value, metric_timestamp)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (metric_id) DO UPDATE SET
                metric_value = EXCLUDED.metric_value,
                metric_timestamp = EXCLUDED.metric_timestamp
            """, (f"METRIC-{run.run_id}-{metric_name}", run.run_id,
                  metric_name, metric_value, datetime.now()))

    # å­˜å‚¨æ¨¡å‹æ³¨å†Œ
    for model in ml_data.model_registry.registered_models:
        cursor.execute("""
            INSERT INTO model_registry
            (model_id, model_name, model_description, created_by)
            VALUES (%s, %s, %s, %s)
            ON CONFLICT (model_id) DO UPDATE SET
            model_name = EXCLUDED.model_name,
            model_description = EXCLUDED.model_description,
            updated_at = CURRENT_TIMESTAMP
        """, (model.model_id, model.model_name, model.model_description, model.created_by))

        # å­˜å‚¨æ¨¡å‹ç‰ˆæœ¬
        for version in ml_data.model_registry.model_versions:
            if version.model_id == model.model_id:
                cursor.execute("""
                    INSERT INTO model_versions
                    (version_id, model_id, version_number, version_stage, run_id, model_uri, model_format, created_by)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (version_id) DO UPDATE SET
                    version_stage = EXCLUDED.version_stage,
                    model_uri = EXCLUDED.model_uri
                """, (version.version_id, version.model_id, version.version_number,
                      version.version_stage, version.run_id, version.model_uri,
                      version.model_format, version.created_by))

    # å­˜å‚¨æ¨¡å‹éƒ¨ç½²
    for deployment in ml_data.model_serving.model_deployments:
        cursor.execute("""
            INSERT INTO model_deployments
            (deployment_id, model_id, version_id, deployment_name, deployment_environment,
             deployment_status, deployment_date, deployment_endpoint)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (deployment_id) DO UPDATE SET
            deployment_status = EXCLUDED.deployment_status,
            deployment_endpoint = EXCLUDED.deployment_endpoint
        """, (deployment.deployment_id, deployment.model_id, deployment.version_id,
              deployment.deployment_name, deployment.deployment_environment,
              deployment.deployment_status, deployment.deployment_date,
              deployment.deployment_endpoint))

    conn.commit()

def generate_ml_report(conn):
    """ç”Ÿæˆæœºå™¨å­¦ä¹ æŠ¥è¡¨"""
    cursor = conn.cursor()

    # æŸ¥è¯¢å®éªŒæ±‡æ€»
    cursor.execute("""
        SELECT
            em.experiment_name,
            COUNT(rm.run_id) as run_count,
            SUM(CASE WHEN rm.run_status = 'Finished' THEN 1 ELSE 0 END) as completed_runs
        FROM experiment_metadata em
        LEFT JOIN run_metadata rm ON em.experiment_id = rm.experiment_id
        GROUP BY em.experiment_id, em.experiment_name
        ORDER BY em.experiment_name
    """)

    experiment_report = cursor.fetchall()

    # æŸ¥è¯¢æ¨¡å‹éƒ¨ç½²æŠ¥è¡¨
    cursor.execute("""
        SELECT
            mr.model_name,
            mv.version_number,
            md.deployment_environment,
            md.deployment_status
        FROM model_registry mr
        JOIN model_versions mv ON mr.model_id = mv.model_id
        JOIN model_deployments md ON mv.version_id = md.version_id
        ORDER BY md.deployment_date DESC
    """)

    deployment_report = cursor.fetchall()

    return {
        "experiment_report": experiment_report,
        "deployment_report": deployment_report
    }
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `04_Transformation.md` - è½¬æ¢ä½“ç³»

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
