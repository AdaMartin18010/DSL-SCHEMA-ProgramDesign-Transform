# æ•°æ®æŒ–æ˜Schemaå®è·µæ¡ˆä¾‹

## ğŸ“‘ ç›®å½•

- [æ•°æ®æŒ–æ˜Schemaå®è·µæ¡ˆä¾‹](#æ•°æ®æŒ–æ˜schemaå®è·µæ¡ˆä¾‹)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¡ˆä¾‹æ¦‚è¿°](#1-æ¡ˆä¾‹æ¦‚è¿°)
  - [2. æ¡ˆä¾‹1ï¼šå®¢æˆ·æµå¤±é¢„æµ‹](#2-æ¡ˆä¾‹1å®¢æˆ·æµå¤±é¢„æµ‹)
    - [2.1 åœºæ™¯æè¿°](#21-åœºæ™¯æè¿°)
    - [2.2 Schemaå®šä¹‰](#22-schemaå®šä¹‰)
  - [3. æ¡ˆä¾‹2ï¼šCRISP-DMæµç¨‹å®æ–½](#3-æ¡ˆä¾‹2crisp-dmæµç¨‹å®æ–½)
    - [3.1 åœºæ™¯æè¿°](#31-åœºæ™¯æè¿°)
    - [3.2 å®ç°ä»£ç ](#32-å®ç°ä»£ç )
  - [4. æ¡ˆä¾‹3ï¼šæ¨¡å‹è®­ç»ƒä¸è¯„ä¼°](#4-æ¡ˆä¾‹3æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°)
    - [4.1 åœºæ™¯æè¿°](#41-åœºæ™¯æè¿°)
    - [4.2 å®ç°ä»£ç ](#42-å®ç°ä»£ç )
  - [5. æ¡ˆä¾‹4ï¼šæ¨¡å‹éƒ¨ç½²ä¸ç›‘æ§](#5-æ¡ˆä¾‹4æ¨¡å‹éƒ¨ç½²ä¸ç›‘æ§)
    - [5.1 åœºæ™¯æè¿°](#51-åœºæ™¯æè¿°)
    - [5.2 å®ç°ä»£ç ](#52-å®ç°ä»£ç )
  - [6. æ¡ˆä¾‹5ï¼šæ•°æ®æŒ–æ˜æ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿ](#6-æ¡ˆä¾‹5æ•°æ®æŒ–æ˜æ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿ)
    - [6.1 åœºæ™¯æè¿°](#61-åœºæ™¯æè¿°)
    - [6.2 å®ç°ä»£ç ](#62-å®ç°ä»£ç )

---

## 1. æ¡ˆä¾‹æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›æ•°æ®æŒ–æ˜Schemaåœ¨å®é™…åº”ç”¨ä¸­çš„å®è·µæ¡ˆä¾‹ã€‚

---

## 2. æ¡ˆä¾‹1ï¼šå®¢æˆ·æµå¤±é¢„æµ‹

### 2.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
æ„å»ºå®¢æˆ·æµå¤±é¢„æµ‹æ¨¡å‹ï¼Œé¢„æµ‹å®¢æˆ·æµå¤±æ¦‚ç‡ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- æ”¯æŒå®¢æˆ·ç‰¹å¾åˆ†æ
- æ”¯æŒæµå¤±é¢„æµ‹æ¨¡å‹è®­ç»ƒ
- æ”¯æŒæ¨¡å‹è¯„ä¼°å’Œéƒ¨ç½²

### 2.2 Schemaå®šä¹‰

**å®¢æˆ·æµå¤±é¢„æµ‹Schema**ï¼š

```dsl
schema CustomerChurnPrediction {
  data_preparation: DataPreparation {
    features: List<Feature> {
      customer_age: Feature {
        feature_name: String @value("customer_age")
        feature_type: Enum @value("Numerical")
        is_selected: Boolean @value(true)
      }
      customer_tenure: Feature {
        feature_name: String @value("customer_tenure")
        feature_type: Enum @value("Numerical")
        is_selected: Boolean @value(true)
      }
      monthly_charges: Feature {
        feature_name: String @value("monthly_charges")
        feature_type: Enum @value("Numerical")
        is_selected: Boolean @value(true)
      }
    }
    data_sampling: DataSampling {
      train_ratio: Decimal @value(0.7)
      test_ratio: Decimal @value(0.15)
      validation_ratio: Decimal @value(0.15)
    }
  }

  model_training: ModelTraining {
    model: Model {
      model_id: String @value("MODEL-CHURN-001")
      model_name: String @value("CustomerChurnPrediction")
      model_type: Enum @value("Classification")
      algorithm: Enum @value("Random_Forest")
      training_parameters: TrainingParameters {
        learning_rate: Decimal @value(0.01)
        max_iterations: Int @value(1000)
        batch_size: Int @value(32)
      }
    }
  }

  model_evaluation: ModelEvaluation {
    evaluation_result: EvaluationResult {
      model_id: String @value("MODEL-CHURN-001")
      metrics: Map<String, Decimal> {
        "Accuracy": Decimal @value(0.85)
        "Precision": Decimal @value(0.82)
        "Recall": Decimal @value(0.88)
        "F1_Score": Decimal @value(0.85)
      }
    }
  }
}
```

---

## 3. æ¡ˆä¾‹2ï¼šCRISP-DMæµç¨‹å®æ–½

### 3.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
æŒ‰ç…§CRISP-DMæ ‡å‡†æµç¨‹æ‰§è¡Œæ•°æ®æŒ–æ˜é¡¹ç›®ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- æ”¯æŒCRISP-DMå…­ä¸ªé˜¶æ®µ
- æ”¯æŒé˜¶æ®µé—´æ•°æ®æµè½¬
- æ”¯æŒæµç¨‹è¿½æº¯

### 3.2 å®ç°ä»£ç 

```python
def execute_crisp_dm_process(business_objectives: Dict) -> DataMiningSchema:
    """æ‰§è¡ŒCRISP-DMæµç¨‹"""
    mining_schema = DataMiningSchema()

    # 1. ä¸šåŠ¡ç†è§£
    business_understanding = BusinessUnderstanding()
    business_understanding.business_objectives = business_objectives
    business_understanding.success_criteria = define_success_criteria(business_objectives)
    mining_schema.business_understanding = business_understanding

    # 2. æ•°æ®ç†è§£
    data_understanding = DataUnderstanding()
    data_understanding.data_sources = collect_data_sources(business_objectives)
    data_understanding.data_quality = assess_data_quality(data_understanding.data_sources)
    mining_schema.data_understanding = data_understanding

    # 3. æ•°æ®å‡†å¤‡
    data_preparation = DataPreparation()
    data_preparation.data_cleaning = clean_data(data_understanding.data_sources)
    data_preparation.feature_engineering = engineer_features(data_preparation.data_cleaning)
    data_preparation.data_sampling = sample_data(data_preparation.feature_engineering)
    mining_schema.data_preparation = data_preparation

    # 4. å»ºæ¨¡
    model_training = ModelTraining()
    model_training.models = train_models(data_preparation.data_sampling)
    mining_schema.model_training = model_training

    # 5. è¯„ä¼°
    model_evaluation = ModelEvaluation()
    model_evaluation.evaluation_results = evaluate_models(model_training.models, data_preparation.data_sampling)
    model_evaluation.model_comparison = compare_models(model_evaluation.evaluation_results)
    mining_schema.model_evaluation = model_evaluation

    # 6. éƒ¨ç½²
    best_model = model_evaluation.model_comparison.best_model_id
    model_deployment = ModelDeployment()
    model_deployment.model_deployments = deploy_model(best_model)
    mining_schema.model_deployment = model_deployment

    return mining_schema
```

---

## 4. æ¡ˆä¾‹3ï¼šæ¨¡å‹è®­ç»ƒä¸è¯„ä¼°

### 4.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œé€‰æ‹©æœ€ä½³æ¨¡å‹ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- æ”¯æŒå¤šæ¨¡å‹è®­ç»ƒ
- æ”¯æŒæ¨¡å‹æ€§èƒ½è¯„ä¼°
- æ”¯æŒæ¨¡å‹æ¯”è¾ƒå’Œé€‰æ‹©

### 4.2 å®ç°ä»£ç 

```python
def train_and_evaluate_models(mining_data: DataMiningSchema) -> ModelEvaluation:
    """è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹"""
    models = []
    evaluation_results = []

    # è®­ç»ƒå¤šä¸ªæ¨¡å‹
    algorithms = ["Decision_Tree", "Random_Forest", "SVM", "Neural_Network"]

    for algorithm in algorithms:
        model = Model()
        model.model_id = f"MODEL-{algorithm}-001"
        model.model_name = f"{algorithm}Model"
        model.model_type = "Classification"
        model.algorithm = algorithm
        model.training_parameters = TrainingParameters(
            learning_rate=0.01,
            max_iterations=1000,
            batch_size=32
        )

        # è®­ç»ƒæ¨¡å‹
        trained_model = train_model(model, mining_data.data_preparation.data_sampling)
        models.append(trained_model)

        # è¯„ä¼°æ¨¡å‹
        evaluation_result = evaluate_model(trained_model, mining_data.data_preparation.data_sampling)
        evaluation_results.append(evaluation_result)

    # æ¨¡å‹æ¯”è¾ƒ
    model_comparison = ModelComparison()
    model_comparison.comparison_id = "COMP-001"
    model_comparison.comparison_date = datetime.now().date()
    model_comparison.compared_models = [m.model_id for m in models]

    # æ¯”è¾ƒæŒ‡æ ‡
    comparison_metrics = {}
    for result in evaluation_results:
        comparison_metrics[result.model_id] = {
            metric.metric_name: metric.metric_value
            for metric in result.metrics
        }

    model_comparison.comparison_metrics = comparison_metrics

    # é€‰æ‹©æœ€ä½³æ¨¡å‹ï¼ˆåŸºäºF1åˆ†æ•°ï¼‰
    best_model_id = max(
        comparison_metrics.keys(),
        key=lambda mid: comparison_metrics[mid].get("F1_Score", 0)
    )
    model_comparison.best_model_id = best_model_id

    model_evaluation = ModelEvaluation()
    model_evaluation.evaluation_results = evaluation_results
    model_evaluation.model_comparison = model_comparison

    return model_evaluation
```

---

## 5. æ¡ˆä¾‹4ï¼šæ¨¡å‹éƒ¨ç½²ä¸ç›‘æ§

### 5.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
éƒ¨ç½²æ¨¡å‹åˆ°ç”Ÿäº§ç¯å¢ƒå¹¶ç›‘æ§æ¨¡å‹æ€§èƒ½ã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- æ”¯æŒæ¨¡å‹éƒ¨ç½²
- æ”¯æŒæ¨¡å‹æ€§èƒ½ç›‘æ§
- æ”¯æŒæ¨¡å‹æ¼‚ç§»æ£€æµ‹

### 5.2 å®ç°ä»£ç 

```python
def deploy_and_monitor_model(model_id: str, mining_data: DataMiningSchema) -> ModelDeployment:
    """éƒ¨ç½²å’Œç›‘æ§æ¨¡å‹"""
    model = find_model(mining_data.model_training, model_id)

    # éƒ¨ç½²æ¨¡å‹
    deployment = ModelDeployment()
    deployment.deployment_id = f"DEPLOY-{model_id}"
    deployment.model_id = model_id
    deployment.deployment_environment = "Production"
    deployment.deployment_date = datetime.now().date()
    deployment.deployment_status = "Deployed"
    deployment.deployment_endpoint = f"https://api.example.com/models/{model_id}/predict"

    # åˆ›å»ºç›‘æ§
    monitoring = ModelMonitoring()
    monitoring.monitoring_id = f"MON-{deployment.deployment_id}"
    monitoring.deployment_id = deployment.deployment_id

    # ç›‘æ§æŒ‡æ ‡
    monitoring.monitoring_metrics = [
        MonitoringMetric(
            metric_name="prediction_count",
            metric_type="Prediction_Count",
            metric_value=0,
            metric_timestamp=datetime.now()
        ),
        MonitoringMetric(
            metric_name="average_latency",
            metric_type="Latency",
            metric_value=0,
            metric_timestamp=datetime.now()
        ),
        MonitoringMetric(
            metric_name="error_rate",
            metric_type="Error_Rate",
            metric_value=0,
            metric_timestamp=datetime.now()
        )
    ]

    # æ¼‚ç§»æ£€æµ‹
    monitoring.drift_detection = DriftDetection(
        drift_score=0.0,
        drift_threshold=0.1,
        is_drifted=False
    )

    deployment.model_monitoring = monitoring

    return deployment

def monitor_model_performance(deployment_id: str, conn):
    """ç›‘æ§æ¨¡å‹æ€§èƒ½"""
    cursor = conn.cursor()

    # æŸ¥è¯¢é¢„æµ‹ç»Ÿè®¡
    cursor.execute("""
        SELECT
            COUNT(*) as prediction_count,
            AVG(latency_ms) as avg_latency,
            SUM(CASE WHEN error_occurred THEN 1 ELSE 0 END) * 100.0 / COUNT(*) as error_rate
        FROM model_predictions
        WHERE deployment_id = %s
        AND prediction_timestamp >= CURRENT_TIMESTAMP - INTERVAL '1 hour'
    """, (deployment_id,))

    performance_stats = cursor.fetchone()

    # æ›´æ–°ç›‘æ§æŒ‡æ ‡
    cursor.execute("""
        INSERT INTO model_monitoring_metrics
        (monitoring_id, metric_name, metric_type, metric_value, metric_timestamp)
        VALUES
        (%s, 'prediction_count', 'Prediction_Count', %s, CURRENT_TIMESTAMP),
        (%s, 'average_latency', 'Latency', %s, CURRENT_TIMESTAMP),
        (%s, 'error_rate', 'Error_Rate', %s, CURRENT_TIMESTAMP)
    """, (
        deployment_id, performance_stats[0],
        deployment_id, performance_stats[1],
        deployment_id, performance_stats[2]
    ))

    # æ£€æµ‹æ¼‚ç§»
    cursor.execute("""
        SELECT
            drift_score,
            drift_threshold
        FROM model_drift_detection
        WHERE deployment_id = %s
        ORDER BY detection_date DESC
        LIMIT 1
    """, (deployment_id,))

    drift_info = cursor.fetchone()
    if drift_info and drift_info[0] > drift_info[1]:
        # è§¦å‘æ¼‚ç§»å‘Šè­¦
        send_drift_alert(deployment_id, drift_info[0])

    conn.commit()
```

---

## 6. æ¡ˆä¾‹5ï¼šæ•°æ®æŒ–æ˜æ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿ

### 6.1 åœºæ™¯æè¿°

**åº”ç”¨åœºæ™¯**ï¼š
æ•°æ®æŒ–æ˜æ•°æ®å­˜å‚¨ä¸åˆ†æç³»ç»Ÿï¼Œæ”¯æŒå…ƒæ•°æ®å­˜å‚¨ã€æŸ¥è¯¢ã€åˆ†æã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- æ”¯æŒæ•°æ®æŒ–æ˜å…ƒæ•°æ®å­˜å‚¨
- æ”¯æŒå…ƒæ•°æ®æŸ¥è¯¢å’Œåˆ†æ
- æ”¯æŒæ¨¡å‹æ€§èƒ½ç›‘æ§

### 6.2 å®ç°ä»£ç 

```python
def store_mining_data(mining_data: DataMiningSchema, conn):
    """å­˜å‚¨æ•°æ®æŒ–æ˜æ•°æ®åˆ°PostgreSQL"""
    cursor = conn.cursor()

    # å­˜å‚¨æ¨¡å‹å…ƒæ•°æ®
    for model in mining_data.model_training.models:
        cursor.execute("""
            INSERT INTO model_metadata
            (model_id, model_name, model_type, algorithm, training_status,
             training_start_time, training_end_time)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (model_id) DO UPDATE SET
            model_name = EXCLUDED.model_name,
            training_status = EXCLUDED.training_status,
            training_start_time = EXCLUDED.training_start_time,
            training_end_time = EXCLUDED.training_end_time,
            updated_at = CURRENT_TIMESTAMP
        """, (model.model_id, model.model_name, model.model_type,
              model.algorithm, model.training_status,
              model.training_start_time, model.training_end_time))

        # å­˜å‚¨è®­ç»ƒå‚æ•°
        cursor.execute("""
            INSERT INTO training_parameters
            (parameter_id, model_id, parameter_name, parameter_value)
            VALUES
            (%s, %s, 'learning_rate', %s),
            (%s, %s, 'max_iterations', %s),
            (%s, %s, 'batch_size', %s),
            (%s, %s, 'regularization', %s)
            ON CONFLICT (parameter_id) DO UPDATE SET
            parameter_value = EXCLUDED.parameter_value
        """, (
            f"PARAM-{model.model_id}-LR", model.model_id, str(model.training_parameters.learning_rate),
            f"PARAM-{model.model_id}-MAX", model.model_id, str(model.training_parameters.max_iterations),
            f"PARAM-{model.model_id}-BATCH", model.model_id, str(model.training_parameters.batch_size),
            f"PARAM-{model.model_id}-REG", model.model_id, str(model.training_parameters.regularization)
        ))

    # å­˜å‚¨è¯„ä¼°æŒ‡æ ‡
    for result in mining_data.model_evaluation.evaluation_results:
        for metric in result.metrics:
            cursor.execute("""
                INSERT INTO evaluation_metrics
                (metric_id, model_id, metric_name, metric_type, metric_value, dataset_type, evaluation_date)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (metric_id) DO UPDATE SET
                metric_value = EXCLUDED.metric_value,
                evaluation_date = EXCLUDED.evaluation_date
            """, (metric.metric_id, result.model_id, metric.metric_name,
                  metric.metric_type, metric.metric_value,
                  result.dataset_type, result.evaluation_date))

    # å­˜å‚¨æ¨¡å‹éƒ¨ç½²
    for deployment in mining_data.model_deployment.model_deployments:
        cursor.execute("""
            INSERT INTO model_deployments
            (deployment_id, model_id, deployment_environment, deployment_date,
             deployment_status, deployment_endpoint)
            VALUES (%s, %s, %s, %s, %s, %s)
            ON CONFLICT (deployment_id) DO UPDATE SET
            deployment_status = EXCLUDED.deployment_status,
            deployment_endpoint = EXCLUDED.deployment_endpoint
        """, (deployment.deployment_id, deployment.model_id,
              deployment.deployment_environment, deployment.deployment_date,
              deployment.deployment_status, deployment.deployment_endpoint))

    conn.commit()

def generate_mining_report(conn):
    """ç”Ÿæˆæ•°æ®æŒ–æ˜æŠ¥è¡¨"""
    cursor = conn.cursor()

    # æŸ¥è¯¢æ¨¡å‹æ€§èƒ½æŠ¥è¡¨
    cursor.execute("""
        SELECT
            mm.model_name,
            mm.algorithm,
            em.metric_name,
            em.metric_value,
            em.dataset_type
        FROM model_metadata mm
        JOIN evaluation_metrics em ON mm.model_id = em.model_id
        WHERE em.dataset_type = 'Testing'
        ORDER BY mm.model_name, em.metric_name
    """)

    performance_report = cursor.fetchall()

    # æŸ¥è¯¢æ¨¡å‹éƒ¨ç½²æŠ¥è¡¨
    cursor.execute("""
        SELECT
            mm.model_name,
            md.deployment_environment,
            md.deployment_status,
            md.deployment_date
        FROM model_metadata mm
        JOIN model_deployments md ON mm.model_id = md.model_id
        ORDER BY md.deployment_date DESC
    """)

    deployment_report = cursor.fetchall()

    return {
        "performance_report": performance_report,
        "deployment_report": deployment_report
    }
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `04_Transformation.md` - è½¬æ¢ä½“ç³»

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
