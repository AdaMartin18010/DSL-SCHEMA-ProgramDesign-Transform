# æ•°æ®æŒ–æ˜Schemaè½¬æ¢ä½“ç³»

## ğŸ“‘ ç›®å½•

- [æ•°æ®æŒ–æ˜Schemaè½¬æ¢ä½“ç³»](#æ•°æ®æŒ–æ˜schemaè½¬æ¢ä½“ç³»)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. è½¬æ¢ä½“ç³»æ¦‚è¿°](#1-è½¬æ¢ä½“ç³»æ¦‚è¿°)
    - [1.1 è½¬æ¢ç›®æ ‡](#11-è½¬æ¢ç›®æ ‡)
  - [2. æ•°æ®æŒ–æ˜åˆ°PMMLè½¬æ¢](#2-æ•°æ®æŒ–æ˜åˆ°pmmlè½¬æ¢)
  - [3. æ•°æ®æŒ–æ˜åˆ°MLflowè½¬æ¢](#3-æ•°æ®æŒ–æ˜åˆ°mlflowè½¬æ¢)
  - [4. æ•°æ®æŒ–æ˜åˆ°ONNXè½¬æ¢](#4-æ•°æ®æŒ–æ˜åˆ°onnxè½¬æ¢)
  - [5. æ•°æ®æŒ–æ˜æ•°æ®å­˜å‚¨ä¸åˆ†æ](#5-æ•°æ®æŒ–æ˜æ•°æ®å­˜å‚¨ä¸åˆ†æ)
    - [5.1 PostgreSQLæ•°æ®æŒ–æ˜æ•°æ®å­˜å‚¨](#51-postgresqlæ•°æ®æŒ–æ˜æ•°æ®å­˜å‚¨)
    - [5.2 æ•°æ®æŒ–æ˜æ•°æ®åˆ†ææŸ¥è¯¢](#52-æ•°æ®æŒ–æ˜æ•°æ®åˆ†ææŸ¥è¯¢)

---

## 1. è½¬æ¢ä½“ç³»æ¦‚è¿°

æ•°æ®æŒ–æ˜Schemaè½¬æ¢ä½“ç³»æ”¯æŒæ•°æ®æŒ–æ˜åˆ°PMMLã€MLflowã€ONNXæ ¼å¼è½¬æ¢ï¼Œä»¥åŠæ•°æ®æŒ–æ˜æ•°æ®å­˜å‚¨ã€‚

### 1.1 è½¬æ¢ç›®æ ‡

1. **æ•°æ®æŒ–æ˜åˆ°PMMLè½¬æ¢**ï¼šæ•°æ®æŒ–æ˜æ¨¡å‹åˆ°PMMLæ ¼å¼
2. **æ•°æ®æŒ–æ˜åˆ°MLflowè½¬æ¢**ï¼šæ•°æ®æŒ–æ˜æ¨¡å‹åˆ°MLflowæ ¼å¼
3. **æ•°æ®æŒ–æ˜åˆ°ONNXè½¬æ¢**ï¼šæ•°æ®æŒ–æ˜æ¨¡å‹åˆ°ONNXæ ¼å¼
4. **æ•°æ®æŒ–æ˜åˆ°æ•°æ®åº“è½¬æ¢**ï¼šæ•°æ®æŒ–æ˜æ•°æ®åˆ°PostgreSQLå­˜å‚¨

---

## 2. æ•°æ®æŒ–æ˜åˆ°PMMLè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- æ¨¡å‹å®šä¹‰ â†’ PMML Model Element
- æ¨¡å‹å‚æ•° â†’ PMML Parameters
- æ¨¡å‹ç»“æ„ â†’ PMML Structure

**è½¬æ¢ç¤ºä¾‹**ï¼š

```python
def convert_mining_to_pmml(mining_data: DataMiningSchema) -> PMMLModel:
    """å°†æ•°æ®æŒ–æ˜æ¨¡å‹è½¬æ¢ä¸ºPMMLæ ¼å¼"""
    pmml_model = PMMLModel()

    model = mining_data.model_training.models[0]

    # æ¨¡å‹å¤´éƒ¨
    pmml_model.header = PMMLHeader(
        copyright="Data Mining Model",
        description=model.model_name,
        application_name="Data Mining System",
        application_version="1.0"
    )

    # æ•°æ®å­—å…¸
    data_dictionary = PMMLDataDictionary()
    for feature in mining_data.data_preparation.feature_engineering.features:
        if feature.is_selected:
            data_field = PMMLDataField(
                name=feature.feature_name,
                optype=map_feature_type_to_pmml_optype(feature.feature_type),
                data_type=map_feature_type_to_pmml_data_type(feature.feature_type)
            )
            data_dictionary.data_fields.append(data_field)

    pmml_model.data_dictionary = data_dictionary

    # æ¨¡å‹å®šä¹‰
    if model.model_type == "Classification":
        pmml_model.model = PMMLClassificationModel(
            model_name=model.model_name,
            function_name="classification",
            algorithm_name=model.algorithm
        )
    elif model.model_type == "Regression":
        pmml_model.model = PMMLRegressionModel(
            model_name=model.model_name,
            function_name="regression",
            algorithm_name=model.algorithm
        )

    # æ¨¡å‹å‚æ•°
    pmml_model.model.mining_schema = PMMLMiningSchema()
    for feature in mining_data.data_preparation.feature_engineering.features:
        if feature.is_selected:
            mining_field = PMMLMiningField(
                name=feature.feature_name,
                usage_type="active"
            )
            pmml_model.model.mining_schema.mining_fields.append(mining_field)

    return pmml_model
```

---

## 3. æ•°æ®æŒ–æ˜åˆ°MLflowè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- æ¨¡å‹å®šä¹‰ â†’ MLflow Model
- è®­ç»ƒå‚æ•° â†’ MLflow Parameters
- è¯„ä¼°æŒ‡æ ‡ â†’ MLflow Metrics

**è½¬æ¢ç¤ºä¾‹**ï¼š

```python
def convert_mining_to_mlflow(mining_data: DataMiningSchema) -> MLflowExperiment:
    """å°†æ•°æ®æŒ–æ˜æ¨¡å‹è½¬æ¢ä¸ºMLflowæ ¼å¼"""
    import mlflow

    model = mining_data.model_training.models[0]
    evaluation = mining_data.model_evaluation.evaluation_results[0]

    # åˆ›å»ºMLflowå®éªŒ
    experiment = mlflow.create_experiment(model.model_name)

    with mlflow.start_run(experiment_id=experiment):
        # è®°å½•å‚æ•°
        mlflow.log_params({
            "learning_rate": model.training_parameters.learning_rate,
            "max_iterations": model.training_parameters.max_iterations,
            "batch_size": model.training_parameters.batch_size,
            "regularization": model.training_parameters.regularization
        })

        # è®°å½•æŒ‡æ ‡
        for metric in evaluation.metrics:
            mlflow.log_metric(metric.metric_name, metric.metric_value)

        # è®°å½•æ¨¡å‹
        mlflow.sklearn.log_model(
            model.model_structure,
            "model",
            registered_model_name=model.model_name
        )

        # è®°å½•ç‰¹å¾é‡è¦æ€§
        if evaluation.feature_importance:
            feature_importance_dict = {
                fi.feature_name: fi.importance_score
                for fi in evaluation.feature_importance
            }
            mlflow.log_dict(feature_importance_dict, "feature_importance.json")

    return experiment
```

---

## 4. æ•°æ®æŒ–æ˜åˆ°ONNXè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- æ¨¡å‹ç»“æ„ â†’ ONNX Graph
- æ¨¡å‹å‚æ•° â†’ ONNX Initializers
- æ¨¡å‹è¾“å…¥è¾“å‡º â†’ ONNX Inputs/Outputs

**è½¬æ¢ç¤ºä¾‹**ï¼š

```python
def convert_mining_to_onnx(mining_data: DataMiningSchema) -> ONNXModel:
    """å°†æ•°æ®æŒ–æ˜æ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼"""
    import onnx
    from onnx import helper, TensorProto

    model = mining_data.model_training.models[0]

    # åˆ›å»ºONNXå›¾
    graph_inputs = []
    for feature in mining_data.data_preparation.feature_engineering.features:
        if feature.is_selected:
            input_tensor = helper.make_tensor_value_info(
                feature.feature_name,
                TensorProto.FLOAT,
                [None, 1]
            )
            graph_inputs.append(input_tensor)

    graph_outputs = [
        helper.make_tensor_value_info(
            model.model_structure.output_target,
            TensorProto.FLOAT,
            [None, 1]
        )
    ]

    # åˆ›å»ºONNXèŠ‚ç‚¹ï¼ˆæ ¹æ®ç®—æ³•ç±»å‹ï¼‰
    graph_nodes = []
    if model.algorithm == "Neural_Network":
        # ç¥ç»ç½‘ç»œèŠ‚ç‚¹
        for i, layer_size in enumerate(model.model_structure.hidden_layers):
            node = helper.make_node(
                "MatMul",
                inputs=[f"input_{i}", f"weight_{i}"],
                outputs=[f"output_{i}"]
            )
            graph_nodes.append(node)

    # åˆ›å»ºONNXæ¨¡å‹
    onnx_model = helper.make_model(
        helper.make_graph(
            graph_nodes,
            model.model_name,
            graph_inputs,
            graph_outputs
        )
    )

    return onnx_model
```

---

## 5. æ•°æ®æŒ–æ˜æ•°æ®å­˜å‚¨ä¸åˆ†æ

### 5.1 PostgreSQLæ•°æ®æŒ–æ˜æ•°æ®å­˜å‚¨

**è¡¨ç»“æ„è®¾è®¡**ï¼š

```sql
-- æ¨¡å‹å…ƒæ•°æ®è¡¨
CREATE TABLE model_metadata (
    model_id VARCHAR(50) PRIMARY KEY,
    model_name VARCHAR(200) NOT NULL,
    model_type VARCHAR(20) NOT NULL,
    algorithm VARCHAR(50) NOT NULL,
    training_status VARCHAR(20) DEFAULT 'Not_Started',
    training_start_time TIMESTAMP,
    training_end_time TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç‰¹å¾å…ƒæ•°æ®è¡¨
CREATE TABLE feature_metadata (
    feature_id VARCHAR(50) PRIMARY KEY,
    feature_name VARCHAR(200) NOT NULL,
    feature_type VARCHAR(20) NOT NULL,
    feature_source VARCHAR(200) NOT NULL,
    is_selected BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- è®­ç»ƒå‚æ•°è¡¨
CREATE TABLE training_parameters (
    parameter_id VARCHAR(50) PRIMARY KEY,
    model_id VARCHAR(50) NOT NULL,
    parameter_name VARCHAR(100) NOT NULL,
    parameter_value VARCHAR(200) NOT NULL,
    FOREIGN KEY (model_id) REFERENCES model_metadata(model_id)
);

-- è¯„ä¼°æŒ‡æ ‡è¡¨
CREATE TABLE evaluation_metrics (
    metric_id VARCHAR(50) PRIMARY KEY,
    model_id VARCHAR(50) NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    metric_type VARCHAR(20) NOT NULL,
    metric_value DECIMAL(18, 4) NOT NULL,
    dataset_type VARCHAR(20) NOT NULL,
    evaluation_date DATE NOT NULL,
    FOREIGN KEY (model_id) REFERENCES model_metadata(model_id)
);

-- æ¨¡å‹éƒ¨ç½²è¡¨
CREATE TABLE model_deployments (
    deployment_id VARCHAR(50) PRIMARY KEY,
    model_id VARCHAR(50) NOT NULL,
    deployment_environment VARCHAR(20) NOT NULL,
    deployment_date DATE NOT NULL,
    deployment_status VARCHAR(20) DEFAULT 'Deployed',
    deployment_endpoint VARCHAR(500) NOT NULL,
    FOREIGN KEY (model_id) REFERENCES model_metadata(model_id)
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_training_parameters_model ON training_parameters(model_id);
CREATE INDEX idx_evaluation_metrics_model ON evaluation_metrics(model_id);
CREATE INDEX idx_evaluation_metrics_date ON evaluation_metrics(evaluation_date);
CREATE INDEX idx_model_deployments_model ON model_deployments(model_id);
CREATE INDEX idx_model_deployments_status ON model_deployments(deployment_status);
```

### 5.2 æ•°æ®æŒ–æ˜æ•°æ®åˆ†ææŸ¥è¯¢

**æŸ¥è¯¢ç¤ºä¾‹**ï¼š

```python
def analyze_mining_data(conn):
    """åˆ†ææ•°æ®æŒ–æ˜æ•°æ®"""
    cursor = conn.cursor()

    # æŸ¥è¯¢æ¨¡å‹æ€§èƒ½æ±‡æ€»
    cursor.execute("""
        SELECT
            mm.model_name,
            mm.model_type,
            mm.algorithm,
            AVG(em.metric_value) as avg_metric_value,
            MAX(em.metric_value) as max_metric_value,
            MIN(em.metric_value) as min_metric_value
        FROM model_metadata mm
        JOIN evaluation_metrics em ON mm.model_id = em.model_id
        WHERE em.dataset_type = 'Testing'
        AND em.metric_type = 'Accuracy'
        GROUP BY mm.model_id, mm.model_name, mm.model_type, mm.algorithm
        ORDER BY avg_metric_value DESC
    """)

    model_performance = cursor.fetchall()

    # æŸ¥è¯¢æ¨¡å‹éƒ¨ç½²æ±‡æ€»
    cursor.execute("""
        SELECT
            mm.model_name,
            md.deployment_environment,
            md.deployment_status,
            md.deployment_date
        FROM model_metadata mm
        JOIN model_deployments md ON mm.model_id = md.model_id
        WHERE md.deployment_status = 'Active'
        ORDER BY md.deployment_date DESC
    """)

    deployment_summary = cursor.fetchall()

    return {
        "model_performance": model_performance,
        "deployment_summary": deployment_summary
    }
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `05_Case_Studies.md` - å®è·µæ¡ˆä¾‹

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
