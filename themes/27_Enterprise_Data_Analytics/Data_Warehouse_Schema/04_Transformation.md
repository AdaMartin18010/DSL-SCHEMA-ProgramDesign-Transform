# æ•°æ®ä»“åº“Schemaè½¬æ¢ä½“ç³»

## ğŸ“‘ ç›®å½•

- [æ•°æ®ä»“åº“Schemaè½¬æ¢ä½“ç³»](#æ•°æ®ä»“åº“schemaè½¬æ¢ä½“ç³»)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. è½¬æ¢ä½“ç³»æ¦‚è¿°](#1-è½¬æ¢ä½“ç³»æ¦‚è¿°)
    - [1.1 è½¬æ¢ç›®æ ‡](#11-è½¬æ¢ç›®æ ‡)
  - [2. æ•°æ®ä»“åº“åˆ°SQL Schemaè½¬æ¢](#2-æ•°æ®ä»“åº“åˆ°sql-schemaè½¬æ¢)
  - [3. æ•°æ®ä»“åº“åˆ°JSON Schemaè½¬æ¢](#3-æ•°æ®ä»“åº“åˆ°json-schemaè½¬æ¢)
  - [4. æ•°æ®ä»“åº“åˆ°OpenAPIè½¬æ¢](#4-æ•°æ®ä»“åº“åˆ°openapiè½¬æ¢)
  - [5. æ•°æ®ä»“åº“æ•°æ®å­˜å‚¨ä¸åˆ†æ](#5-æ•°æ®ä»“åº“æ•°æ®å­˜å‚¨ä¸åˆ†æ)
    - [5.1 PostgreSQLæ•°æ®ä»“åº“æ•°æ®å­˜å‚¨](#51-postgresqlæ•°æ®ä»“åº“æ•°æ®å­˜å‚¨)
    - [5.2 æ•°æ®ä»“åº“æ•°æ®åˆ†ææŸ¥è¯¢](#52-æ•°æ®ä»“åº“æ•°æ®åˆ†ææŸ¥è¯¢)

---

## 1. è½¬æ¢ä½“ç³»æ¦‚è¿°

æ•°æ®ä»“åº“Schemaè½¬æ¢ä½“ç³»æ”¯æŒæ•°æ®ä»“åº“åˆ°SQL Schemaã€JSON Schemaã€OpenAPIæ ¼å¼è½¬æ¢ï¼Œä»¥åŠæ•°æ®ä»“åº“æ•°æ®å­˜å‚¨ã€‚

### 1.1 è½¬æ¢ç›®æ ‡

1. **æ•°æ®ä»“åº“åˆ°SQL Schemaè½¬æ¢**ï¼šæ•°æ®ä»“åº“åˆ°SQL Schemaæ ¼å¼
2. **æ•°æ®ä»“åº“åˆ°JSON Schemaè½¬æ¢**ï¼šæ•°æ®ä»“åº“åˆ°JSON Schemaæ ¼å¼
3. **æ•°æ®ä»“åº“åˆ°OpenAPIè½¬æ¢**ï¼šæ•°æ®ä»“åº“åˆ°OpenAPIæ ¼å¼
4. **æ•°æ®ä»“åº“åˆ°æ•°æ®åº“è½¬æ¢**ï¼šæ•°æ®ä»“åº“æ•°æ®åˆ°PostgreSQLå­˜å‚¨

---

## 2. æ•°æ®ä»“åº“åˆ°SQL Schemaè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- äº‹å®è¡¨ â†’ SQL Table
- ç»´åº¦è¡¨ â†’ SQL Table
- ç»´åº¦é”® â†’ SQL Foreign Key

**è½¬æ¢ç¤ºä¾‹**ï¼š

```python
def convert_dw_to_sql(dw_data: DataWarehouseSchema) -> SQLSchema:
    """å°†æ•°æ®ä»“åº“æ•°æ®è½¬æ¢ä¸ºSQL Schemaæ ¼å¼"""
    sql_schema = SQLSchema()

    # è½¬æ¢äº‹å®è¡¨
    for fact_table in dw_data.star_schema.fact_tables:
        sql_table = SQLTable()
        sql_table.table_name = fact_table.fact_table_name

        # è½¬æ¢åº¦é‡
        for measure in fact_table.measures:
            sql_column = SQLColumn()
            sql_column.column_name = measure.measure_name
            sql_column.data_type = measure.data_type
            sql_column.is_nullable = False
            sql_table.columns.append(sql_column)

        # è½¬æ¢ç»´åº¦é”®
        for dimension_key in fact_table.dimension_keys:
            sql_column = SQLColumn()
            sql_column.column_name = dimension_key.foreign_key_name
            sql_column.data_type = "INTEGER"
            sql_column.is_nullable = False
            sql_table.columns.append(sql_column)

            # åˆ›å»ºå¤–é”®
            sql_foreign_key = SQLForeignKey()
            sql_foreign_key.column_name = dimension_key.foreign_key_name
            sql_foreign_key.referenced_table = get_dimension_table_name(dimension_key.dimension_table_id)
            sql_foreign_key.referenced_column = "dimension_id"
            sql_table.foreign_keys.append(sql_foreign_key)

        sql_schema.tables.append(sql_table)

    # è½¬æ¢ç»´åº¦è¡¨
    for dimension_table in dw_data.star_schema.dimension_tables:
        sql_table = SQLTable()
        sql_table.table_name = dimension_table.dimension_table_name

        # è½¬æ¢ä¸»é”®
        sql_column = SQLColumn()
        sql_column.column_name = dimension_table.primary_key
        sql_column.data_type = "INTEGER"
        sql_column.is_primary_key = True
        sql_column.is_nullable = False
        sql_table.columns.append(sql_column)

        # è½¬æ¢å±æ€§
        for attribute in dimension_table.attributes:
            sql_column = SQLColumn()
            sql_column.column_name = attribute.attribute_name
            sql_column.data_type = attribute.data_type
            sql_column.is_nullable = not attribute.is_required
            sql_table.columns.append(sql_column)

        sql_schema.tables.append(sql_table)

    return sql_schema
```

---

## 3. æ•°æ®ä»“åº“åˆ°JSON Schemaè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- äº‹å®è¡¨ â†’ JSON Schema Object
- ç»´åº¦è¡¨ â†’ JSON Schema Object
- åº¦é‡ â†’ JSON Schema Property

**è½¬æ¢ç¤ºä¾‹**ï¼š

```python
def convert_dw_to_json_schema(dw_data: DataWarehouseSchema) -> JSONSchema:
    """å°†æ•°æ®ä»“åº“æ•°æ®è½¬æ¢ä¸ºJSON Schemaæ ¼å¼"""
    json_schema = {
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object",
        "properties": {}
    }

    # è½¬æ¢äº‹å®è¡¨
    for fact_table in dw_data.star_schema.fact_tables:
        fact_schema = {
            "type": "object",
            "properties": {}
        }

        # è½¬æ¢åº¦é‡
        for measure in fact_table.measures:
            fact_schema["properties"][measure.measure_name] = {
                "type": map_data_type_to_json_type(measure.data_type),
                "description": measure.measure_name
            }

        # è½¬æ¢ç»´åº¦é”®
        for dimension_key in fact_table.dimension_keys:
            fact_schema["properties"][dimension_key.foreign_key_name] = {
                "type": "integer",
                "description": f"Foreign key to {dimension_key.dimension_table_id}"
            }

        json_schema["properties"][fact_table.fact_table_name] = fact_schema

    # è½¬æ¢ç»´åº¦è¡¨
    for dimension_table in dw_data.star_schema.dimension_tables:
        dimension_schema = {
            "type": "object",
            "properties": {}
        }

        # è½¬æ¢å±æ€§
        for attribute in dimension_table.attributes:
            dimension_schema["properties"][attribute.attribute_name] = {
                "type": map_data_type_to_json_type(attribute.data_type),
                "description": attribute.attribute_name
            }

        json_schema["properties"][dimension_table.dimension_table_name] = dimension_schema

    return json_schema
```

---

## 4. æ•°æ®ä»“åº“åˆ°OpenAPIè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- äº‹å®è¡¨ â†’ OpenAPI Schema
- ç»´åº¦è¡¨ â†’ OpenAPI Schema
- æ•°æ®ä»“åº“ â†’ OpenAPI API

**è½¬æ¢ç¤ºä¾‹**ï¼š

```python
def convert_dw_to_openapi(dw_data: DataWarehouseSchema) -> OpenAPISchema:
    """å°†æ•°æ®ä»“åº“æ•°æ®è½¬æ¢ä¸ºOpenAPIæ ¼å¼"""
    openapi_schema = OpenAPISchema()

    # è½¬æ¢äº‹å®è¡¨
    for fact_table in dw_data.star_schema.fact_tables:
        fact_schema = {
            "type": "object",
            "properties": {}
        }

        # è½¬æ¢åº¦é‡
        for measure in fact_table.measures:
            fact_schema["properties"][measure.measure_name] = {
                "type": map_data_type_to_openapi_type(measure.data_type),
                "description": measure.measure_name
            }

        # è½¬æ¢ç»´åº¦é”®
        for dimension_key in fact_table.dimension_keys:
            fact_schema["properties"][dimension_key.foreign_key_name] = {
                "type": "integer",
                "format": "int64",
                "description": f"Foreign key to {dimension_key.dimension_table_id}"
            }

        openapi_schema.components.schemas[fact_table.fact_table_name] = fact_schema

    # è½¬æ¢ç»´åº¦è¡¨
    for dimension_table in dw_data.star_schema.dimension_tables:
        dimension_schema = {
            "type": "object",
            "properties": {}
        }

        # è½¬æ¢å±æ€§
        for attribute in dimension_table.attributes:
            dimension_schema["properties"][attribute.attribute_name] = {
                "type": map_data_type_to_openapi_type(attribute.data_type),
                "description": attribute.attribute_name
            }

        openapi_schema.components.schemas[dimension_table.dimension_table_name] = dimension_schema

    return openapi_schema
```

---

## 5. æ•°æ®ä»“åº“æ•°æ®å­˜å‚¨ä¸åˆ†æ

### 5.1 PostgreSQLæ•°æ®ä»“åº“æ•°æ®å­˜å‚¨

**è¡¨ç»“æ„è®¾è®¡**ï¼š

```sql
-- äº‹å®è¡¨å…ƒæ•°æ®è¡¨
CREATE TABLE fact_table_metadata (
    fact_table_id VARCHAR(50) PRIMARY KEY,
    fact_table_name VARCHAR(200) NOT NULL,
    fact_table_type VARCHAR(20) NOT NULL,
    grain VARCHAR(200) NOT NULL,
    partition_key VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç»´åº¦è¡¨å…ƒæ•°æ®è¡¨
CREATE TABLE dimension_table_metadata (
    dimension_table_id VARCHAR(50) PRIMARY KEY,
    dimension_table_name VARCHAR(200) NOT NULL,
    dimension_type VARCHAR(20) NOT NULL,
    primary_key VARCHAR(100) NOT NULL,
    slow_changing_type VARCHAR(10) DEFAULT 'Type1',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åº¦é‡å…ƒæ•°æ®è¡¨
CREATE TABLE measure_metadata (
    measure_id VARCHAR(50) PRIMARY KEY,
    fact_table_id VARCHAR(50) NOT NULL,
    measure_name VARCHAR(200) NOT NULL,
    measure_type VARCHAR(20) NOT NULL,
    data_type VARCHAR(20) NOT NULL,
    aggregation_function VARCHAR(50) NOT NULL,
    FOREIGN KEY (fact_table_id) REFERENCES fact_table_metadata(fact_table_id)
);

-- ç»´åº¦å±æ€§å…ƒæ•°æ®è¡¨
CREATE TABLE dimension_attribute_metadata (
    attribute_id VARCHAR(50) PRIMARY KEY,
    dimension_table_id VARCHAR(50) NOT NULL,
    attribute_name VARCHAR(200) NOT NULL,
    attribute_type VARCHAR(20) NOT NULL,
    data_type VARCHAR(20) NOT NULL,
    is_required BOOLEAN DEFAULT TRUE,
    FOREIGN KEY (dimension_table_id) REFERENCES dimension_table_metadata(dimension_table_id)
);

-- æ•°æ®è¡€ç¼˜è¡¨
CREATE TABLE data_lineage (
    lineage_id VARCHAR(50) PRIMARY KEY,
    from_node_id VARCHAR(50) NOT NULL,
    to_node_id VARCHAR(50) NOT NULL,
    transformation_rule TEXT,
    data_flow_type VARCHAR(20) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ•°æ®è´¨é‡æŒ‡æ ‡è¡¨
CREATE TABLE data_quality_metrics (
    metric_id VARCHAR(50) PRIMARY KEY,
    table_id VARCHAR(50) NOT NULL,
    metric_name VARCHAR(200) NOT NULL,
    metric_type VARCHAR(20) NOT NULL,
    metric_value DECIMAL(5, 2),
    threshold DECIMAL(5, 2) DEFAULT 90,
    is_passed BOOLEAN,
    check_date DATE NOT NULL
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_measure_metadata_fact_table ON measure_metadata(fact_table_id);
CREATE INDEX idx_dimension_attribute_metadata_dimension ON dimension_attribute_metadata(dimension_table_id);
CREATE INDEX idx_data_lineage_from_node ON data_lineage(from_node_id);
CREATE INDEX idx_data_lineage_to_node ON data_lineage(to_node_id);
CREATE INDEX idx_data_quality_metrics_table ON data_quality_metrics(table_id);
```

### 5.2 æ•°æ®ä»“åº“æ•°æ®åˆ†ææŸ¥è¯¢

**æŸ¥è¯¢ç¤ºä¾‹**ï¼š

```python
def analyze_dw_metadata(conn):
    """åˆ†ææ•°æ®ä»“åº“å…ƒæ•°æ®"""
    cursor = conn.cursor()

    # æŸ¥è¯¢äº‹å®è¡¨æ±‡æ€»
    cursor.execute("""
        SELECT
            ftm.fact_table_name,
            ftm.fact_table_type,
            COUNT(mm.measure_id) as measure_count,
            COUNT(DISTINCT dkm.dimension_key_id) as dimension_count
        FROM fact_table_metadata ftm
        LEFT JOIN measure_metadata mm ON ftm.fact_table_id = mm.fact_table_id
        LEFT JOIN dimension_key_metadata dkm ON ftm.fact_table_id = dkm.fact_table_id
        GROUP BY ftm.fact_table_id, ftm.fact_table_name, ftm.fact_table_type
        ORDER BY ftm.fact_table_name
    """)

    fact_table_summary = cursor.fetchall()

    # æŸ¥è¯¢ç»´åº¦è¡¨æ±‡æ€»
    cursor.execute("""
        SELECT
            dtm.dimension_table_name,
            dtm.dimension_type,
            COUNT(dam.attribute_id) as attribute_count
        FROM dimension_table_metadata dtm
        LEFT JOIN dimension_attribute_metadata dam ON dtm.dimension_table_id = dam.dimension_table_id
        GROUP BY dtm.dimension_table_id, dtm.dimension_table_name, dtm.dimension_type
        ORDER BY dtm.dimension_table_name
    """)

    dimension_table_summary = cursor.fetchall()

    # æŸ¥è¯¢æ•°æ®è´¨é‡æ±‡æ€»
    cursor.execute("""
        SELECT
            dqm.table_id,
            dqm.metric_type,
            AVG(dqm.metric_value) as avg_metric_value,
            COUNT(*) as check_count,
            SUM(CASE WHEN dqm.is_passed THEN 1 ELSE 0 END) as passed_count
        FROM data_quality_metrics dqm
        WHERE dqm.check_date >= CURRENT_DATE - INTERVAL '30 days'
        GROUP BY dqm.table_id, dqm.metric_type
        ORDER BY dqm.table_id, dqm.metric_type
    """)

    quality_summary = cursor.fetchall()

    return {
        "fact_table_summary": fact_table_summary,
        "dimension_table_summary": dimension_table_summary,
        "quality_summary": quality_summary
    }
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `05_Case_Studies.md` - å®è·µæ¡ˆä¾‹

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
