# æ¶ˆæ¯é˜Ÿåˆ—Schemaè½¬æ¢ä½“ç³»

## ğŸ“‘ ç›®å½•

- [æ¶ˆæ¯é˜Ÿåˆ—Schemaè½¬æ¢ä½“ç³»](#æ¶ˆæ¯é˜Ÿåˆ—schemaè½¬æ¢ä½“ç³»)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. è½¬æ¢ä½“ç³»æ¦‚è¿°](#1-è½¬æ¢ä½“ç³»æ¦‚è¿°)
  - [2. åè®®è½¬æ¢](#2-åè®®è½¬æ¢)
    - [2.1 MQTTåˆ°Kafkaè½¬æ¢](#21-mqttåˆ°kafkaè½¬æ¢)
    - [2.2 Kafkaåˆ°MQTTè½¬æ¢](#22-kafkaåˆ°mqttè½¬æ¢)
    - [2.3 AMQPè½¬æ¢](#23-amqpè½¬æ¢)
  - [3. æ¶ˆæ¯æ ¼å¼è½¬æ¢](#3-æ¶ˆæ¯æ ¼å¼è½¬æ¢)
  - [4. è½¬æ¢å·¥å…·](#4-è½¬æ¢å·¥å…·)
  - [5. è½¬æ¢éªŒè¯](#5-è½¬æ¢éªŒè¯)
  - [6. æ¶ˆæ¯é˜Ÿåˆ—æ•°æ®å­˜å‚¨ä¸åˆ†æ](#6-æ¶ˆæ¯é˜Ÿåˆ—æ•°æ®å­˜å‚¨ä¸åˆ†æ)
    - [6.1 PostgreSQLæ¶ˆæ¯é˜Ÿåˆ—æ•°æ®å­˜å‚¨](#61-postgresqlæ¶ˆæ¯é˜Ÿåˆ—æ•°æ®å­˜å‚¨)
    - [6.2 æ¶ˆæ¯é˜Ÿåˆ—æ•°æ®åˆ†ææŸ¥è¯¢](#62-æ¶ˆæ¯é˜Ÿåˆ—æ•°æ®åˆ†ææŸ¥è¯¢)

---

## 1. è½¬æ¢ä½“ç³»æ¦‚è¿°

æ¶ˆæ¯é˜Ÿåˆ—Schemaè½¬æ¢ä½“ç³»æ”¯æŒMQTTã€Kafkaã€AMQPç­‰åè®®ä¹‹é—´çš„è½¬æ¢ã€‚

### 1.1 è½¬æ¢ç›®æ ‡

1. **åè®®è½¬æ¢**ï¼šMQTT â†” Kafka, MQTT â†” AMQP
2. **æ¶ˆæ¯æ ¼å¼è½¬æ¢**ï¼šJSON â†” Avro, Binary â†” Protobuf
3. **ä¸»é¢˜æ˜ å°„**ï¼šMQTTä¸»é¢˜ â†” Kafkaä¸»é¢˜

---

## 2. åè®®è½¬æ¢

### 2.1 MQTTåˆ°Kafkaè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- MQTTä¸»é¢˜ â†’ Kafkaä¸»é¢˜
- MQTTæ¶ˆæ¯è´Ÿè½½ â†’ Kafkaæ¶ˆæ¯å€¼
- MQTT QoS â†’ Kafka acksé…ç½®

### 2.2 Kafkaåˆ°MQTTè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- Kafkaä¸»é¢˜ â†’ MQTTä¸»é¢˜
- Kafkaæ¶ˆæ¯å€¼ â†’ MQTTæ¶ˆæ¯è´Ÿè½½
- Kafkaåˆ†åŒºé”® â†’ MQTTä¸»é¢˜åç¼€

### 2.3 AMQPè½¬æ¢

**è½¬æ¢è§„åˆ™**ï¼š

- AMQP Exchange â†’ MQTT/Kafkaä¸»é¢˜
- AMQP Queue â†’ Kafkaæ¶ˆè´¹è€…ç»„
- AMQP Routing Key â†’ ä¸»é¢˜æ¨¡å¼

---

## 3. æ¶ˆæ¯æ ¼å¼è½¬æ¢

æ”¯æŒJSONã€Avroã€Protobufã€Binaryç­‰æ ¼å¼ä¹‹é—´çš„è½¬æ¢ã€‚

---

## 4. è½¬æ¢å·¥å…·

- **Kafka Connect**ï¼šKafkaè¿æ¥å™¨
- **MQTT Bridge**ï¼šMQTTæ¡¥æ¥å·¥å…·
- **Protocol Gateway**ï¼šåè®®ç½‘å…³

---

## 5. è½¬æ¢éªŒè¯

éªŒè¯è½¬æ¢çš„è¯­ä¹‰ç­‰ä»·æ€§ã€æ€§èƒ½å’Œå¯é æ€§ã€‚

---

## 6. æ¶ˆæ¯é˜Ÿåˆ—æ•°æ®å­˜å‚¨ä¸åˆ†æ

### 6.1 PostgreSQLæ¶ˆæ¯é˜Ÿåˆ—æ•°æ®å­˜å‚¨

**æ¶ˆæ¯é˜Ÿåˆ—æ•°æ®å­˜å‚¨æ–¹æ¡ˆ**ï¼š

```python
import psycopg2
import json
from typing import Dict, List, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass

@dataclass
class KafkaMessage:
    """Kafkaæ¶ˆæ¯"""
    topic: str
    partition: int
    offset: int
    key: Optional[bytes]
    value: bytes
    timestamp: datetime
    headers: Dict[str, bytes] = None

class MessageQueueStorage:
    """æ¶ˆæ¯é˜Ÿåˆ—æ•°æ®å­˜å‚¨ç³»ç»Ÿ"""

    def __init__(self, connection_string: str):
        self.conn = psycopg2.connect(connection_string)
        self.cur = self.conn.cursor()
        self._create_tables()

    def _create_tables(self):
        """åˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—æ•°æ®è¡¨"""
        # MQTTæ¶ˆæ¯è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS mqtt_messages (
                id BIGSERIAL PRIMARY KEY,
                topic VARCHAR(500) NOT NULL,
                payload BYTEA NOT NULL,
                payload_text TEXT,
                qos INTEGER NOT NULL,
                retain BOOLEAN DEFAULT FALSE,
                client_id VARCHAR(200),
                timestamp TIMESTAMP NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # Kafkaæ¶ˆæ¯è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS kafka_messages (
                id BIGSERIAL PRIMARY KEY,
                topic VARCHAR(500) NOT NULL,
                partition INTEGER NOT NULL,
                offset BIGINT NOT NULL,
                message_key BYTEA,
                message_value BYTEA NOT NULL,
                message_value_text TEXT,
                headers JSONB,
                timestamp TIMESTAMP NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(topic, partition, offset)
            )
        """)

        # ä¸»é¢˜å®šä¹‰è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS topic_definitions (
                id SERIAL PRIMARY KEY,
                topic_name VARCHAR(500) UNIQUE NOT NULL,
                protocol_type VARCHAR(50) NOT NULL,
                definition JSONB NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # æ¶ˆæ¯ç»Ÿè®¡è¡¨
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS message_statistics (
                id SERIAL PRIMARY KEY,
                topic_name VARCHAR(500) NOT NULL,
                protocol_type VARCHAR(50) NOT NULL,
                time_window TIMESTAMP NOT NULL,
                statistics JSONB NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(topic_name, protocol_type, time_window)
            )
        """)

        # åˆ›å»ºç´¢å¼•
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_mqtt_topic_time
            ON mqtt_messages(topic, timestamp DESC)
        """)
        self.cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_kafka_topic_partition_offset
            ON kafka_messages(topic, partition, offset DESC)
        """)

        self.conn.commit()

    def store_mqtt_message(self, topic: str, payload: bytes,
                          qos: int, retain: bool, timestamp: datetime,
                          client_id: str = None):
        """å­˜å‚¨MQTTæ¶ˆæ¯"""
        payload_text = payload.decode('utf-8', errors='ignore')
        self.cur.execute("""
            INSERT INTO mqtt_messages
            (topic, payload, payload_text, qos, retain, client_id, timestamp)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
        """, (topic, payload, payload_text, qos, retain, client_id, timestamp))
        self.conn.commit()

    def store_kafka_message(self, message: KafkaMessage):
        """å­˜å‚¨Kafkaæ¶ˆæ¯"""
        value_text = message.value.decode('utf-8', errors='ignore')
        headers_json = json.dumps({k: v.hex() for k, v in (message.headers or {}).items()})
        self.cur.execute("""
            INSERT INTO kafka_messages
            (topic, partition, offset, message_key, message_value,
             message_value_text, headers, timestamp)
            VALUES (%s, %s, %s, %s, %s, %s, %s::jsonb, %s)
            ON CONFLICT (topic, partition, offset) DO NOTHING
        """, (message.topic, message.partition, message.offset,
              message.key, message.value, value_text, headers_json,
              message.timestamp))
        self.conn.commit()

    def query_topic_messages(self, topic: str, protocol: str,
                            start_time: datetime, end_time: datetime,
                            limit: int = 1000):
        """æŸ¥è¯¢ä¸»é¢˜æ¶ˆæ¯"""
        if protocol == "MQTT":
            self.cur.execute("""
                SELECT topic, payload_text, qos, timestamp
                FROM mqtt_messages
                WHERE topic = %s AND timestamp BETWEEN %s AND %s
                ORDER BY timestamp DESC
                LIMIT %s
            """, (topic, start_time, end_time, limit))
        elif protocol == "Kafka":
            self.cur.execute("""
                SELECT topic, partition, offset, message_value_text, timestamp
                FROM kafka_messages
                WHERE topic = %s AND timestamp BETWEEN %s AND %s
                ORDER BY timestamp DESC
                LIMIT %s
            """, (topic, start_time, end_time, limit))
        return self.cur.fetchall()

    def calculate_statistics(self, topic: str, protocol: str,
                            time_window: datetime):
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        if protocol == "MQTT":
            self.cur.execute("""
                SELECT
                    COUNT(*) as message_count,
                    COUNT(DISTINCT client_id) as client_count,
                    AVG(LENGTH(payload)) as avg_payload_size
                FROM mqtt_messages
                WHERE topic = %s AND timestamp >= %s
            """, (topic, time_window))
        elif protocol == "Kafka":
            self.cur.execute("""
                SELECT
                    COUNT(*) as message_count,
                    COUNT(DISTINCT partition) as partition_count,
                    MAX(offset) - MIN(offset) as offset_range,
                    AVG(LENGTH(message_value)) as avg_value_size
                FROM kafka_messages
                WHERE topic = %s AND timestamp >= %s
            """, (topic, time_window))

        stats = dict(zip([desc[0] for desc in self.cur.description],
                         self.cur.fetchone()))

        # å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
        self.cur.execute("""
            INSERT INTO message_statistics
            (topic_name, protocol_type, time_window, statistics)
            VALUES (%s, %s, %s, %s::jsonb)
            ON CONFLICT (topic_name, protocol_type, time_window)
            DO UPDATE SET statistics = EXCLUDED.statistics
        """, (topic, protocol, time_window, json.dumps(stats)))
        self.conn.commit()

        return stats
```

### 6.2 æ¶ˆæ¯é˜Ÿåˆ—æ•°æ®åˆ†ææŸ¥è¯¢

**æŸ¥è¯¢ç¤ºä¾‹**ï¼š

```python
# æŸ¥è¯¢MQTTä¸»é¢˜æ¶ˆæ¯æµé‡
storage.query_topic_messages(
    topic="sensors/temperature",
    protocol="MQTT",
    start_time=datetime.now() - timedelta(hours=1),
    end_time=datetime.now()
)

# è®¡ç®—Kafkaä¸»é¢˜ç»Ÿè®¡ä¿¡æ¯
stats = storage.calculate_statistics(
    topic="sensor-stream",
    protocol="Kafka",
    time_window=datetime.now() - timedelta(hours=1)
)
```

---

**å‚è€ƒæ–‡æ¡£**ï¼š

- `01_Overview.md` - æ¦‚è¿°
- `02_Formal_Definition.md` - å½¢å¼åŒ–å®šä¹‰
- `03_Standards.md` - æ ‡å‡†å¯¹æ ‡
- `05_Case_Studies.md` - å®è·µæ¡ˆä¾‹

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
