# å¢é‡è½¬æ¢å®æ–½æŒ‡å—

## ğŸ“‘ ç›®å½•

- [å¢é‡è½¬æ¢å®æ–½æŒ‡å—](#å¢é‡è½¬æ¢å®æ–½æŒ‡å—)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. å®æ–½æ¦‚è¿°](#1-å®æ–½æ¦‚è¿°)
    - [1.1 å®æ–½ç›®æ ‡](#11-å®æ–½ç›®æ ‡)
    - [1.2 å®æ–½æ­¥éª¤](#12-å®æ–½æ­¥éª¤)
  - [2. å˜æ›´æ£€æµ‹å®ç°](#2-å˜æ›´æ£€æµ‹å®ç°)
    - [2.1 å“ˆå¸Œæ¯”è¾ƒå®ç°](#21-å“ˆå¸Œæ¯”è¾ƒå®ç°)
    - [2.2 å·®å¼‚ç®—æ³•å®ç°](#22-å·®å¼‚ç®—æ³•å®ç°)
    - [2.3 äº‹ä»¶é©±åŠ¨å®ç°](#23-äº‹ä»¶é©±åŠ¨å®ç°)
  - [3. å¢é‡æ›´æ–°å®ç°](#3-å¢é‡æ›´æ–°å®ç°)
    - [3.1 æ›´æ–°ç­–ç•¥å®ç°](#31-æ›´æ–°ç­–ç•¥å®ç°)
    - [3.2 å¢é‡è½¬æ¢å¼•æ“](#32-å¢é‡è½¬æ¢å¼•æ“)
    - [3.3 ç»“æœåˆå¹¶æœºåˆ¶](#33-ç»“æœåˆå¹¶æœºåˆ¶)
  - [4. ä¾èµ–åˆ†æå®ç°](#4-ä¾èµ–åˆ†æå®ç°)
    - [4.1 ä¾èµ–å›¾æ„å»º](#41-ä¾èµ–å›¾æ„å»º)
    - [4.2 ä¾èµ–ä¼ æ’­å®ç°](#42-ä¾èµ–ä¼ æ’­å®ç°)
    - [4.3 ä¾èµ–ä¼˜åŒ–å®ç°](#43-ä¾èµ–ä¼˜åŒ–å®ç°)
  - [5. å†²çªå¤„ç†å®ç°](#5-å†²çªå¤„ç†å®ç°)
    - [5.1 å†²çªæ£€æµ‹](#51-å†²çªæ£€æµ‹)
    - [5.2 å†²çªè§£å†³ç­–ç•¥](#52-å†²çªè§£å†³ç­–ç•¥)
    - [5.3 å†²çªåˆå¹¶ç®—æ³•](#53-å†²çªåˆå¹¶ç®—æ³•)
  - [6. æ€§èƒ½ä¼˜åŒ–å®ç°](#6-æ€§èƒ½ä¼˜åŒ–å®ç°)
    - [6.1 ç¼“å­˜æœºåˆ¶](#61-ç¼“å­˜æœºåˆ¶)
    - [6.2 å¹¶è¡Œå¤„ç†](#62-å¹¶è¡Œå¤„ç†)
    - [6.3 å»¶è¿Ÿè®¡ç®—](#63-å»¶è¿Ÿè®¡ç®—)
  - [7. æµ‹è¯•ä¸éªŒè¯](#7-æµ‹è¯•ä¸éªŒè¯)
    - [7.1 å•å…ƒæµ‹è¯•](#71-å•å…ƒæµ‹è¯•)
    - [7.2 é›†æˆæµ‹è¯•](#72-é›†æˆæµ‹è¯•)
    - [7.3 æ€§èƒ½æµ‹è¯•](#73-æ€§èƒ½æµ‹è¯•)
  - [8. éƒ¨ç½²ä¸è¿ç»´](#8-éƒ¨ç½²ä¸è¿ç»´)
    - [8.1 éƒ¨ç½²é…ç½®](#81-éƒ¨ç½²é…ç½®)
    - [8.2 ç›‘æ§å‘Šè­¦](#82-ç›‘æ§å‘Šè­¦)
    - [8.3 æ•…éšœå¤„ç†](#83-æ•…éšœå¤„ç†)
  - [9. å¢é‡è½¬æ¢ç»¼åˆåº”ç”¨å®é™…ç¤ºä¾‹](#9-å¢é‡è½¬æ¢ç»¼åˆåº”ç”¨å®é™…ç¤ºä¾‹)
  - [10. å‚è€ƒæ–‡æ¡£](#10-å‚è€ƒæ–‡æ¡£)
    - [ç®—æ³•æ–‡æ¡£](#ç®—æ³•æ–‡æ¡£)
    - [æ¨¡å¼æ–‡æ¡£ â­æ–°å¢](#æ¨¡å¼æ–‡æ¡£-æ–°å¢)
  - [ğŸ“ ç‰ˆæœ¬å†å²](#-ç‰ˆæœ¬å†å²)

---

## 1. å®æ–½æ¦‚è¿°

### 1.1 å®æ–½ç›®æ ‡

**å®æ–½ç›®æ ‡**ï¼š

1. **å˜æ›´æ£€æµ‹å‡†ç¡®ç‡**ï¼šâ‰¥ 95%
2. **å¢é‡æ›´æ–°æ•ˆç‡**ï¼šæå‡70%ä»¥ä¸Š
3. **ä¾èµ–åˆ†æå®Œæ•´æ€§**ï¼š100%
4. **å†²çªå¤„ç†æ­£ç¡®æ€§**ï¼š100%

### 1.2 å®æ–½æ­¥éª¤

**å®æ–½é˜¶æ®µ**ï¼š

1. **é˜¶æ®µ1**ï¼šå˜æ›´æ£€æµ‹å®ç°ï¼ˆWeek 1ï¼‰
2. **é˜¶æ®µ2**ï¼šå¢é‡æ›´æ–°å®ç°ï¼ˆWeek 1-2ï¼‰
3. **é˜¶æ®µ3**ï¼šä¾èµ–åˆ†æå®ç°ï¼ˆWeek 2ï¼‰
4. **é˜¶æ®µ4**ï¼šå†²çªå¤„ç†å®ç°ï¼ˆWeek 2-3ï¼‰
5. **é˜¶æ®µ5**ï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆWeek 3ï¼‰
6. **é˜¶æ®µ6**ï¼šæµ‹è¯•éªŒè¯ï¼ˆWeek 3-4ï¼‰

---

## 2. å˜æ›´æ£€æµ‹å®ç°

### 2.1 å“ˆå¸Œæ¯”è¾ƒå®ç°

**å®ç°ä»£ç **ï¼š

```typescript
// src/transformers/incremental/change-detector.ts
import { createHash } from 'crypto';

export class ChangeDetector {
  private hashCache: Map<string, string> = new Map();

  computeHash(schema: Schema): string {
    const key = schema.id;
    if (this.hashCache.has(key)) {
      return this.hashCache.get(key)!;
    }

    const hash = createHash('sha256')
      .update(JSON.stringify(schema))
      .digest('hex');

    this.hashCache.set(key, hash);
    return hash;
  }

  detectChanges(
    oldSchema: Schema,
    newSchema: Schema
  ): Change[] {
    const oldHash = this.computeHash(oldSchema);
    const newHash = this.computeHash(newSchema);

    if (oldHash === newHash) {
      return []; // æ— å˜æ›´
    }

    // ä½¿ç”¨å·®å¼‚ç®—æ³•æ£€æµ‹è¯¦ç»†å˜æ›´
    return this.detectDetailedChanges(oldSchema, newSchema);
  }

  private detectDetailedChanges(
    oldSchema: Schema,
    newSchema: Schema
  ): Change[] {
    const changes: Change[] = [];

    // æ£€æµ‹å­—æ®µå˜æ›´
    changes.push(...this.detectFieldChanges(oldSchema, newSchema));

    // æ£€æµ‹ç±»å‹å˜æ›´
    changes.push(...this.detectTypeChanges(oldSchema, newSchema));

    // æ£€æµ‹æ“ä½œå˜æ›´
    changes.push(...this.detectOperationChanges(oldSchema, newSchema));

    return changes;
  }
}
```

### 2.2 å·®å¼‚ç®—æ³•å®ç°

**Myersç®—æ³•å®ç°**ï¼š

```typescript
// src/transformers/incremental/diff-algorithm.ts
export class DiffAlgorithm {
  computeDiff(oldSchema: Schema, newSchema: Schema): Change[] {
    const oldPaths = this.extractPaths(oldSchema);
    const newPaths = this.extractPaths(newSchema);

    return this.myersDiff(oldPaths, newPaths);
  }

  private myersDiff(
    oldPaths: string[],
    newPaths: string[]
  ): Change[] {
    // Myerså·®å¼‚ç®—æ³•å®ç°
    const changes: Change[] = [];
    const n = oldPaths.length;
    const m = newPaths.length;

    // å®ç°Myersç®—æ³•æ ¸å¿ƒé€»è¾‘
    // ...

    return changes;
  }
}
```

### 2.3 äº‹ä»¶é©±åŠ¨å®ç°

**äº‹ä»¶ç›‘å¬**ï¼š

```typescript
// src/transformers/incremental/event-driven.ts
import { EventEmitter } from 'events';

export class SchemaChangeEmitter extends EventEmitter {
  watch(schema: Schema): void {
    // ç›‘å¬Schemaå˜æ›´äº‹ä»¶
    this.on('schema-change', (change: Change) => {
      this.handleChange(change);
    });
  }

  private handleChange(change: Change): void {
    // å¤„ç†å˜æ›´äº‹ä»¶
    this.emit('change-detected', change);
  }
}
```

---

## 3. å¢é‡æ›´æ–°å®ç°

### 3.1 æ›´æ–°ç­–ç•¥å®ç°

**ç­–ç•¥å®ç°**ï¼š

```typescript
// src/transformers/incremental/update-strategy.ts
export class UpdateStrategy {
  async update(
    changes: Change[],
    strategy: 'immediate' | 'batch' | 'delayed' | 'smart'
  ): Promise<void> {
    switch (strategy) {
      case 'immediate':
        return this.immediateUpdate(changes);
      case 'batch':
        return this.batchUpdate(changes);
      case 'delayed':
        return this.delayedUpdate(changes);
      case 'smart':
        return this.smartUpdate(changes);
    }
  }

  private async immediateUpdate(changes: Change[]): Promise<void> {
    for (const change of changes) {
      await this.processChange(change);
    }
  }

  private async batchUpdate(changes: Change[]): Promise<void> {
    // æ‰¹é‡å¤„ç†å˜æ›´
    await this.processBatch(changes);
  }

  private async smartUpdate(changes: Change[]): Promise<void> {
    // æ ¹æ®å˜æ›´ç±»å‹é€‰æ‹©ç­–ç•¥
    const critical = changes.filter(c => c.priority === 'high');
    const normal = changes.filter(c => c.priority === 'normal');

    await this.immediateUpdate(critical);
    await this.batchUpdate(normal);
  }
}
```

### 3.2 å¢é‡è½¬æ¢å¼•æ“

**è½¬æ¢å¼•æ“**ï¼š

```typescript
// src/transformers/incremental/incremental-transformer.ts
export class IncrementalTransformer {
  async transformIncremental(
    oldSchema: Schema,
    newSchema: Schema,
    changes: Change[]
  ): Promise<TransformationResult> {
    const result: TransformationResult = {
      changed: [],
      unchanged: [],
      deleted: [],
    };

    for (const change of changes) {
      switch (change.type) {
        case 'add':
          result.changed.push(await this.transformAdded(change));
          break;
        case 'modify':
          result.changed.push(await this.transformModified(change));
          break;
        case 'delete':
          result.deleted.push(await this.transformDeleted(change));
          break;
      }
    }

    return result;
  }

  private async transformAdded(change: Change): Promise<TransformedNode> {
    // è½¬æ¢æ–°å¢èŠ‚ç‚¹
    return this.transform(change.newValue);
  }

  private async transformModified(change: Change): Promise<TransformedNode> {
    // è½¬æ¢ä¿®æ”¹èŠ‚ç‚¹
    const oldResult = this.getCachedResult(change.path);
    const newResult = await this.transform(change.newValue);

    // åˆå¹¶ç»“æœ
    return this.mergeResults(oldResult, newResult);
  }

  private async transformDeleted(change: Change): Promise<void> {
    // æ¸…ç†åˆ é™¤èŠ‚ç‚¹
    this.removeCachedResult(change.path);
  }
}
```

### 3.3 ç»“æœåˆå¹¶æœºåˆ¶

**åˆå¹¶ç®—æ³•**ï¼š

```typescript
// src/transformers/incremental/result-merger.ts
export class ResultMerger {
  merge(
    oldResult: TransformationResult,
    newResult: TransformationResult
  ): TransformationResult {
    return {
      changed: this.mergeChanged(oldResult.changed, newResult.changed),
      unchanged: this.mergeUnchanged(oldResult.unchanged, newResult.unchanged),
      deleted: this.mergeDeleted(oldResult.deleted, newResult.deleted),
    };
  }

  private mergeChanged(
    old: TransformedNode[],
    new_: TransformedNode[]
  ): TransformedNode[] {
    // åˆå¹¶å˜æ›´ç»“æœ
    const merged = new Map<string, TransformedNode>();

    old.forEach(node => merged.set(node.id, node));
    new_.forEach(node => {
      const existing = merged.get(node.id);
      if (existing) {
        merged.set(node.id, this.mergeNode(existing, node));
      } else {
        merged.set(node.id, node);
      }
    });

    return Array.from(merged.values());
  }
}
```

---

## 4. ä¾èµ–åˆ†æå®ç°

### 4.1 ä¾èµ–å›¾æ„å»º

**æ„å»ºå®ç°**ï¼š

```typescript
// src/transformers/incremental/dependency-graph.ts
export class DependencyGraphBuilder {
  buildGraph(schemas: Schema[]): DependencyGraph {
    const graph: DependencyGraph = {
      nodes: new Map(),
      edges: new Map(),
    };

    // æ„å»ºèŠ‚ç‚¹
    schemas.forEach(schema => {
      graph.nodes.set(schema.id, {
        id: schema.id,
        schema,
        dependencies: [],
        dependents: [],
      });
    });

    // æ„å»ºè¾¹
    schemas.forEach(schema => {
      const dependencies = this.extractDependencies(schema);
      dependencies.forEach(depId => {
        this.addEdge(graph, schema.id, depId);
      });
    });

    return graph;
  }

  private extractDependencies(schema: Schema): string[] {
    const dependencies: string[] = [];

    // æå–å¼•ç”¨ä¾èµ–
    this.traverseSchema(schema, (node) => {
      if (node.$ref) {
        dependencies.push(this.resolveRef(node.$ref));
      }
    });

    return dependencies;
  }

  private addEdge(
    graph: DependencyGraph,
    from: string,
    to: string
  ): void {
    const fromNode = graph.nodes.get(from);
    const toNode = graph.nodes.get(to);

    if (fromNode && toNode) {
      fromNode.dependencies.push(to);
      toNode.dependents.push(from);

      if (!graph.edges.has(from)) {
        graph.edges.set(from, []);
      }
      graph.edges.get(from)!.push({
        from,
        to,
        type: 'direct',
        weight: 1,
      });
    }
  }
}
```

### 4.2 ä¾èµ–ä¼ æ’­å®ç°

**ä¼ æ’­å®ç°**ï¼š

```typescript
// src/transformers/incremental/dependency-propagator.ts
export class DependencyPropagator {
  propagate(
    graph: DependencyGraph,
    changedNode: string
  ): Set<string> {
    const affected: Set<string> = new Set();
    const queue: string[] = [changedNode];
    const visited: Set<string> = new Set();

    while (queue.length > 0) {
      const nodeId = queue.shift()!;

      if (visited.has(nodeId)) continue;
      visited.add(nodeId);
      affected.add(nodeId);

      const node = graph.nodes.get(nodeId);
      if (node) {
        // ä¼ æ’­åˆ°ä¾èµ–èŠ‚ç‚¹
        node.dependents.forEach(dependentId => {
          if (!visited.has(dependentId)) {
            queue.push(dependentId);
          }
        });
      }
    }

    return affected;
  }

  getTopologicalOrder(graph: DependencyGraph): string[] {
    // æ‹“æ‰‘æ’åº
    const inDegree = new Map<string, number>();
    const queue: string[] = [];
    const result: string[] = [];

    // è®¡ç®—å…¥åº¦
    graph.nodes.forEach((node, id) => {
      inDegree.set(id, node.dependencies.length);
      if (node.dependencies.length === 0) {
        queue.push(id);
      }
    });

    // æ‹“æ‰‘æ’åº
    while (queue.length > 0) {
      const nodeId = queue.shift()!;
      result.push(nodeId);

      const node = graph.nodes.get(nodeId);
      if (node) {
        node.dependents.forEach(dependentId => {
          const degree = inDegree.get(dependentId)! - 1;
          inDegree.set(dependentId, degree);
          if (degree === 0) {
            queue.push(dependentId);
          }
        });
      }
    }

    return result;
  }
}
```

### 4.3 ä¾èµ–ä¼˜åŒ–å®ç°

**ä¼˜åŒ–å®ç°**ï¼š

```typescript
// src/transformers/incremental/dependency-optimizer.ts
export class DependencyOptimizer {
  optimize(graph: DependencyGraph): DependencyGraph {
    // å‹ç¼©ä¼ é€’ä¾èµ–
    const optimized = this.compressTransitive(graph);

    // ç¼“å­˜ä¾èµ–å…³ç³»
    this.cacheDependencies(optimized);

    return optimized;
  }

  private compressTransitive(
    graph: DependencyGraph
  ): DependencyGraph {
    // å‹ç¼©ä¼ é€’ä¾èµ–
    const compressed = this.cloneGraph(graph);

    // ç§»é™¤ä¼ é€’è¾¹
    compressed.nodes.forEach((node, id) => {
      const directDeps = new Set(node.dependencies);
      const transitiveDeps = this.getTransitiveDependencies(graph, id);

      transitiveDeps.forEach(transDep => {
        if (directDeps.has(transDep)) {
          // ç§»é™¤ä¼ é€’ä¾èµ–
          this.removeEdge(compressed, id, transDep);
        }
      });
    });

    return compressed;
  }

  private getTransitiveDependencies(
    graph: DependencyGraph,
    nodeId: string
  ): Set<string> {
    const transitive = new Set<string>();
    const visited = new Set<string>();

    const dfs = (id: string) => {
      if (visited.has(id)) return;
      visited.add(id);

      const node = graph.nodes.get(id);
      if (node) {
        node.dependencies.forEach(depId => {
          transitive.add(depId);
          dfs(depId);
        });
      }
    };

    const node = graph.nodes.get(nodeId);
    if (node) {
      node.dependencies.forEach(depId => {
        dfs(depId);
      });
    }

    return transitive;
  }
}
```

---

## 5. å†²çªå¤„ç†å®ç°

### 5.1 å†²çªæ£€æµ‹

**æ£€æµ‹å®ç°**ï¼š

```typescript
// src/transformers/incremental/conflict-detector.ts
export class ConflictDetector {
  detectConflicts(changes: Change[]): Conflict[] {
    const conflicts: Conflict[] = [];

    // æ£€æµ‹å¹¶å‘ä¿®æ”¹å†²çª
    conflicts.push(...this.detectConcurrentModifications(changes));

    // æ£€æµ‹ä¾èµ–å†²çª
    conflicts.push(...this.detectDependencyConflicts(changes));

    // æ£€æµ‹è½¬æ¢å†²çª
    conflicts.push(...this.detectTransformationConflicts(changes));

    return conflicts;
  }

  private detectConcurrentModifications(
    changes: Change[]
  ): Conflict[] {
    const conflicts: Conflict[] = [];
    const pathChanges = new Map<string, Change[]>();

    // æŒ‰è·¯å¾„åˆ†ç»„å˜æ›´
    changes.forEach(change => {
      const path = change.path.join('.');
      if (!pathChanges.has(path)) {
        pathChanges.set(path, []);
      }
      pathChanges.get(path)!.push(change);
    });

    // æ£€æµ‹åŒä¸€è·¯å¾„çš„å¤šä¸ªå˜æ›´
    pathChanges.forEach((changesForPath, path) => {
      if (changesForPath.length > 1) {
        conflicts.push({
          type: 'concurrent-modification',
          path,
          changes: changesForPath,
          resolution: 'merge',
        });
      }
    });

    return conflicts;
  }
}
```

### 5.2 å†²çªè§£å†³ç­–ç•¥

**è§£å†³ç­–ç•¥**ï¼š

```typescript
// src/transformers/incremental/conflict-resolver.ts
export class ConflictResolver {
  async resolve(conflict: Conflict): Promise<Resolution> {
    switch (conflict.type) {
      case 'concurrent-modification':
        return this.resolveConcurrentModification(conflict);
      case 'dependency':
        return this.resolveDependency(conflict);
      case 'transformation':
        return this.resolveTransformation(conflict);
    }
  }

  private async resolveConcurrentModification(
    conflict: Conflict
  ): Promise<Resolution> {
    // åˆå¹¶ç­–ç•¥
    if (conflict.resolution === 'merge') {
      return this.mergeChanges(conflict.changes);
    }

    // æœ€åå†™å…¥è·èƒœ
    if (conflict.resolution === 'last-write-wins') {
      return this.lastWriteWins(conflict.changes);
    }

    // æ‰‹åŠ¨è§£å†³
    return this.manualResolution(conflict);
  }
}
```

### 5.3 å†²çªåˆå¹¶ç®—æ³•

**åˆå¹¶ç®—æ³•**ï¼š

```typescript
// src/transformers/incremental/conflict-merger.ts
export class ConflictMerger {
  merge(changes: Change[]): Change {
    // ä¸‰è·¯åˆå¹¶ç®—æ³•
    const base = this.getBaseVersion(changes[0].path);
    const change1 = changes[0];
    const change2 = changes[1];

    return this.threeWayMerge(base, change1, change2);
  }

  private threeWayMerge(
    base: any,
    change1: Change,
    change2: Change
  ): Change {
    // ä¸‰è·¯åˆå¹¶é€»è¾‘
    // 1. å¦‚æœä¸¤ä¸ªå˜æ›´ç›¸åŒï¼Œè¿”å›ä»»ä¸€
    if (this.isEqual(change1.newValue, change2.newValue)) {
      return change1;
    }

    // 2. å¦‚æœä¸€ä¸ªå˜æ›´ä¸baseç›¸åŒï¼Œè¿”å›å¦ä¸€ä¸ª
    if (this.isEqual(change1.newValue, base)) {
      return change2;
    }
    if (this.isEqual(change2.newValue, base)) {
      return change1;
    }

    // 3. å¦åˆ™éœ€è¦æ‰‹åŠ¨åˆå¹¶
    return this.manualMerge(change1, change2);
  }
}
```

---

## 6. æ€§èƒ½ä¼˜åŒ–å®ç°

### 6.1 ç¼“å­˜æœºåˆ¶

**ç¼“å­˜å®ç°**ï¼š

```typescript
// src/transformers/incremental/transformation-cache.ts
export class TransformationCache {
  private cache: Map<string, CachedResult> = new Map();

  get(key: string): CachedResult | null {
    const cached = this.cache.get(key);
    if (cached && !this.isExpired(cached)) {
      return cached;
    }
    return null;
  }

  set(key: string, result: TransformationResult): void {
    this.cache.set(key, {
      result,
      timestamp: Date.now(),
      ttl: 3600000, // 1å°æ—¶
    });
  }

  invalidate(pattern: string): void {
    // å¤±æ•ˆåŒ¹é…çš„ç¼“å­˜
    for (const key of this.cache.keys()) {
      if (key.includes(pattern)) {
        this.cache.delete(key);
      }
    }
  }
}
```

### 6.2 å¹¶è¡Œå¤„ç†

**å¹¶è¡Œå®ç°**ï¼š

```typescript
// src/transformers/incremental/parallel-processor.ts
export class ParallelProcessor {
  async processParallel(
    tasks: Task[],
    concurrency: number = 5
  ): Promise<Result[]> {
    const results: Result[] = [];
    const executing: Promise<void>[] = [];

    for (const task of tasks) {
      const promise = this.processTask(task).then(result => {
        results.push(result);
      });

      executing.push(promise);

      if (executing.length >= concurrency) {
        await Promise.race(executing);
        executing.splice(
          executing.findIndex(p => p === promise),
          1
        );
      }
    }

    await Promise.all(executing);
    return results;
  }
}
```

### 6.3 å»¶è¿Ÿè®¡ç®—

**å»¶è¿Ÿå®ç°**ï¼š

```typescript
// src/transformers/incremental/lazy-evaluator.ts
export class LazyEvaluator {
  private lazyResults: Map<string, () => Promise<any>> = new Map();

  lazyTransform(path: string, transformer: () => Promise<any>): void {
    this.lazyResults.set(path, transformer);
  }

  async evaluate(path: string): Promise<any> {
    const transformer = this.lazyResults.get(path);
    if (transformer) {
      return await transformer();
    }
    return null;
  }

  async evaluateAll(): Promise<Map<string, any>> {
    const results = new Map<string, any>();

    for (const [path, transformer] of this.lazyResults.entries()) {
      results.set(path, await transformer());
    }

    return results;
  }
}
```

---

## 7. æµ‹è¯•ä¸éªŒè¯

### 7.1 å•å…ƒæµ‹è¯•

**æµ‹è¯•ç”¨ä¾‹**ï¼š

```typescript
// tests/incremental/change-detector.test.ts
describe('ChangeDetector', () => {
  it('should detect schema changes', () => {
    const detector = new ChangeDetector();
    const oldSchema = loadSchema('old.json');
    const newSchema = loadSchema('new.json');

    const changes = detector.detectChanges(oldSchema, newSchema);
    expect(changes.length).toBeGreaterThan(0);
  });
});
```

### 7.2 é›†æˆæµ‹è¯•

**é›†æˆæµ‹è¯•**ï¼š

```typescript
// tests/incremental/integration.test.ts
describe('Incremental Transformation Integration', () => {
  it('should transform incrementally', async () => {
    const transformer = new IncrementalTransformer();
    const oldSchema = loadSchema('v1.json');
    const newSchema = loadSchema('v2.json');

    const result = await transformer.transform(oldSchema, newSchema);
    expect(result.changed.length).toBeGreaterThan(0);
  });
});
```

### 7.3 æ€§èƒ½æµ‹è¯•

**æ€§èƒ½æµ‹è¯•**ï¼š

```typescript
// tests/incremental/performance.test.ts
describe('Performance Tests', () => {
  it('should be faster than full transformation', async () => {
    const transformer = new IncrementalTransformer();
    const oldSchema = loadLargeSchema('large-v1.json');
    const newSchema = loadLargeSchema('large-v2.json');

    const start = Date.now();
    await transformer.transform(oldSchema, newSchema);
    const incrementalTime = Date.now() - start;

    const start2 = Date.now();
    await fullTransform(newSchema);
    const fullTime = Date.now() - start2;

    expect(incrementalTime).toBeLessThan(fullTime * 0.3);
  });
});
```

---

## 8. éƒ¨ç½²ä¸è¿ç»´

### 8.1 éƒ¨ç½²é…ç½®

**é…ç½®ç¤ºä¾‹**ï¼š

```yaml
# config/incremental.yaml
changeDetection:
  method: hash
  hashAlgorithm: sha256
  cacheEnabled: true

updateStrategy:
  default: smart
  critical: immediate
  normal: batch

dependencyAnalysis:
  enabled: true
  cacheEnabled: true
  optimizationEnabled: true

conflictResolution:
  default: merge
  concurrent: last-write-wins
```

### 8.2 ç›‘æ§å‘Šè­¦

**ç›‘æ§æŒ‡æ ‡**ï¼š

- å˜æ›´æ£€æµ‹æ—¶é—´
- å¢é‡è½¬æ¢æ—¶é—´
- ä¾èµ–åˆ†ææ—¶é—´
- å†²çªå¤„ç†æ—¶é—´
- ç¼“å­˜å‘½ä¸­ç‡

### 8.3 æ•…éšœå¤„ç†

**æ•…éšœå¤„ç†**ï¼š

1. å˜æ›´æ£€æµ‹å¤±è´¥ï¼šå›é€€åˆ°å…¨é‡è½¬æ¢
2. ä¾èµ–åˆ†æå¤±è´¥ï¼šä½¿ç”¨ä¿å®ˆç­–ç•¥
3. å†²çªå¤„ç†å¤±è´¥ï¼šæ ‡è®°ä¸ºæ‰‹åŠ¨å¤„ç†

---

## 9. å¢é‡è½¬æ¢ç»¼åˆåº”ç”¨å®é™…ç¤ºä¾‹

**ç¤ºä¾‹ï¼šå®ç°å¢é‡Schemaè½¬æ¢ç»¼åˆæ¡†æ¶**

```python
import hashlib
import time
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Set, Tuple
from enum import Enum
from collections import defaultdict

class ChangeType(Enum):
    """å˜æ›´ç±»å‹"""
    ADD = "add"
    MODIFY = "modify"
    DELETE = "delete"

class ConflictResolution(Enum):
    """å†²çªè§£å†³ç­–ç•¥"""
    LAST_WRITE_WINS = "last_write_wins"
    FIRST_WRITE_WINS = "first_write_wins"
    MERGE = "merge"
    MANUAL = "manual"

@dataclass
class SchemaChange:
    """Schemaå˜æ›´"""
    path: str
    change_type: ChangeType
    old_value: Any = None
    new_value: Any = None
    timestamp: float = field(default_factory=time.time)

@dataclass
class DependencyNode:
    """ä¾èµ–èŠ‚ç‚¹"""
    schema_id: str
    dependencies: Set[str] = field(default_factory=set)
    dependents: Set[str] = field(default_factory=set)

@dataclass
class ConflictInfo:
    """å†²çªä¿¡æ¯"""
    path: str
    conflicting_changes: List[SchemaChange]
    resolution: Optional[str] = None

class IncrementalTransformationFramework:
    """å¢é‡è½¬æ¢ç»¼åˆæ¡†æ¶"""

    def __init__(self):
        # å˜æ›´æ£€æµ‹ï¼ˆåŸºäºç¬¬2ç« ï¼‰
        self.schema_hashes: Dict[str, str] = {}
        self.change_history: Dict[str, List[SchemaChange]] = defaultdict(list)

        # ä¾èµ–åˆ†æï¼ˆåŸºäºç¬¬4ç« ï¼‰
        self.dependency_graph: Dict[str, DependencyNode] = {}

        # ç¼“å­˜ï¼ˆåŸºäºç¬¬6ç« ï¼‰
        self.transform_cache: Dict[str, Dict] = {}
        self.cache_timestamps: Dict[str, float] = {}

        # å†²çªå¤„ç†ï¼ˆåŸºäºç¬¬5ç« ï¼‰
        self.conflicts: List[ConflictInfo] = []
        self.default_resolution = ConflictResolution.MERGE

    # ===== å˜æ›´æ£€æµ‹ï¼ˆåŸºäºç¬¬2ç« ï¼‰=====
    def compute_hash(self, schema: Dict) -> str:
        """è®¡ç®—Schemaå“ˆå¸Œï¼ˆåŸºäºç¬¬2.1ç« ï¼‰"""
        normalized = self._normalize_schema(schema)
        return hashlib.sha256(str(normalized).encode()).hexdigest()

    def detect_changes(self, schema_id: str, old_schema: Dict, new_schema: Dict) -> List[SchemaChange]:
        """æ£€æµ‹å˜æ›´ï¼ˆåŸºäºç¬¬2.2ç« ï¼‰"""
        changes = []
        self._diff_schemas(old_schema, new_schema, "", changes)

        # è®°å½•å˜æ›´å†å²
        self.change_history[schema_id].extend(changes)

        # æ›´æ–°å“ˆå¸Œ
        self.schema_hashes[schema_id] = self.compute_hash(new_schema)

        return changes

    def _diff_schemas(self, old: Any, new: Any, path: str, changes: List[SchemaChange]):
        """é€’å½’æ¯”è¾ƒSchema"""
        if old is None and new is not None:
            changes.append(SchemaChange(path=path, change_type=ChangeType.ADD, new_value=new))
        elif old is not None and new is None:
            changes.append(SchemaChange(path=path, change_type=ChangeType.DELETE, old_value=old))
        elif isinstance(old, dict) and isinstance(new, dict):
            all_keys = set(old.keys()) | set(new.keys())
            for key in all_keys:
                new_path = f"{path}.{key}" if path else key
                self._diff_schemas(old.get(key), new.get(key), new_path, changes)
        elif old != new:
            changes.append(SchemaChange(
                path=path, change_type=ChangeType.MODIFY,
                old_value=old, new_value=new
            ))

    def _normalize_schema(self, schema: Any) -> Any:
        """è§„èŒƒåŒ–Schemaç”¨äºå“ˆå¸Œè®¡ç®—"""
        if isinstance(schema, dict):
            return tuple(sorted((k, self._normalize_schema(v)) for k, v in schema.items()))
        elif isinstance(schema, list):
            return tuple(self._normalize_schema(item) for item in schema)
        return schema

    # ===== å¢é‡æ›´æ–°ï¼ˆåŸºäºç¬¬3ç« ï¼‰=====
    def incremental_transform(self, schema_id: str, changes: List[SchemaChange],
                               base_result: Dict, transformer: callable) -> Dict:
        """å¢é‡è½¬æ¢ï¼ˆåŸºäºç¬¬3.1ç« ï¼‰"""
        if not changes:
            return base_result

        result = base_result.copy()

        # åˆ†æå½±å“èŒƒå›´
        affected_paths = self._analyze_affected_paths(changes)

        # æŒ‰å˜æ›´ç±»å‹å¤„ç†
        for change in changes:
            if change.change_type == ChangeType.ADD:
                self._apply_add_change(result, change, transformer)
            elif change.change_type == ChangeType.MODIFY:
                self._apply_modify_change(result, change, transformer)
            elif change.change_type == ChangeType.DELETE:
                self._apply_delete_change(result, change)

        # æ›´æ–°ç¼“å­˜
        self.transform_cache[schema_id] = result
        self.cache_timestamps[schema_id] = time.time()

        return result

    def _analyze_affected_paths(self, changes: List[SchemaChange]) -> Set[str]:
        """åˆ†æå—å½±å“çš„è·¯å¾„"""
        affected = set()
        for change in changes:
            affected.add(change.path)
            # æ·»åŠ çˆ¶è·¯å¾„
            parts = change.path.split('.')
            for i in range(len(parts)):
                affected.add('.'.join(parts[:i+1]))
        return affected

    def _apply_add_change(self, result: Dict, change: SchemaChange, transformer: callable):
        """åº”ç”¨æ·»åŠ å˜æ›´"""
        path_parts = change.path.split('.') if change.path else []
        current = result

        for part in path_parts[:-1]:
            if part not in current:
                current[part] = {}
            current = current[part]

        if path_parts:
            transformed = transformer({path_parts[-1]: change.new_value})
            current[path_parts[-1]] = transformed.get(path_parts[-1], change.new_value)

    def _apply_modify_change(self, result: Dict, change: SchemaChange, transformer: callable):
        """åº”ç”¨ä¿®æ”¹å˜æ›´"""
        self._apply_add_change(result, change, transformer)

    def _apply_delete_change(self, result: Dict, change: SchemaChange):
        """åº”ç”¨åˆ é™¤å˜æ›´"""
        path_parts = change.path.split('.') if change.path else []
        current = result

        for part in path_parts[:-1]:
            if part not in current:
                return
            current = current[part]

        if path_parts and path_parts[-1] in current:
            del current[path_parts[-1]]

    # ===== ä¾èµ–åˆ†æï¼ˆåŸºäºç¬¬4ç« ï¼‰=====
    def build_dependency_graph(self, schemas: Dict[str, Dict]):
        """æ„å»ºä¾èµ–å›¾ï¼ˆåŸºäºç¬¬4.1ç« ï¼‰"""
        self.dependency_graph.clear()

        for schema_id, schema in schemas.items():
            node = DependencyNode(schema_id=schema_id)
            self.dependency_graph[schema_id] = node

        # åˆ†æä¾èµ–å…³ç³»
        for schema_id, schema in schemas.items():
            refs = self._extract_references(schema)
            for ref in refs:
                if ref in self.dependency_graph:
                    self.dependency_graph[schema_id].dependencies.add(ref)
                    self.dependency_graph[ref].dependents.add(schema_id)

    def _extract_references(self, schema: Any, refs: Set[str] = None) -> Set[str]:
        """æå–Schemaå¼•ç”¨"""
        if refs is None:
            refs = set()

        if isinstance(schema, dict):
            if '$ref' in schema:
                ref = schema['$ref']
                # æå–å¼•ç”¨çš„Schema ID
                if ref.startswith('#/components/schemas/'):
                    refs.add(ref.split('/')[-1])
            for value in schema.values():
                self._extract_references(value, refs)
        elif isinstance(schema, list):
            for item in schema:
                self._extract_references(item, refs)

        return refs

    def get_affected_schemas(self, schema_id: str) -> Set[str]:
        """è·å–å—å½±å“çš„Schemaï¼ˆåŸºäºç¬¬4.2ç« ï¼‰"""
        affected = set()
        self._propagate_dependencies(schema_id, affected)
        return affected

    def _propagate_dependencies(self, schema_id: str, affected: Set[str]):
        """ä¼ æ’­ä¾èµ–"""
        if schema_id in affected:
            return

        affected.add(schema_id)

        if schema_id in self.dependency_graph:
            for dependent in self.dependency_graph[schema_id].dependents:
                self._propagate_dependencies(dependent, affected)

    def get_transform_order(self) -> List[str]:
        """è·å–è½¬æ¢é¡ºåºï¼ˆæ‹“æ‰‘æ’åºï¼‰"""
        visited = set()
        order = []

        def visit(node_id: str):
            if node_id in visited:
                return
            visited.add(node_id)

            if node_id in self.dependency_graph:
                for dep in self.dependency_graph[node_id].dependencies:
                    visit(dep)

            order.append(node_id)

        for node_id in self.dependency_graph:
            visit(node_id)

        return order

    # ===== å†²çªå¤„ç†ï¼ˆåŸºäºç¬¬5ç« ï¼‰=====
    def detect_conflicts(self, changes1: List[SchemaChange],
                          changes2: List[SchemaChange]) -> List[ConflictInfo]:
        """æ£€æµ‹å†²çªï¼ˆåŸºäºç¬¬5.1ç« ï¼‰"""
        conflicts = []

        # æŒ‰è·¯å¾„åˆ†ç»„
        changes1_by_path = {c.path: c for c in changes1}
        changes2_by_path = {c.path: c for c in changes2}

        # æ£€æµ‹åŒä¸€è·¯å¾„çš„å†²çª
        common_paths = set(changes1_by_path.keys()) & set(changes2_by_path.keys())

        for path in common_paths:
            c1 = changes1_by_path[path]
            c2 = changes2_by_path[path]

            if c1.new_value != c2.new_value:
                conflicts.append(ConflictInfo(
                    path=path,
                    conflicting_changes=[c1, c2]
                ))

        self.conflicts.extend(conflicts)
        return conflicts

    def resolve_conflict(self, conflict: ConflictInfo,
                          strategy: ConflictResolution = None) -> SchemaChange:
        """è§£å†³å†²çªï¼ˆåŸºäºç¬¬5.2ç« ï¼‰"""
        strategy = strategy or self.default_resolution
        changes = conflict.conflicting_changes

        if strategy == ConflictResolution.LAST_WRITE_WINS:
            # æœ€åå†™å…¥èƒœå‡º
            latest = max(changes, key=lambda c: c.timestamp)
            conflict.resolution = f"last_write_wins: {latest.timestamp}"
            return latest

        elif strategy == ConflictResolution.FIRST_WRITE_WINS:
            # æœ€å…ˆå†™å…¥èƒœå‡º
            earliest = min(changes, key=lambda c: c.timestamp)
            conflict.resolution = f"first_write_wins: {earliest.timestamp}"
            return earliest

        elif strategy == ConflictResolution.MERGE:
            # åˆå¹¶ç­–ç•¥
            merged = self._merge_changes(changes)
            conflict.resolution = "merged"
            return merged

        else:
            # æ‰‹åŠ¨å¤„ç†
            conflict.resolution = "manual"
            return changes[0]

    def _merge_changes(self, changes: List[SchemaChange]) -> SchemaChange:
        """åˆå¹¶å˜æ›´"""
        # ç®€å•åˆå¹¶ï¼šä½¿ç”¨æœ€æ–°çš„éç©ºå€¼
        latest = max(changes, key=lambda c: c.timestamp)

        if all(isinstance(c.new_value, dict) for c in changes if c.new_value):
            merged_value = {}
            for change in sorted(changes, key=lambda c: c.timestamp):
                if isinstance(change.new_value, dict):
                    merged_value.update(change.new_value)
            return SchemaChange(
                path=latest.path,
                change_type=ChangeType.MODIFY,
                new_value=merged_value
            )

        return latest

    # ===== æ€§èƒ½ä¼˜åŒ–ï¼ˆåŸºäºç¬¬6ç« ï¼‰=====
    def get_cached_result(self, schema_id: str) -> Optional[Dict]:
        """è·å–ç¼“å­˜ç»“æœï¼ˆåŸºäºç¬¬6.1ç« ï¼‰"""
        if schema_id in self.transform_cache:
            return self.transform_cache[schema_id]
        return None

    def invalidate_cache(self, schema_id: str):
        """å¤±æ•ˆç¼“å­˜"""
        if schema_id in self.transform_cache:
            del self.transform_cache[schema_id]
            del self.cache_timestamps[schema_id]

        # çº§è”å¤±æ•ˆä¾èµ–çš„Schema
        affected = self.get_affected_schemas(schema_id)
        for affected_id in affected:
            if affected_id in self.transform_cache:
                del self.transform_cache[affected_id]

    def get_transformation_stats(self) -> Dict:
        """è·å–è½¬æ¢ç»Ÿè®¡"""
        return {
            'total_schemas': len(self.dependency_graph),
            'cached_results': len(self.transform_cache),
            'total_changes': sum(len(changes) for changes in self.change_history.values()),
            'unresolved_conflicts': len([c for c in self.conflicts if not c.resolution]),
            'dependency_stats': {
                'max_depth': self._calculate_max_depth(),
                'avg_dependencies': self._calculate_avg_dependencies()
            }
        }

    def _calculate_max_depth(self) -> int:
        """è®¡ç®—æœ€å¤§ä¾èµ–æ·±åº¦"""
        def depth(node_id: str, visited: Set[str]) -> int:
            if node_id in visited or node_id not in self.dependency_graph:
                return 0
            visited.add(node_id)
            deps = self.dependency_graph[node_id].dependencies
            if not deps:
                return 1
            return 1 + max(depth(d, visited) for d in deps)

        if not self.dependency_graph:
            return 0
        return max(depth(n, set()) for n in self.dependency_graph)

    def _calculate_avg_dependencies(self) -> float:
        """è®¡ç®—å¹³å‡ä¾èµ–æ•°"""
        if not self.dependency_graph:
            return 0
        total_deps = sum(len(n.dependencies) for n in self.dependency_graph.values())
        return total_deps / len(self.dependency_graph)

# å®é™…åº”ç”¨ç¤ºä¾‹
framework = IncrementalTransformationFramework()

# ç¤ºä¾‹1ï¼šå˜æ›´æ£€æµ‹
print("=== ç¤ºä¾‹1ï¼šå˜æ›´æ£€æµ‹ ===")
old_schema = {
    'type': 'object',
    'properties': {
        'name': {'type': 'string'},
        'age': {'type': 'integer'}
    }
}
new_schema = {
    'type': 'object',
    'properties': {
        'name': {'type': 'string', 'maxLength': 100},
        'email': {'type': 'string'}
    }
}
changes = framework.detect_changes('user_schema', old_schema, new_schema)
print(f"æ£€æµ‹åˆ° {len(changes)} ä¸ªå˜æ›´:")
for change in changes:
    print(f"  [{change.change_type.value}] {change.path}")

# ç¤ºä¾‹2ï¼šä¾èµ–åˆ†æ
print("\n=== ç¤ºä¾‹2ï¼šä¾èµ–åˆ†æ ===")
schemas = {
    'User': {'type': 'object', 'properties': {}},
    'Order': {
        'type': 'object',
        'properties': {
            'user': {'$ref': '#/components/schemas/User'}
        }
    },
    'Invoice': {
        'type': 'object',
        'properties': {
            'order': {'$ref': '#/components/schemas/Order'}
        }
    }
}
framework.build_dependency_graph(schemas)
print(f"è½¬æ¢é¡ºåº: {framework.get_transform_order()}")

affected = framework.get_affected_schemas('User')
print(f"Userå˜æ›´å½±å“: {affected}")

# ç¤ºä¾‹3ï¼šå†²çªæ£€æµ‹ä¸è§£å†³
print("\n=== ç¤ºä¾‹3ï¼šå†²çªæ£€æµ‹ä¸è§£å†³ ===")
changes1 = [SchemaChange(path='properties.name', change_type=ChangeType.MODIFY,
                          new_value={'type': 'string', 'maxLength': 50})]
changes2 = [SchemaChange(path='properties.name', change_type=ChangeType.MODIFY,
                          new_value={'type': 'string', 'maxLength': 100})]
conflicts = framework.detect_conflicts(changes1, changes2)
print(f"æ£€æµ‹åˆ° {len(conflicts)} ä¸ªå†²çª")
if conflicts:
    resolved = framework.resolve_conflict(conflicts[0], ConflictResolution.MERGE)
    print(f"è§£å†³æ–¹æ¡ˆ: {resolved.new_value}")

# ç¤ºä¾‹4ï¼šç»Ÿè®¡ä¿¡æ¯
print("\n=== è½¬æ¢ç»Ÿè®¡ ===")
stats = framework.get_transformation_stats()
for key, value in stats.items():
    print(f"  {key}: {value}")
```

---

## 10. å‚è€ƒæ–‡æ¡£

### ç®—æ³•æ–‡æ¡£

- `analysis/12_Incremental_Transformation_Algorithm.md` - å¢é‡è½¬æ¢ç®—æ³•åˆ†æ
- `src/transformers/incremental/` - å¢é‡è½¬æ¢ä»£ç å®ç°

### æ¨¡å¼æ–‡æ¡£ â­æ–°å¢

- `docs/structure/INFORMATION_PROCESSING_PATTERNS_SUMMARY.md`ï¼šä¿¡æ¯å¤„ç†æ¨¡å¼æ€»ç»“ï¼ˆ12ä¸ªæ¨¡å¼ï¼‰
  - åœ¨å¢é‡è½¬æ¢ä¸­ï¼Œå¯ä»¥å‚è€ƒæµå¤„ç†æ¨¡å¼ã€å®æ—¶å¤„ç†æ¨¡å¼ã€æ‰¹å¤„ç†æ¨¡å¼ç­‰
- `docs/structure/ARCHITECTURE_PATTERNS_SUMMARY.md`ï¼šæ¶æ„æ¨¡å¼æ€»ç»“ï¼ˆ12ä¸ªæ¨¡å¼ï¼‰
  - åœ¨å¢é‡è½¬æ¢ç³»ç»Ÿæ¶æ„è®¾è®¡ä¸­ï¼Œå¯ä»¥å‚è€ƒäº‹ä»¶é©±åŠ¨æ¶æ„ã€å¾®æœåŠ¡æ¶æ„ç­‰
- `docs/structure/DESIGN_PATTERNS_SUMMARY.md`ï¼šè®¾è®¡æ¨¡å¼æ€»ç»“ï¼ˆ15ä¸ªæ¨¡å¼ï¼‰
  - åœ¨å¢é‡è½¬æ¢å®ç°ä¸­ï¼Œå¯ä»¥å‚è€ƒè§‚å¯Ÿè€…æ¨¡å¼ã€ç­–ç•¥æ¨¡å¼ã€çŠ¶æ€æ¨¡å¼ç­‰
- `docs/structure/PATTERNS_QUICK_REFERENCE.md`ï¼šæ¨¡å¼å¿«é€Ÿå‚è€ƒæŒ‡å— â­æ¨è

---

## ğŸ“ ç‰ˆæœ¬å†å²

### v1.2 (2025-01-21) - å®é™…åº”ç”¨ç¤ºä¾‹å¢å¼ºç‰ˆ

- âœ… æ‰©å±•ç¬¬9ç« ï¼šä¸ºå¢é‡è½¬æ¢æ·»åŠ ç»¼åˆåº”ç”¨å®é™…ç¤ºä¾‹ï¼ˆåŒ…å«å¢é‡è½¬æ¢ç»¼åˆæ¡†æ¶å®ç°ã€å˜æ›´æ£€æµ‹ã€ä¾èµ–å›¾æ„å»ºã€ä¾èµ–ä¼ æ’­ã€å†²çªæ£€æµ‹ã€å†²çªè§£å†³ã€ç¼“å­˜ç®¡ç†ã€ç»Ÿè®¡åˆ†æï¼‰
- âœ… æ·»åŠ ç‰ˆæœ¬å†å²ç« èŠ‚
- âœ… æ›´æ–°æ–‡æ¡£ç‰ˆæœ¬å·è‡³v1.2

### v1.1 (2025-01-27) - åˆå§‹ç‰ˆæœ¬

- âœ… åˆ›å»ºæ–‡æ¡£ï¼šå¢é‡è½¬æ¢å®æ–½æŒ‡å—
- âœ… æ·»åŠ å˜æ›´æ£€æµ‹å®ç°
- âœ… æ·»åŠ å¢é‡æ›´æ–°å®ç°
- âœ… æ·»åŠ ä¾èµ–åˆ†æå®ç°
- âœ… æ·»åŠ å†²çªå¤„ç†å®ç°
- âœ… æ·»åŠ æ€§èƒ½ä¼˜åŒ–å®ç°
- âœ… æ·»åŠ æµ‹è¯•ä¸éªŒè¯
- âœ… æ·»åŠ éƒ¨ç½²ä¸è¿ç»´

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼š1.2ï¼ˆå®é™…åº”ç”¨ç¤ºä¾‹å¢å¼ºç‰ˆï¼‰
**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
