# MCPåè®®æ€§èƒ½ä¼˜åŒ–å®æ–½æŒ‡å—

## ğŸ“‘ ç›®å½•

- [MCPåè®®æ€§èƒ½ä¼˜åŒ–å®æ–½æŒ‡å—](#mcpåè®®æ€§èƒ½ä¼˜åŒ–å®æ–½æŒ‡å—)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. å®æ–½æ¦‚è¿°](#1-å®æ–½æ¦‚è¿°)
    - [1.1 ä¼˜åŒ–ç›®æ ‡](#11-ä¼˜åŒ–ç›®æ ‡)
    - [1.2 å®æ–½æ­¥éª¤](#12-å®æ–½æ­¥éª¤)
  - [2. è¿æ¥æ± ä¼˜åŒ–å®æ–½](#2-è¿æ¥æ± ä¼˜åŒ–å®æ–½)
    - [2.1 è¿æ¥æ± ç®¡ç†å™¨å®ç°](#21-è¿æ¥æ± ç®¡ç†å™¨å®ç°)
    - [2.2 è¿æ¥å¤ç”¨æœºåˆ¶](#22-è¿æ¥å¤ç”¨æœºåˆ¶)
    - [2.3 è¿æ¥é¢„çƒ­ç­–ç•¥](#23-è¿æ¥é¢„çƒ­ç­–ç•¥)
  - [3. è¯·æ±‚æ‰¹å¤„ç†å®æ–½](#3-è¯·æ±‚æ‰¹å¤„ç†å®æ–½)
    - [3.1 æ‰¹å¤„ç†è°ƒåº¦å™¨å®ç°](#31-æ‰¹å¤„ç†è°ƒåº¦å™¨å®ç°)
    - [3.2 æ‰¹é‡è½¬æ¢å¼•æ“](#32-æ‰¹é‡è½¬æ¢å¼•æ“)
    - [3.3 ç»“æœåˆ†å‘æœºåˆ¶](#33-ç»“æœåˆ†å‘æœºåˆ¶)
  - [4. ç¼“å­˜ç­–ç•¥å®æ–½](#4-ç¼“å­˜ç­–ç•¥å®æ–½)
    - [4.1 å¤šçº§ç¼“å­˜æ¶æ„](#41-å¤šçº§ç¼“å­˜æ¶æ„)
    - [4.2 ç¼“å­˜ç­–ç•¥å®ç°](#42-ç¼“å­˜ç­–ç•¥å®ç°)
    - [4.3 ç¼“å­˜å¤±æ•ˆæœºåˆ¶](#43-ç¼“å­˜å¤±æ•ˆæœºåˆ¶)
  - [5. å¼‚æ­¥å¤„ç†å®æ–½](#5-å¼‚æ­¥å¤„ç†å®æ–½)
    - [5.1 å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—](#51-å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—)
    - [5.2 å·¥ä½œçº¿ç¨‹æ± ](#52-å·¥ä½œçº¿ç¨‹æ± )
    - [5.3 ä»»åŠ¡è°ƒåº¦å™¨](#53-ä»»åŠ¡è°ƒåº¦å™¨)
  - [6. æ€§èƒ½ç›‘æ§å®æ–½](#6-æ€§èƒ½ç›‘æ§å®æ–½)
    - [6.1 ç›‘æ§æŒ‡æ ‡æ”¶é›†](#61-ç›‘æ§æŒ‡æ ‡æ”¶é›†)
    - [6.2 æ€§èƒ½åˆ†æå·¥å…·](#62-æ€§èƒ½åˆ†æå·¥å…·)
    - [6.3 å‘Šè­¦æœºåˆ¶](#63-å‘Šè­¦æœºåˆ¶)
  - [7. æµ‹è¯•ä¸éªŒè¯](#7-æµ‹è¯•ä¸éªŒè¯)
    - [7.1 å•å…ƒæµ‹è¯•](#71-å•å…ƒæµ‹è¯•)
    - [7.2 æ€§èƒ½æµ‹è¯•](#72-æ€§èƒ½æµ‹è¯•)
    - [7.3 å‹åŠ›æµ‹è¯•](#73-å‹åŠ›æµ‹è¯•)
  - [8. éƒ¨ç½²ä¸è¿ç»´](#8-éƒ¨ç½²ä¸è¿ç»´)
    - [8.1 éƒ¨ç½²é…ç½®](#81-éƒ¨ç½²é…ç½®)
    - [8.2 è¿ç»´ç›‘æ§](#82-è¿ç»´ç›‘æ§)
    - [8.3 æ•…éšœå¤„ç†](#83-æ•…éšœå¤„ç†)
  - [9. MCPæ€§èƒ½ä¼˜åŒ–ç»¼åˆåº”ç”¨å®é™…ç¤ºä¾‹](#9-mcpæ€§èƒ½ä¼˜åŒ–ç»¼åˆåº”ç”¨å®é™…ç¤ºä¾‹)
  - [10. å‚è€ƒæ–‡æ¡£](#10-å‚è€ƒæ–‡æ¡£)
    - [æ€§èƒ½ä¼˜åŒ–æ–‡æ¡£](#æ€§èƒ½ä¼˜åŒ–æ–‡æ¡£)
    - [æ¨¡å¼æ–‡æ¡£ â­æ–°å¢](#æ¨¡å¼æ–‡æ¡£-æ–°å¢)
  - [ğŸ“ ç‰ˆæœ¬å†å²](#-ç‰ˆæœ¬å†å²)
    - [v1.2 (2025-01-21) - å®é™…åº”ç”¨ç¤ºä¾‹å¢å¼ºç‰ˆ](#v12-2025-01-21---å®é™…åº”ç”¨ç¤ºä¾‹å¢å¼ºç‰ˆ)
    - [v1.1 (2025-01-27) - åˆå§‹ç‰ˆæœ¬](#v11-2025-01-27---åˆå§‹ç‰ˆæœ¬)

---

## 1. å®æ–½æ¦‚è¿°

### 1.1 ä¼˜åŒ–ç›®æ ‡

**æ€§èƒ½ä¼˜åŒ–ç›®æ ‡**ï¼š

1. **è¿æ¥æ± æ€§èƒ½**ï¼šæå‡50%ä»¥ä¸Š
2. **è¯·æ±‚å»¶è¿Ÿ**ï¼šå‡å°‘30%ä»¥ä¸Š
3. **ç¼“å­˜å‘½ä¸­ç‡**ï¼šè¾¾åˆ°80%ä»¥ä¸Š
4. **ååé‡**ï¼šæå‡100%ä»¥ä¸Š

### 1.2 å®æ–½æ­¥éª¤

**å®æ–½é˜¶æ®µ**ï¼š

1. **é˜¶æ®µ1**ï¼šè¿æ¥æ± ä¼˜åŒ–ï¼ˆWeek 1ï¼‰
2. **é˜¶æ®µ2**ï¼šè¯·æ±‚æ‰¹å¤„ç†ï¼ˆWeek 1-2ï¼‰
3. **é˜¶æ®µ3**ï¼šç¼“å­˜ç­–ç•¥ï¼ˆWeek 2ï¼‰
4. **é˜¶æ®µ4**ï¼šå¼‚æ­¥å¤„ç†ï¼ˆWeek 2-3ï¼‰
5. **é˜¶æ®µ5**ï¼šæ€§èƒ½ç›‘æ§ï¼ˆWeek 3ï¼‰
6. **é˜¶æ®µ6**ï¼šæµ‹è¯•éªŒè¯ï¼ˆWeek 3-4ï¼‰

---

## 2. è¿æ¥æ± ä¼˜åŒ–å®æ–½

### 2.1 è¿æ¥æ± ç®¡ç†å™¨å®ç°

**å®ç°ä»£ç **ï¼š

```typescript
// src/server/performance/connection-pool.ts
import { EventEmitter } from 'events';

interface Connection {
  id: string;
  createdAt: Date;
  lastUsedAt: Date;
  isActive: boolean;
  resource: any;
}

export class ConnectionPool extends EventEmitter {
  private pool: Map<string, Connection> = new Map();
  private maxSize: number;
  private minSize: number;
  private idleTimeout: number;
  private maxIdleTime: number;

  constructor(config: {
    maxSize?: number;
    minSize?: number;
    idleTimeout?: number;
    maxIdleTime?: number;
  }) {
    super();
    this.maxSize = config.maxSize || 20;
    this.minSize = config.minSize || 5;
    this.idleTimeout = config.idleTimeout || 30000; // 30s
    this.maxIdleTime = config.maxIdleTime || 300000; // 5min

    this.startIdleCleanup();
  }

  async acquire(): Promise<Connection> {
    // å°è¯•å¤ç”¨ç°æœ‰è¿æ¥
    const idleConnection = this.findIdleConnection();
    if (idleConnection) {
      idleConnection.lastUsedAt = new Date();
      idleConnection.isActive = true;
      return idleConnection;
    }

    // æ£€æŸ¥æ± å¤§å°é™åˆ¶
    if (this.pool.size >= this.maxSize) {
      throw new Error('Connection pool exhausted');
    }

    // åˆ›å»ºæ–°è¿æ¥
    const connection = await this.createConnection();
    this.pool.set(connection.id, connection);

    return connection;
  }

  release(connection: Connection): void {
    connection.isActive = false;
    connection.lastUsedAt = new Date();
    this.emit('connection-released', connection);
  }

  private findIdleConnection(): Connection | null {
    for (const conn of this.pool.values()) {
      if (!conn.isActive) {
        const idleTime = Date.now() - conn.lastUsedAt.getTime();
        if (idleTime < this.maxIdleTime) {
          return conn;
        }
      }
    }
    return null;
  }

  private async createConnection(): Promise<Connection> {
    // åˆ›å»ºæ–°è¿æ¥çš„é€»è¾‘
    const connection: Connection = {
      id: `conn-${Date.now()}-${Math.random()}`,
      createdAt: new Date(),
      lastUsedAt: new Date(),
      isActive: true,
      resource: await this.initializeResource(),
    };

    return connection;
  }

  private async initializeResource(): Promise<any> {
    // åˆå§‹åŒ–è¿æ¥èµ„æºçš„é€»è¾‘
    // ä¾‹å¦‚ï¼šæ•°æ®åº“è¿æ¥ã€HTTPè¿æ¥ç­‰
    return {};
  }

  private startIdleCleanup(): void {
    setInterval(() => {
      this.cleanupIdleConnections();
    }, this.idleTimeout);
  }

  private cleanupIdleConnections(): void {
    const now = Date.now();
    const toRemove: string[] = [];

    for (const [id, conn] of this.pool.entries()) {
      if (!conn.isActive) {
        const idleTime = now - conn.lastUsedAt.getTime();
        if (idleTime > this.maxIdleTime && this.pool.size > this.minSize) {
          toRemove.push(id);
        }
      }
    }

    toRemove.forEach(id => {
      const conn = this.pool.get(id);
      if (conn) {
        this.destroyConnection(conn);
        this.pool.delete(id);
      }
    });
  }

  private destroyConnection(connection: Connection): void {
    // é”€æ¯è¿æ¥çš„é€»è¾‘
    if (connection.resource && connection.resource.close) {
      connection.resource.close();
    }
  }

  async warmup(): Promise<void> {
    // é¢„çƒ­è¿æ¥æ± 
    const promises: Promise<Connection>[] = [];
    for (let i = 0; i < this.minSize; i++) {
      promises.push(this.acquire());
    }
    await Promise.all(promises);
  }

  getStats() {
    return {
      total: this.pool.size,
      active: Array.from(this.pool.values()).filter(c => c.isActive).length,
      idle: Array.from(this.pool.values()).filter(c => !c.isActive).length,
    };
  }
}
```

### 2.2 è¿æ¥å¤ç”¨æœºåˆ¶

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```typescript
// ä½¿ç”¨è¿æ¥æ± 
const pool = new ConnectionPool({
  maxSize: 20,
  minSize: 5,
  idleTimeout: 30000,
  maxIdleTime: 300000,
});

// é¢„çƒ­è¿æ¥æ± 
await pool.warmup();

// è·å–è¿æ¥
const connection = await pool.acquire();
try {
  // ä½¿ç”¨è¿æ¥
  await useConnection(connection);
} finally {
  // é‡Šæ”¾è¿æ¥
  pool.release(connection);
}
```

### 2.3 è¿æ¥é¢„çƒ­ç­–ç•¥

**é¢„çƒ­ç­–ç•¥**ï¼š

1. **å¯åŠ¨æ—¶é¢„çƒ­**ï¼šæœåŠ¡å¯åŠ¨æ—¶é¢„åˆ›å»ºæœ€å°è¿æ¥æ•°
2. **æŒ‰éœ€é¢„çƒ­**ï¼šæ ¹æ®è´Ÿè½½åŠ¨æ€é¢„çƒ­
3. **å¥åº·æ£€æŸ¥**ï¼šå®šæœŸæ£€æŸ¥è¿æ¥å¥åº·çŠ¶æ€

---

## 3. è¯·æ±‚æ‰¹å¤„ç†å®æ–½

### 3.1 æ‰¹å¤„ç†è°ƒåº¦å™¨å®ç°

**å®ç°ä»£ç **ï¼š

```typescript
// src/server/performance/batch-processor.ts
interface BatchRequest {
  id: string;
  request: any;
  resolve: (result: any) => void;
  reject: (error: Error) => void;
  timestamp: number;
}

export class BatchProcessor {
  private queue: BatchRequest[] = [];
  private batchSize: number;
  private batchWindow: number;
  private timer: NodeJS.Timeout | null = null;
  private processing: boolean = false;

  constructor(config: {
    batchSize?: number;
    batchWindow?: number;
  }) {
    this.batchSize = config.batchSize || 10;
    this.batchWindow = config.batchWindow || 100; // 100ms
  }

  async addRequest(request: any): Promise<any> {
    return new Promise((resolve, reject) => {
      const batchRequest: BatchRequest = {
        id: `req-${Date.now()}-${Math.random()}`,
        request,
        resolve,
        reject,
        timestamp: Date.now(),
      };

      this.queue.push(batchRequest);

      // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ‰¹å¤„ç†å¤§å°
      if (this.queue.length >= this.batchSize) {
        this.processBatch();
      } else if (!this.timer && !this.processing) {
        // å¯åŠ¨æ—¶é—´çª—å£å®šæ—¶å™¨
        this.timer = setTimeout(() => {
          this.processBatch();
        }, this.batchWindow);
      }
    });
  }

  private async processBatch(): Promise<void> {
    if (this.processing || this.queue.length === 0) {
      return;
    }

    this.processing = true;

    if (this.timer) {
      clearTimeout(this.timer);
      this.timer = null;
    }

    // å–å‡ºæ‰¹å¤„ç†è¯·æ±‚
    const batch = this.queue.splice(0, this.batchSize);

    try {
      // æ‰¹é‡å¤„ç†è¯·æ±‚
      const results = await this.processBatchRequests(batch);

      // åˆ†å‘ç»“æœ
      batch.forEach((item, index) => {
        item.resolve(results[index]);
      });
    } catch (error) {
      // å¤„ç†é”™è¯¯
      batch.forEach((item) => {
        item.reject(error instanceof Error ? error : new Error(String(error)));
      });
    } finally {
      this.processing = false;

      // å¦‚æœè¿˜æœ‰å¾…å¤„ç†è¯·æ±‚ï¼Œç»§ç»­å¤„ç†
      if (this.queue.length > 0) {
        if (this.queue.length >= this.batchSize) {
          this.processBatch();
        } else {
          this.timer = setTimeout(() => {
            this.processBatch();
          }, this.batchWindow);
        }
      }
    }
  }

  private async processBatchRequests(
    batch: BatchRequest[]
  ): Promise<any[]> {
    // æ‰¹é‡è½¬æ¢è¯·æ±‚
    const requests = batch.map(item => item.request);
    const results = await this.batchTransform(requests);
    return results;
  }

  private async batchTransform(requests: any[]): Promise<any[]> {
    // å®ç°æ‰¹é‡è½¬æ¢é€»è¾‘
    // ä¾‹å¦‚ï¼šæ‰¹é‡æ•°æ®åº“æŸ¥è¯¢ã€æ‰¹é‡APIè°ƒç”¨ç­‰
    return Promise.all(requests.map(req => this.transform(req)));
  }

  private async transform(request: any): Promise<any> {
    // å•ä¸ªè½¬æ¢é€»è¾‘
    return request;
  }

  getStats() {
    return {
      queueLength: this.queue.length,
      processing: this.processing,
    };
  }
}
```

### 3.2 æ‰¹é‡è½¬æ¢å¼•æ“

**æ‰¹é‡è½¬æ¢ä¼˜åŒ–**ï¼š

```typescript
// æ‰¹é‡è½¬æ¢ç¤ºä¾‹
async function batchTransformSchemas(
  schemas: Schema[]
): Promise<TransformedSchema[]> {
  // å¹¶è¡Œå¤„ç†å¤šä¸ªSchema
  const results = await Promise.all(
    schemas.map(schema => transformSchema(schema))
  );
  return results;
}
```

### 3.3 ç»“æœåˆ†å‘æœºåˆ¶

**ç»“æœåˆ†å‘**ï¼š

- ä½¿ç”¨Promiseæœºåˆ¶åˆ†å‘ç»“æœ
- é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- ç»“æœç¼“å­˜å’Œå¤ç”¨

---

## 4. ç¼“å­˜ç­–ç•¥å®æ–½

### 4.1 å¤šçº§ç¼“å­˜æ¶æ„

**å®ç°ä»£ç **ï¼š

```typescript
// src/server/performance/multi-level-cache.ts
interface CacheEntry<T> {
  key: string;
  value: T;
  timestamp: number;
  ttl: number;
  accessCount: number;
  lastAccess: number;
}

export class MultiLevelCache<T> {
  private l1Cache: Map<string, CacheEntry<T>> = new Map(); // å†…å­˜ç¼“å­˜
  private l2Cache: any; // Redisç¼“å­˜ï¼ˆå¯é€‰ï¼‰
  private maxL1Size: number;
  private defaultTTL: number;

  constructor(config: {
    maxL1Size?: number;
    defaultTTL?: number;
    l2Cache?: any;
  }) {
    this.maxL1Size = config.maxL1Size || 1000;
    this.defaultTTL = config.defaultTTL || 3600000; // 1å°æ—¶
    this.l2Cache = config.l2Cache;
  }

  async get(key: string): Promise<T | null> {
    // L1ç¼“å­˜æŸ¥æ‰¾
    const l1Entry = this.l1Cache.get(key);
    if (l1Entry && !this.isExpired(l1Entry)) {
      l1Entry.accessCount++;
      l1Entry.lastAccess = Date.now();
      return l1Entry.value;
    }

    // L2ç¼“å­˜æŸ¥æ‰¾
    if (this.l2Cache) {
      const l2Value = await this.l2Cache.get(key);
      if (l2Value) {
        // æå‡åˆ°L1ç¼“å­˜
        await this.set(key, l2Value);
        return l2Value;
      }
    }

    return null;
  }

  async set(key: string, value: T, ttl?: number): Promise<void> {
    const entry: CacheEntry<T> = {
      key,
      value,
      timestamp: Date.now(),
      ttl: ttl || this.defaultTTL,
      accessCount: 1,
      lastAccess: Date.now(),
    };

    // è®¾ç½®L1ç¼“å­˜
    if (this.l1Cache.size >= this.maxL1Size) {
      this.evictLRU();
    }
    this.l1Cache.set(key, entry);

    // è®¾ç½®L2ç¼“å­˜
    if (this.l2Cache) {
      await this.l2Cache.set(key, value, ttl);
    }
  }

  private isExpired(entry: CacheEntry<T>): boolean {
    return Date.now() - entry.timestamp > entry.ttl;
  }

  private evictLRU(): void {
    // LRUæ·˜æ±°ç­–ç•¥
    let lruKey: string | null = null;
    let lruTime = Infinity;

    for (const [key, entry] of this.l1Cache.entries()) {
      if (entry.lastAccess < lruTime) {
        lruTime = entry.lastAccess;
        lruKey = key;
      }
    }

    if (lruKey) {
      this.l1Cache.delete(lruKey);
    }
  }

  invalidate(key: string): void {
    this.l1Cache.delete(key);
    if (this.l2Cache) {
      this.l2Cache.delete(key);
    }
  }

  clear(): void {
    this.l1Cache.clear();
    if (this.l2Cache) {
      this.l2Cache.clear();
    }
  }

  getStats() {
    return {
      l1Size: this.l1Cache.size,
      l1HitRate: this.calculateHitRate(),
    };
  }

  private calculateHitRate(): number {
    // è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡
    return 0; // éœ€è¦å®ç°ç»Ÿè®¡é€»è¾‘
  }
}
```

### 4.2 ç¼“å­˜ç­–ç•¥å®ç°

**ç¼“å­˜ç­–ç•¥é€‰æ‹©**ï¼š

```typescript
// æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©ç¼“å­˜ç­–ç•¥
function selectCacheStrategy(dataType: string): CacheStrategy {
  switch (dataType) {
    case 'hot-data':
      return 'LRU';
    case 'frequent-data':
      return 'LFU';
    case 'time-sensitive':
      return 'TTL';
    default:
      return 'LRU';
  }
}
```

### 4.3 ç¼“å­˜å¤±æ•ˆæœºåˆ¶

**æ™ºèƒ½å¤±æ•ˆ**ï¼š

```typescript
// åŸºäºå˜æ›´æ£€æµ‹çš„ç¼“å­˜å¤±æ•ˆ
class SmartCacheInvalidation {
  async invalidateOnChange(
    schemaId: string,
    changeType: 'update' | 'delete'
  ): Promise<void> {
    // å¤±æ•ˆç›´æ¥ç¼“å­˜
    cache.invalidate(schemaId);

    // å¤±æ•ˆä¾èµ–ç¼“å­˜
    const dependencies = await this.getDependencies(schemaId);
    dependencies.forEach(dep => {
      cache.invalidate(dep);
    });
  }
}
```

---

## 5. å¼‚æ­¥å¤„ç†å®æ–½

### 5.1 å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—

**ä»»åŠ¡é˜Ÿåˆ—å®ç°**ï¼š

```typescript
// src/server/performance/async-queue.ts
interface Task {
  id: string;
  priority: number;
  handler: () => Promise<any>;
  resolve: (result: any) => void;
  reject: (error: Error) => void;
}

export class AsyncTaskQueue {
  private queue: Task[] = [];
  private workers: Worker[] = [];
  private maxWorkers: number;
  private processing: boolean = false;

  constructor(maxWorkers: number = 5) {
    this.maxWorkers = maxWorkers;
  }

  async enqueue(
    handler: () => Promise<any>,
    priority: number = 0
  ): Promise<any> {
    return new Promise((resolve, reject) => {
      const task: Task = {
        id: `task-${Date.now()}-${Math.random()}`,
        priority,
        handler,
        resolve,
        reject,
      };

      this.queue.push(task);
      this.queue.sort((a, b) => b.priority - a.priority);

      this.processQueue();
    });
  }

  private async processQueue(): Promise<void> {
    if (this.processing || this.queue.length === 0) {
      return;
    }

    if (this.workers.length >= this.maxWorkers) {
      return;
    }

    this.processing = true;
    const task = this.queue.shift();

    if (!task) {
      this.processing = false;
      return;
    }

    const worker = this.createWorker(task);
    this.workers.push(worker);

    worker.promise.finally(() => {
      const index = this.workers.indexOf(worker);
      if (index > -1) {
        this.workers.splice(index, 1);
      }
      this.processing = false;
      this.processQueue();
    });
  }

  private createWorker(task: Task): Worker {
    const promise = task.handler()
      .then(result => {
        task.resolve(result);
        return result;
      })
      .catch(error => {
        task.reject(error);
        throw error;
      });

    return { task, promise };
  }
}

interface Worker {
  task: Task;
  promise: Promise<any>;
}
```

### 5.2 å·¥ä½œçº¿ç¨‹æ± 

**çº¿ç¨‹æ± ç®¡ç†**ï¼š

- åŠ¨æ€è°ƒæ•´å·¥ä½œçº¿ç¨‹æ•°
- è´Ÿè½½å‡è¡¡
- ä»»åŠ¡ä¼˜å…ˆçº§è°ƒåº¦

### 5.3 ä»»åŠ¡è°ƒåº¦å™¨

**è°ƒåº¦ç­–ç•¥**ï¼š

- ä¼˜å…ˆçº§è°ƒåº¦
- å…¬å¹³è°ƒåº¦
- è´Ÿè½½å‡è¡¡

---

## 6. æ€§èƒ½ç›‘æ§å®æ–½

### 6.1 ç›‘æ§æŒ‡æ ‡æ”¶é›†

**æŒ‡æ ‡æ”¶é›†**ï¼š

```typescript
// src/server/performance/metrics.ts
export class PerformanceMetrics {
  private metrics: Map<string, Metric> = new Map();

  record(metricName: string, value: number, tags?: Record<string, string>): void {
    const metric = this.getOrCreateMetric(metricName);
    metric.record(value, tags);
  }

  private getOrCreateMetric(name: string): Metric {
    if (!this.metrics.has(name)) {
      this.metrics.set(name, new Metric(name));
    }
    return this.metrics.get(name)!;
  }

  getStats(): Record<string, any> {
    const stats: Record<string, any> = {};
    for (const [name, metric] of this.metrics.entries()) {
      stats[name] = metric.getStats();
    }
    return stats;
  }
}

class Metric {
  private values: number[] = [];
  private count: number = 0;
  private sum: number = 0;
  private min: number = Infinity;
  private max: number = -Infinity;

  record(value: number, tags?: Record<string, string>): void {
    this.values.push(value);
    this.count++;
    this.sum += value;
    this.min = Math.min(this.min, value);
    this.max = Math.max(this.max, value);
  }

  getStats() {
    return {
      count: this.count,
      sum: this.sum,
      avg: this.count > 0 ? this.sum / this.count : 0,
      min: this.min === Infinity ? 0 : this.min,
      max: this.max === -Infinity ? 0 : this.max,
      p95: this.calculatePercentile(95),
      p99: this.calculatePercentile(99),
    };
  }

  private calculatePercentile(percentile: number): number {
    if (this.values.length === 0) return 0;
    const sorted = [...this.values].sort((a, b) => a - b);
    const index = Math.ceil((percentile / 100) * sorted.length) - 1;
    return sorted[index];
  }
}
```

### 6.2 æ€§èƒ½åˆ†æå·¥å…·

**åˆ†æå·¥å…·**ï¼š

- æ€§èƒ½åˆ†æå™¨
- ç“¶é¢ˆè¯†åˆ«
- ä¼˜åŒ–å»ºè®®

### 6.3 å‘Šè­¦æœºåˆ¶

**å‘Šè­¦è§„åˆ™**ï¼š

- å»¶è¿Ÿå‘Šè­¦
- é”™è¯¯ç‡å‘Šè­¦
- èµ„æºä½¿ç”¨å‘Šè­¦

---

## 7. æµ‹è¯•ä¸éªŒè¯

### 7.1 å•å…ƒæµ‹è¯•

**æµ‹è¯•ç”¨ä¾‹**ï¼š

```typescript
// tests/performance/connection-pool.test.ts
describe('ConnectionPool', () => {
  it('should create and reuse connections', async () => {
    const pool = new ConnectionPool({ maxSize: 10 });
    const conn1 = await pool.acquire();
    pool.release(conn1);
    const conn2 = await pool.acquire();
    expect(conn2.id).toBe(conn1.id);
  });
});
```

### 7.2 æ€§èƒ½æµ‹è¯•

**æ€§èƒ½æµ‹è¯•è„šæœ¬**ï¼š

```typescript
// tests/performance/benchmark.ts
async function benchmark() {
  const pool = new ConnectionPool({ maxSize: 20 });
  await pool.warmup();

  const start = Date.now();
  const promises = [];
  for (let i = 0; i < 1000; i++) {
    promises.push(pool.acquire().then(conn => pool.release(conn)));
  }
  await Promise.all(promises);
  const duration = Date.now() - start;

  console.log(`Processed 1000 requests in ${duration}ms`);
  console.log(`Average: ${duration / 1000}ms per request`);
}
```

### 7.3 å‹åŠ›æµ‹è¯•

**å‹åŠ›æµ‹è¯•åœºæ™¯**ï¼š

- é«˜å¹¶å‘è¯·æ±‚
- é•¿æ—¶é—´è¿è¡Œ
- èµ„æºé™åˆ¶æµ‹è¯•

---

## 8. éƒ¨ç½²ä¸è¿ç»´

### 8.1 éƒ¨ç½²é…ç½®

**é…ç½®ç¤ºä¾‹**ï¼š

```yaml
# config/performance.yaml
connectionPool:
  maxSize: 20
  minSize: 5
  idleTimeout: 30000
  maxIdleTime: 300000

batchProcessing:
  batchSize: 10
  batchWindow: 100

cache:
  l1MaxSize: 1000
  defaultTTL: 3600000
  l2Enabled: true
  l2Type: redis
```

### 8.2 è¿ç»´ç›‘æ§

**ç›‘æ§æŒ‡æ ‡**ï¼š

- è¿æ¥æ± çŠ¶æ€
- æ‰¹å¤„ç†é˜Ÿåˆ—é•¿åº¦
- ç¼“å­˜å‘½ä¸­ç‡
- è¯·æ±‚å»¶è¿Ÿåˆ†å¸ƒ

### 8.3 æ•…éšœå¤„ç†

**æ•…éšœå¤„ç†æµç¨‹**ï¼š

1. æ•…éšœæ£€æµ‹
2. è‡ªåŠ¨æ¢å¤
3. å‘Šè­¦é€šçŸ¥
4. æ•…éšœåˆ†æ

---

## 9. MCPæ€§èƒ½ä¼˜åŒ–ç»¼åˆåº”ç”¨å®é™…ç¤ºä¾‹

**ç¤ºä¾‹ï¼šå®ç°MCPæ€§èƒ½ä¼˜åŒ–ç»¼åˆç®¡ç†ç³»ç»Ÿ**

```python
import time
import asyncio
import hashlib
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Callable
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
import threading

@dataclass
class PerformanceConfig:
    """æ€§èƒ½é…ç½®"""
    max_pool_size: int = 20
    min_pool_size: int = 5
    idle_timeout_ms: int = 30000
    batch_size: int = 10
    batch_window_ms: int = 100
    cache_max_size: int = 1000
    cache_ttl_ms: int = 3600000

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    connection_pool_utilization: float = 0.0
    batch_processing_throughput: float = 0.0
    cache_hit_rate: float = 0.0
    avg_response_time_ms: float = 0.0
    total_requests: int = 0
    successful_requests: int = 0

class MCPPerformanceOptimizationFramework:
    """MCPæ€§èƒ½ä¼˜åŒ–ç»¼åˆæ¡†æ¶"""

    def __init__(self, config: PerformanceConfig = None):
        self.config = config or PerformanceConfig()
        self.metrics = PerformanceMetrics()

        # è¿æ¥æ± ï¼ˆåŸºäºç¬¬2ç« ï¼‰
        self.connection_pool: List[Dict] = []
        self.active_connections: Dict[str, Dict] = {}
        self.pool_lock = threading.Lock()

        # æ‰¹å¤„ç†é˜Ÿåˆ—ï¼ˆåŸºäºç¬¬3ç« ï¼‰
        self.batch_queue: List[Dict] = []
        self.batch_lock = threading.Lock()

        # å¤šçº§ç¼“å­˜ï¼ˆåŸºäºç¬¬4ç« ï¼‰
        self.l1_cache: Dict[str, Any] = {}  # å†…å­˜ç¼“å­˜
        self.l2_cache: Dict[str, Any] = {}  # æ¨¡æ‹ŸRedisç¼“å­˜
        self.cache_timestamps: Dict[str, float] = {}
        self.cache_stats = {'hits': 0, 'misses': 0}

        # å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ï¼ˆåŸºäºç¬¬5ç« ï¼‰
        self.task_queue: asyncio.Queue = None
        self.executor = ThreadPoolExecutor(max_workers=4)

        # æ€§èƒ½ç›‘æ§ï¼ˆåŸºäºç¬¬6ç« ï¼‰
        self.response_times: List[float] = []

        # åˆå§‹åŒ–è¿æ¥æ± 
        self._init_connection_pool()

    def _init_connection_pool(self):
        """åˆå§‹åŒ–è¿æ¥æ± ï¼ˆåŸºäºç¬¬2ç« ï¼‰"""
        for i in range(self.config.min_pool_size):
            connection = {
                'id': f'conn_{i}',
                'created_at': time.time(),
                'last_used_at': time.time(),
                'status': 'idle'
            }
            self.connection_pool.append(connection)

    # ===== è¿æ¥æ± ä¼˜åŒ–ï¼ˆåŸºäºç¬¬2ç« ï¼‰=====
    def acquire_connection(self) -> Optional[Dict]:
        """è·å–è¿æ¥"""
        with self.pool_lock:
            # æŸ¥æ‰¾ç©ºé—²è¿æ¥
            for conn in self.connection_pool:
                if conn['status'] == 'idle':
                    conn['status'] = 'active'
                    conn['last_used_at'] = time.time()
                    self.active_connections[conn['id']] = conn
                    return conn

            # å¦‚æœæ²¡æœ‰ç©ºé—²è¿æ¥ä¸”æœªè¾¾åˆ°æœ€å¤§å€¼ï¼Œåˆ›å»ºæ–°è¿æ¥
            if len(self.connection_pool) < self.config.max_pool_size:
                new_conn = {
                    'id': f'conn_{len(self.connection_pool)}',
                    'created_at': time.time(),
                    'last_used_at': time.time(),
                    'status': 'active'
                }
                self.connection_pool.append(new_conn)
                self.active_connections[new_conn['id']] = new_conn
                return new_conn

            return None

    def release_connection(self, conn_id: str):
        """é‡Šæ”¾è¿æ¥"""
        with self.pool_lock:
            if conn_id in self.active_connections:
                conn = self.active_connections.pop(conn_id)
                conn['status'] = 'idle'
                conn['last_used_at'] = time.time()

    def get_pool_utilization(self) -> float:
        """è·å–è¿æ¥æ± åˆ©ç”¨ç‡"""
        with self.pool_lock:
            active = len(self.active_connections)
            total = len(self.connection_pool)
            return active / total if total > 0 else 0

    # ===== æ‰¹å¤„ç†ä¼˜åŒ–ï¼ˆåŸºäºç¬¬3ç« ï¼‰=====
    def add_to_batch(self, request: Dict) -> str:
        """æ·»åŠ è¯·æ±‚åˆ°æ‰¹å¤„ç†é˜Ÿåˆ—"""
        request_id = hashlib.md5(str(time.time()).encode()).hexdigest()[:8]
        request['id'] = request_id
        request['queued_at'] = time.time()

        with self.batch_lock:
            self.batch_queue.append(request)

            # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰§è¡Œæ‰¹å¤„ç†
            if len(self.batch_queue) >= self.config.batch_size:
                self._process_batch()

        return request_id

    def _process_batch(self) -> List[Dict]:
        """å¤„ç†æ‰¹é‡è¯·æ±‚"""
        with self.batch_lock:
            batch = self.batch_queue[:self.config.batch_size]
            self.batch_queue = self.batch_queue[self.config.batch_size:]

        results = []
        start_time = time.time()

        for request in batch:
            result = self._execute_request(request)
            results.append(result)

        # æ›´æ–°ååé‡æŒ‡æ ‡
        elapsed = time.time() - start_time
        self.metrics.batch_processing_throughput = len(batch) / elapsed if elapsed > 0 else 0

        return results

    def _execute_request(self, request: Dict) -> Dict:
        """æ‰§è¡Œå•ä¸ªè¯·æ±‚"""
        start = time.time()

        # æ¨¡æ‹Ÿè¯·æ±‚å¤„ç†
        time.sleep(0.001)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

        elapsed = (time.time() - start) * 1000
        self.response_times.append(elapsed)

        return {
            'id': request.get('id'),
            'success': True,
            'elapsed_ms': elapsed
        }

    # ===== ç¼“å­˜ç­–ç•¥ï¼ˆåŸºäºç¬¬4ç« ï¼‰=====
    def cache_get(self, key: str) -> Optional[Any]:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        # å…ˆæŸ¥L1ç¼“å­˜
        if key in self.l1_cache:
            if self._is_cache_valid(key):
                self.cache_stats['hits'] += 1
                return self.l1_cache[key]

        # å†æŸ¥L2ç¼“å­˜
        if key in self.l2_cache:
            if self._is_cache_valid(key):
                self.cache_stats['hits'] += 1
                # æå‡åˆ°L1ç¼“å­˜
                self.l1_cache[key] = self.l2_cache[key]
                return self.l2_cache[key]

        self.cache_stats['misses'] += 1
        return None

    def cache_set(self, key: str, value: Any, ttl_ms: int = None):
        """è®¾ç½®ç¼“å­˜"""
        ttl = ttl_ms or self.config.cache_ttl_ms

        # L1ç¼“å­˜æ»¡äº†ï¼Œç§»é™¤æœ€æ—§çš„
        if len(self.l1_cache) >= self.config.cache_max_size:
            oldest_key = min(self.cache_timestamps, key=self.cache_timestamps.get)
            # é™çº§åˆ°L2ç¼“å­˜
            self.l2_cache[oldest_key] = self.l1_cache.pop(oldest_key)

        self.l1_cache[key] = value
        self.cache_timestamps[key] = time.time() + (ttl / 1000)

    def _is_cache_valid(self, key: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if key not in self.cache_timestamps:
            return False
        return time.time() < self.cache_timestamps[key]

    def get_cache_hit_rate(self) -> float:
        """è·å–ç¼“å­˜å‘½ä¸­ç‡"""
        total = self.cache_stats['hits'] + self.cache_stats['misses']
        return self.cache_stats['hits'] / total if total > 0 else 0

    # ===== å¼‚æ­¥å¤„ç†ï¼ˆåŸºäºç¬¬5ç« ï¼‰=====
    async def async_transform(self, schema: Dict, transformer: Callable) -> Dict:
        """å¼‚æ­¥æ‰§è¡Œè½¬æ¢"""
        loop = asyncio.get_event_loop()

        # æ£€æŸ¥ç¼“å­˜
        cache_key = hashlib.md5(str(schema).encode()).hexdigest()
        cached = self.cache_get(cache_key)
        if cached:
            return cached

        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œè½¬æ¢
        result = await loop.run_in_executor(
            self.executor,
            transformer,
            schema
        )

        # å­˜å…¥ç¼“å­˜
        self.cache_set(cache_key, result)

        return result

    async def async_batch_transform(self, schemas: List[Dict], transformer: Callable) -> List[Dict]:
        """å¼‚æ­¥æ‰¹é‡è½¬æ¢"""
        tasks = [
            self.async_transform(schema, transformer)
            for schema in schemas
        ]
        return await asyncio.gather(*tasks)

    # ===== æ€§èƒ½ç›‘æ§ï¼ˆåŸºäºç¬¬6ç« ï¼‰=====
    def collect_metrics(self) -> PerformanceMetrics:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        self.metrics.connection_pool_utilization = self.get_pool_utilization()
        self.metrics.cache_hit_rate = self.get_cache_hit_rate()

        if self.response_times:
            self.metrics.avg_response_time_ms = sum(self.response_times) / len(self.response_times)
            self.metrics.total_requests = len(self.response_times)
            self.metrics.successful_requests = len(self.response_times)

        return self.metrics

    def get_performance_report(self) -> Dict:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        metrics = self.collect_metrics()

        return {
            'connection_pool': {
                'total_connections': len(self.connection_pool),
                'active_connections': len(self.active_connections),
                'utilization': f"{metrics.connection_pool_utilization:.1%}"
            },
            'batch_processing': {
                'queue_size': len(self.batch_queue),
                'throughput': f"{metrics.batch_processing_throughput:.1f} req/s"
            },
            'cache': {
                'l1_size': len(self.l1_cache),
                'l2_size': len(self.l2_cache),
                'hit_rate': f"{metrics.cache_hit_rate:.1%}",
                'hits': self.cache_stats['hits'],
                'misses': self.cache_stats['misses']
            },
            'response_time': {
                'avg_ms': f"{metrics.avg_response_time_ms:.2f}",
                'total_requests': metrics.total_requests
            }
        }

    def check_performance_alerts(self) -> List[Dict]:
        """æ£€æŸ¥æ€§èƒ½å‘Šè­¦"""
        alerts = []
        metrics = self.collect_metrics()

        # è¿æ¥æ± åˆ©ç”¨ç‡å‘Šè­¦
        if metrics.connection_pool_utilization > 0.8:
            alerts.append({
                'level': 'warning',
                'type': 'connection_pool',
                'message': f'è¿æ¥æ± åˆ©ç”¨ç‡è¿‡é«˜: {metrics.connection_pool_utilization:.1%}'
            })

        # ç¼“å­˜å‘½ä¸­ç‡å‘Šè­¦
        if metrics.cache_hit_rate < 0.5:
            alerts.append({
                'level': 'warning',
                'type': 'cache',
                'message': f'ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½: {metrics.cache_hit_rate:.1%}'
            })

        # å“åº”æ—¶é—´å‘Šè­¦
        if metrics.avg_response_time_ms > 100:
            alerts.append({
                'level': 'warning',
                'type': 'response_time',
                'message': f'å¹³å‡å“åº”æ—¶é—´è¿‡é•¿: {metrics.avg_response_time_ms:.2f}ms'
            })

        return alerts

# å®é™…åº”ç”¨ç¤ºä¾‹
config = PerformanceConfig(
    max_pool_size=10,
    batch_size=5,
    cache_max_size=100
)
framework = MCPPerformanceOptimizationFramework(config)

# ç¤ºä¾‹1ï¼šè¿æ¥æ± ä½¿ç”¨
print("=== ç¤ºä¾‹1ï¼šè¿æ¥æ± ä½¿ç”¨ ===")
conn1 = framework.acquire_connection()
conn2 = framework.acquire_connection()
print(f"è¿æ¥æ± åˆ©ç”¨ç‡: {framework.get_pool_utilization():.1%}")
framework.release_connection(conn1['id'])
print(f"é‡Šæ”¾ååˆ©ç”¨ç‡: {framework.get_pool_utilization():.1%}")

# ç¤ºä¾‹2ï¼šæ‰¹å¤„ç†
print("\n=== ç¤ºä¾‹2ï¼šæ‰¹å¤„ç† ===")
for i in range(5):
    req_id = framework.add_to_batch({'data': f'request_{i}'})
    print(f"æ·»åŠ è¯·æ±‚: {req_id}")
print(f"é˜Ÿåˆ—å¤§å°: {len(framework.batch_queue)}")

# ç¤ºä¾‹3ï¼šç¼“å­˜ä½¿ç”¨
print("\n=== ç¤ºä¾‹3ï¼šç¼“å­˜ä½¿ç”¨ ===")
framework.cache_set('schema_1', {'type': 'object'})
result = framework.cache_get('schema_1')
print(f"ç¼“å­˜å‘½ä¸­: {result is not None}")
print(f"ç¼“å­˜å‘½ä¸­ç‡: {framework.get_cache_hit_rate():.1%}")

# ç¤ºä¾‹4ï¼šæ€§èƒ½æŠ¥å‘Š
print("\n=== æ€§èƒ½æŠ¥å‘Š ===")
report = framework.get_performance_report()
for category, data in report.items():
    print(f"\n{category}:")
    for key, value in data.items():
        print(f"  {key}: {value}")

# ç¤ºä¾‹5ï¼šæ€§èƒ½å‘Šè­¦
print("\n=== æ€§èƒ½å‘Šè­¦ ===")
alerts = framework.check_performance_alerts()
if alerts:
    for alert in alerts:
        print(f"[{alert['level']}] {alert['type']}: {alert['message']}")
else:
    print("æ— å‘Šè­¦")
```

---

## 10. å‚è€ƒæ–‡æ¡£

### æ€§èƒ½ä¼˜åŒ–æ–‡æ¡£

- `analysis/11_MCP_Performance_Optimization.md` - æ€§èƒ½ä¼˜åŒ–åˆ†æ
- `src/server/performance/` - æ€§èƒ½ä¼˜åŒ–ä»£ç å®ç°

### æ¨¡å¼æ–‡æ¡£ â­æ–°å¢

- `docs/structure/INFORMATION_PROCESSING_PATTERNS_SUMMARY.md`ï¼šä¿¡æ¯å¤„ç†æ¨¡å¼æ€»ç»“ï¼ˆ12ä¸ªæ¨¡å¼ï¼‰
  - åœ¨MCPæ€§èƒ½ä¼˜åŒ–ä¸­ï¼Œå¯ä»¥å‚è€ƒæµå¤„ç†æ¨¡å¼ã€æ‰¹å¤„ç†æ¨¡å¼ã€å®æ—¶å¤„ç†æ¨¡å¼ç­‰
- `docs/structure/DESIGN_PATTERNS_SUMMARY.md`ï¼šè®¾è®¡æ¨¡å¼æ€»ç»“ï¼ˆ15ä¸ªæ¨¡å¼ï¼‰
  - åœ¨æ€§èƒ½ä¼˜åŒ–å®ç°ä¸­ï¼Œå¯ä»¥å‚è€ƒè£…é¥°å™¨æ¨¡å¼ï¼ˆç¼“å­˜è£…é¥°å™¨ï¼‰ã€ç­–ç•¥æ¨¡å¼ï¼ˆä¼˜åŒ–ç­–ç•¥ï¼‰ç­‰
- `docs/structure/ARCHITECTURE_PATTERNS_SUMMARY.md`ï¼šæ¶æ„æ¨¡å¼æ€»ç»“ï¼ˆ12ä¸ªæ¨¡å¼ï¼‰
  - åœ¨MCPç³»ç»Ÿæ¶æ„è®¾è®¡ä¸­ï¼Œå¯ä»¥å‚è€ƒå¾®æœåŠ¡æ¶æ„ã€äº‹ä»¶é©±åŠ¨æ¶æ„ç­‰
- `docs/structure/PATTERNS_QUICK_REFERENCE.md`ï¼šæ¨¡å¼å¿«é€Ÿå‚è€ƒæŒ‡å— â­æ¨è

---

## ğŸ“ ç‰ˆæœ¬å†å²

### v1.2 (2025-01-21) - å®é™…åº”ç”¨ç¤ºä¾‹å¢å¼ºç‰ˆ

- âœ… æ‰©å±•ç¬¬9ç« ï¼šä¸ºMCPæ€§èƒ½ä¼˜åŒ–æ·»åŠ ç»¼åˆåº”ç”¨å®é™…ç¤ºä¾‹ï¼ˆåŒ…å«æ€§èƒ½ä¼˜åŒ–ç»¼åˆæ¡†æ¶å®ç°ã€è¿æ¥æ± ç®¡ç†ã€æ‰¹å¤„ç†é˜Ÿåˆ—ã€å¤šçº§ç¼“å­˜ã€å¼‚æ­¥å¤„ç†ã€æ€§èƒ½ç›‘æ§ã€å‘Šè­¦æœºåˆ¶ï¼‰
- âœ… æ·»åŠ ç‰ˆæœ¬å†å²ç« èŠ‚
- âœ… æ›´æ–°æ–‡æ¡£ç‰ˆæœ¬å·è‡³v1.2

### v1.1 (2025-01-27) - åˆå§‹ç‰ˆæœ¬

- âœ… åˆ›å»ºæ–‡æ¡£ï¼šMCPåè®®æ€§èƒ½ä¼˜åŒ–å®æ–½æŒ‡å—
- âœ… æ·»åŠ è¿æ¥æ± ä¼˜åŒ–å®æ–½
- âœ… æ·»åŠ è¯·æ±‚æ‰¹å¤„ç†å®æ–½
- âœ… æ·»åŠ ç¼“å­˜ç­–ç•¥å®æ–½
- âœ… æ·»åŠ å¼‚æ­¥å¤„ç†å®æ–½
- âœ… æ·»åŠ æ€§èƒ½ç›‘æ§å®æ–½
- âœ… æ·»åŠ æµ‹è¯•ä¸éªŒè¯
- âœ… æ·»åŠ éƒ¨ç½²ä¸è¿ç»´

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼š1.2ï¼ˆå®é™…åº”ç”¨ç¤ºä¾‹å¢å¼ºç‰ˆï¼‰
**åˆ›å»ºæ—¶é—´**ï¼š2025-01-21
**æœ€åæ›´æ–°**ï¼š2025-01-21
